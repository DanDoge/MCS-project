{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试DVI正态近似的准确性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import os, json \n",
    "\n",
    "import gaussian_variables as gv\n",
    "import utils as u\n",
    "import plot_utils as pu\n",
    "import bayes_layers as bnn\n",
    "from bayes_models import MLP, PointMLP, AdaptedMLP\n",
    "\n",
    "np.random.seed(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先构建数据集：\n",
    "\\begin{equation}\n",
    "    y = -(x+0.5)\\sin(3\\pi x) + \\eta\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "    \\eta = 0.45(x + 0.5)^2\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def base_model(x):\n",
    "    return -(x+0.5)*np.sin(3 * np.pi *x)\n",
    "\n",
    "def noise_model(x):\n",
    "    return 0.45*(x+0.5)**2\n",
    "\n",
    "def sample_data(x):\n",
    "    return base_model(x) + np.random.normal(0, noise_model(x))\n",
    "\n",
    "data_size = {'train': 500, 'valid': 100, 'test': 100}\n",
    "toy_data = []\n",
    "for section in ['train', 'valid', 'test']:\n",
    "    x = (np.random.rand(data_size['train'], 1) - 0.5)\n",
    "    toy_data.append([x, sample_data(x).reshape(-1)])    \n",
    "x = np.arange(-1,1,1/100)\n",
    "toy_data.append([[[_] for _ in x], base_model(x)])\n",
    "\n",
    "pu.toy_results_plot(toy_data, {'mean':base_model, 'std':noise_model})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设置模型参数，这里以一个三层、每层5个神经元的网络为例(本项目中的其他网络结果修改“hidden_dims”参数可得到)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypers = {\n",
    "    \"x_dim\": 1,                                \"y_dim\": 2,\n",
    "    \"hidden_dims\": [5,5,5],                  \"nonlinearity\": \"relu\",\n",
    "    \"adapter\": {\n",
    "        'in' : {\"scale\": [[1.0]], \"shift\": [[0.0]]},\n",
    "        'out': {\"scale\": [[1.0, 0.83]], \"shift\": [[0.0, -3.5]]}\n",
    "    },\n",
    "    \n",
    "    \"method\": \"bayes\",                         \"style\": \"heteroskedastic\",\n",
    "    \"homo_logvar_scale\": 2*np.log(0.2),        \"prior_type\": [\"empirical\", \"wider_he\", \"wider_he\"],\n",
    "    \n",
    "    \"n_epochs\": 20000,                         \"batch_size\": 500,\n",
    "    \"learning_rate\": 0.001,                    \"lambda\": 1.0,\n",
    "    \"warmup_updates\": {'lambda': 14000.0},     \"anneal_updates\": {'lambda': 1000.0},\n",
    "    \"optimizer\": \"adam\",                       \"gradient_clip\": 0.1,\n",
    "\n",
    "    \"data_fraction\": 1.0,                      \"sections_to_run\": [\"train\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(hypers):\n",
    "    if hypers['method'].lower().strip() == 'bayes':\n",
    "        MLP_factory = MLP\n",
    "        prediction = lambda y: tf.reshape(y.mean[:,0], [-1])\n",
    "        loss = bnn.regression_loss\n",
    "    else:\n",
    "        MLP_factory = PointMLP\n",
    "        prediction = lambda y: tf.reshape(y.mean[:,0], [-1])\n",
    "        loss = bnn.point_regression_loss\n",
    "        \n",
    "    mlp = MLP_factory(hypers['x_dim'], hypers['y_dim'], hypers)\n",
    "    mlp = AdaptedMLP(mlp)\n",
    "    mlp.make_placeholders()\n",
    "    ipt = mlp.placeholders['ipt_mean']\n",
    "    y = mlp(ipt)\n",
    "    target = tf.placeholder(tf.float32, [None])\n",
    "    mlp.placeholders['target'] = target\n",
    "    global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "    loss, logprob, all_surprise = loss(y, target, mlp, hypers, global_step)\n",
    "\n",
    "    accuracy = tf.reduce_mean(tf.abs(target - prediction(y)))\n",
    "    \n",
    "    return {\n",
    "        'model': mlp,\n",
    "        'metrics': {\n",
    "            'accuracy': accuracy,   'loss': loss,\n",
    "            'logprob': logprob,     'all_surprise': all_surprise\n",
    "            },\n",
    "        'global_step': global_step}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "给出一个比较DVI和MCVI算法结果的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "def show_compare(model_and_metrics, sess):\n",
    "    plt.figure()\n",
    "    n_samp = 20000\n",
    "    x = 0.25\n",
    "    ipt = [[[x]] for _ in range(n_samp)]\n",
    "\n",
    "    sample_op = model_and_metrics['model'].run_with_MC(\n",
    "        ipt, n_sample=n_samp)\n",
    "    approx_op = model_and_metrics['model'](x)\n",
    "    samples = sess.run(sample_op)\n",
    "    approx = sess.run([approx_op.mean, approx_op.var])\n",
    "\n",
    "    # samples_b.shape\n",
    "    m_min = stats.norm.ppf(\n",
    "        0.0001, loc=approx[0][0, 0], scale=np.sqrt(approx[1][0, 0, 0]))\n",
    "    m_max = stats.norm.ppf(\n",
    "        0.9999, loc=approx[0][0, 0], scale=np.sqrt(approx[1][0, 0, 0]))\n",
    "    l_min = stats.norm.ppf(\n",
    "        0.0001, loc=approx[0][0, 1], scale=np.sqrt(approx[1][0, 1, 1]))\n",
    "    l_max = stats.norm.ppf(\n",
    "        0.9999, loc=approx[0][0, 1], scale=np.sqrt(approx[1][0, 1, 1]))\n",
    "\n",
    "    bin_no_m = np.linspace(m_min, m_max, 50)\n",
    "    bin_no_l = np.linspace(l_min, l_max, 50)\n",
    "\n",
    "    fig = plt.figure()\n",
    "\n",
    "    ax1 = fig.add_subplot(221)\n",
    "    ax1.hist(samples[:, 0, 0], bin_no_m,\n",
    "             density=True, edgecolor='k', facecolor='#b4c7e7')\n",
    "    ax1.plot(*gaussian1d(approx[0][0, 0], approx[1][0, 0, 0],\n",
    "                         m_min, m_max), 'b')\n",
    "    plt.xlim([m_min, m_max])\n",
    "    ax1.set_yticks([])\n",
    "    ax1.set_xlabel('$m$')\n",
    "    ax1.set_ylabel('$q(m)$')\n",
    "\n",
    "    ax2 = fig.add_subplot(222)\n",
    "    ax2.hist(samples[:, 0, 1], bin_no_l,\n",
    "             density=True, edgecolor='k', facecolor='#b4c7e7', label=\"MC\")\n",
    "\n",
    "    ax2.plot(*gaussian1d(approx[0][0, 1],\n",
    "                         approx[1][0, 1, 1],\n",
    "                         l_min,\n",
    "                         l_max), 'b', label=\"ours\")\n",
    "    plt.xlim([l_min, l_max])\n",
    "    ax2.set_yticks([])\n",
    "    ax2.set_xlabel('$\\ell$')\n",
    "    ax2.set_ylabel('$q(\\ell)$')\n",
    "    plt.show()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian1d(mean, var, min, max):\n",
    "    x_axis = np.linspace(min, max, 1000)\n",
    "    return x_axis, 1.0 / np.sqrt(2.0 * np.pi * var) * \\\n",
    "        np.exp(-1.0 / (2.0 * var) * (x_axis - mean)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run(data):\n",
    "    run_id = u.start_run()\n",
    "\n",
    "    restricted_training_set = u.restrict_dataset_size(data[0], hypers['data_fraction'])\n",
    "    hypers['dataset_size'] = len(restricted_training_set[0])\n",
    "\n",
    "    device_id = 1\n",
    "    device_string = u.get_device_string(device_id)\n",
    "    print(hypers)\n",
    "    with tf.device(device_string):\n",
    "        if True:\n",
    "            model_and_metrics = make_model(hypers)\n",
    "            train_op = u.make_optimizer(model_and_metrics, hypers)\n",
    "            sess = u.get_session()\n",
    "            saver = tf.train.Saver()\n",
    "\n",
    "            all_summaries = []\n",
    "            best_valid_accuracy = np.inf\n",
    "\n",
    "        show_compare(model_and_metrics, sess)\n",
    "\n",
    "        for epoch in range(hypers['n_epochs']):\n",
    "            verbose = (epoch % 20 == 0)\n",
    "            if verbose:\n",
    "                print(\"Epoch %i:        \" % epoch, end='')\n",
    "            epoch_summary, accuracies = u.train_valid_test(\n",
    "                {\n",
    "                    'train': restricted_training_set,\n",
    "                    'valid': data[1],\n",
    "                    'test': data[2]\n",
    "                },\n",
    "                sess, model_and_metrics, train_op, hypers, verbose)\n",
    "\n",
    "        show_compare(model_and_metrics, sess)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "开始训练，并得到两个DVI和MCVI之间的比较"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "* RUN ID: 20200104_232817_28154 \n",
      "********************************************************************************\n",
      "{'x_dim': 1, 'y_dim': 2, 'hidden_dims': [5, 5, 5], 'nonlinearity': 'relu', 'adapter': {'in': {'scale': [[1.0]], 'shift': [[0.0]]}, 'out': {'scale': [[1.0, 0.83]], 'shift': [[0.0, -3.5]]}}, 'method': 'bayes', 'style': 'heteroskedastic', 'homo_logvar_scale': -3.2188758248682006, 'prior_type': ['empirical', 'wider_he', 'wider_he'], 'n_epochs': 20000, 'batch_size': 500, 'learning_rate': 0.001, 'lambda': 1.0, 'warmup_updates': {'lambda': 14000.0}, 'anneal_updates': {'lambda': 1000.0}, 'optimizer': 'adam', 'gradient_clip': 0.1, 'data_fraction': 1.0, 'sections_to_run': ['train'], 'dataset_size': 500}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:         train accuracy = 2.4631 | logprob = -inf | KL term = 0.06878518676757812\n",
      "Epoch 20:         train accuracy = 2.3221 | logprob = -inf | KL term = 0.07073880004882813\n",
      "Epoch 40:         train accuracy = 2.1761 | logprob = -inf | KL term = 0.07277249145507812\n",
      "Epoch 60:         train accuracy = 2.0272 | logprob = -inf | KL term = 0.07488713073730469\n",
      "Epoch 80:         train accuracy = 1.8775 | logprob = -inf | KL term = 0.07708345031738281\n",
      "Epoch 100:         train accuracy = 1.7284 | logprob = -inf | KL term = 0.07936199951171875\n",
      "Epoch 120:         train accuracy = 1.5813 | logprob = -inf | KL term = 0.08172322082519531\n",
      "Epoch 140:         train accuracy = 1.4293 | logprob = -inf | KL term = 0.0841532974243164\n",
      "Epoch 160:         train accuracy = 1.1791 | logprob = -5625878350360481583423217991680.0000 | KL term = 0.08607627868652344\n",
      "Epoch 180:         train accuracy = 0.9313 | logprob = -12647288345277070179303424.0000 | KL term = 0.08769320678710937\n",
      "Epoch 200:         train accuracy = 0.7225 | logprob = -256360688572996517888.0000 | KL term = 0.08933316040039062\n",
      "Epoch 220:         train accuracy = 0.5727 | logprob = -36449871317696512.0000 | KL term = 0.09105745697021485\n",
      "Epoch 240:         train accuracy = 0.4928 | logprob = -26735965896704.0000 | KL term = 0.09289052581787109\n",
      "Epoch 260:         train accuracy = 0.4517 | logprob = -76914950144.0000 | KL term = 0.09478584289550782\n",
      "Epoch 280:         train accuracy = 0.4309 | logprob = -683432896.0000 | KL term = 0.09674729919433593\n",
      "Epoch 300:         train accuracy = 0.4217 | logprob = -15222161.0000 | KL term = 0.09878720092773438\n",
      "Epoch 320:         train accuracy = 0.4197 | logprob = -717463.0625 | KL term = 0.10085868835449219\n",
      "Epoch 340:         train accuracy = 0.4247 | logprob = -62222.6797 | KL term = 0.10294915771484375\n",
      "Epoch 360:         train accuracy = 0.4351 | logprob = -8781.4131 | KL term = 0.1050487060546875\n",
      "Epoch 380:         train accuracy = 0.4474 | logprob = -1811.7081 | KL term = 0.10708972930908203\n",
      "Epoch 400:         train accuracy = 0.4628 | logprob = -508.0555 | KL term = 0.10915412902832031\n",
      "Epoch 420:         train accuracy = 0.4800 | logprob = -182.8909 | KL term = 0.11127096557617187\n",
      "Epoch 440:         train accuracy = 0.4963 | logprob = -80.5056 | KL term = 0.11338484954833984\n",
      "Epoch 460:         train accuracy = 0.4918 | logprob = -41.5028 | KL term = 0.11548005676269531\n",
      "Epoch 480:         train accuracy = 0.4814 | logprob = -24.2283 | KL term = 0.11761363983154297\n",
      "Epoch 500:         train accuracy = 0.4701 | logprob = -15.6064 | KL term = 0.11978172302246094\n",
      "Epoch 520:         train accuracy = 0.4585 | logprob = -10.8627 | KL term = 0.12189088439941406\n",
      "Epoch 540:         train accuracy = 0.4473 | logprob = -8.0379 | KL term = 0.12390689849853516\n",
      "Epoch 560:         train accuracy = 0.4363 | logprob = -6.2458 | KL term = 0.12581690216064453\n",
      "Epoch 580:         train accuracy = 0.4252 | logprob = -5.0488 | KL term = 0.12764265441894532\n",
      "Epoch 600:         train accuracy = 0.4143 | logprob = -4.2137 | KL term = 0.12937403869628905\n",
      "Epoch 620:         train accuracy = 0.4042 | logprob = -3.6091 | KL term = 0.13096714782714844\n",
      "Epoch 640:         train accuracy = 0.3950 | logprob = -3.1583 | KL term = 0.13242042541503907\n",
      "Epoch 660:         train accuracy = 0.3866 | logprob = -2.8135 | KL term = 0.13374630737304688\n",
      "Epoch 680:         train accuracy = 0.3790 | logprob = -2.5443 | KL term = 0.13494737243652344\n",
      "Epoch 700:         train accuracy = 0.3721 | logprob = -2.3304 | KL term = 0.13602346801757811\n",
      "Epoch 720:         train accuracy = 0.3659 | logprob = -2.1590 | KL term = 0.13696229553222655\n",
      "Epoch 740:         train accuracy = 0.3603 | logprob = -2.0197 | KL term = 0.13776861572265625\n",
      "Epoch 760:         train accuracy = 0.3555 | logprob = -1.9048 | KL term = 0.13847113037109374\n",
      "Epoch 780:         train accuracy = 0.3512 | logprob = -1.8086 | KL term = 0.13909246826171875\n",
      "Epoch 800:         train accuracy = 0.3476 | logprob = -1.7278 | KL term = 0.13964952087402344\n",
      "Epoch 820:         train accuracy = 0.3448 | logprob = -1.6599 | KL term = 0.1401545867919922\n",
      "Epoch 840:         train accuracy = 0.3427 | logprob = -1.6033 | KL term = 0.14061837768554689\n",
      "Epoch 860:         train accuracy = 0.3415 | logprob = -1.5567 | KL term = 0.14104876708984376\n",
      "Epoch 880:         train accuracy = 0.3411 | logprob = -1.5186 | KL term = 0.1414517059326172\n",
      "Epoch 900:         train accuracy = 0.3411 | logprob = -1.4834 | KL term = 0.14183102416992188\n",
      "Epoch 920:         train accuracy = 0.3411 | logprob = -1.4501 | KL term = 0.142189208984375\n",
      "Epoch 940:         train accuracy = 0.3410 | logprob = -1.4185 | KL term = 0.14252925109863282\n",
      "Epoch 960:         train accuracy = 0.3410 | logprob = -1.3884 | KL term = 0.14285350036621094\n",
      "Epoch 980:         train accuracy = 0.3410 | logprob = -1.3596 | KL term = 0.14316383361816407\n",
      "Epoch 1000:         train accuracy = 0.3410 | logprob = -1.3320 | KL term = 0.14346185302734374\n",
      "Epoch 1020:         train accuracy = 0.3409 | logprob = -1.3055 | KL term = 0.1437488250732422\n",
      "Epoch 1040:         train accuracy = 0.3409 | logprob = -1.2801 | KL term = 0.14402589416503905\n",
      "Epoch 1060:         train accuracy = 0.3409 | logprob = -1.2556 | KL term = 0.1442940216064453\n",
      "Epoch 1080:         train accuracy = 0.3409 | logprob = -1.2321 | KL term = 0.14455403137207032\n",
      "Epoch 1100:         train accuracy = 0.3409 | logprob = -1.2094 | KL term = 0.144806640625\n",
      "Epoch 1120:         train accuracy = 0.3409 | logprob = -1.1875 | KL term = 0.14505245971679687\n",
      "Epoch 1140:         train accuracy = 0.3409 | logprob = -1.1664 | KL term = 0.14529208374023436\n",
      "Epoch 1160:         train accuracy = 0.3409 | logprob = -1.1460 | KL term = 0.14552595520019532\n",
      "Epoch 1180:         train accuracy = 0.3409 | logprob = -1.1264 | KL term = 0.1457545166015625\n",
      "Epoch 1200:         train accuracy = 0.3409 | logprob = -1.1074 | KL term = 0.1459781494140625\n",
      "Epoch 1220:         train accuracy = 0.3408 | logprob = -1.0891 | KL term = 0.14619720458984375\n",
      "Epoch 1240:         train accuracy = 0.3408 | logprob = -1.0713 | KL term = 0.14641201782226562\n",
      "Epoch 1260:         train accuracy = 0.3408 | logprob = -1.0542 | KL term = 0.14662232971191405\n",
      "Epoch 1280:         train accuracy = 0.3408 | logprob = -1.0378 | KL term = 0.14682716369628906\n",
      "Epoch 1300:         train accuracy = 0.3408 | logprob = -1.0220 | KL term = 0.14702667236328126\n",
      "Epoch 1320:         train accuracy = 0.3408 | logprob = -1.0067 | KL term = 0.14722119140625\n",
      "Epoch 1340:         train accuracy = 0.3408 | logprob = -0.9921 | KL term = 0.14741108703613282\n",
      "Epoch 1360:         train accuracy = 0.3408 | logprob = -0.9779 | KL term = 0.14759664916992188\n",
      "Epoch 1380:         train accuracy = 0.3408 | logprob = -0.9642 | KL term = 0.1477781677246094\n",
      "Epoch 1400:         train accuracy = 0.3408 | logprob = -0.9511 | KL term = 0.14795590209960938\n",
      "Epoch 1420:         train accuracy = 0.3408 | logprob = -0.9383 | KL term = 0.14813006591796876\n",
      "Epoch 1440:         train accuracy = 0.3408 | logprob = -0.9261 | KL term = 0.14830087280273438\n",
      "Epoch 1460:         train accuracy = 0.3408 | logprob = -0.9142 | KL term = 0.148468505859375\n",
      "Epoch 1480:         train accuracy = 0.3408 | logprob = -0.9027 | KL term = 0.14863311767578125\n",
      "Epoch 1500:         train accuracy = 0.3408 | logprob = -0.8917 | KL term = 0.14879489135742188\n",
      "Epoch 1520:         train accuracy = 0.3408 | logprob = -0.8810 | KL term = 0.14895394897460937\n",
      "Epoch 1540:         train accuracy = 0.3408 | logprob = -0.8707 | KL term = 0.14911042785644532\n",
      "Epoch 1560:         train accuracy = 0.3408 | logprob = -0.8607 | KL term = 0.14926445007324218\n",
      "Epoch 1580:         train accuracy = 0.3408 | logprob = -0.8511 | KL term = 0.14941612243652344\n",
      "Epoch 1600:         train accuracy = 0.3408 | logprob = -0.8419 | KL term = 0.1495655517578125\n",
      "Epoch 1620:         train accuracy = 0.3408 | logprob = -0.8329 | KL term = 0.14971281433105468\n",
      "Epoch 1640:         train accuracy = 0.3408 | logprob = -0.8243 | KL term = 0.14985801696777343\n",
      "Epoch 1660:         train accuracy = 0.3408 | logprob = -0.8160 | KL term = 0.15000125122070312\n",
      "Epoch 1680:         train accuracy = 0.3408 | logprob = -0.8080 | KL term = 0.15014254760742188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1700:         train accuracy = 0.3408 | logprob = -0.8003 | KL term = 0.15028204345703125\n",
      "Epoch 1720:         train accuracy = 0.3408 | logprob = -0.7929 | KL term = 0.15041973876953124\n",
      "Epoch 1740:         train accuracy = 0.3408 | logprob = -0.7858 | KL term = 0.15055575561523438\n",
      "Epoch 1760:         train accuracy = 0.3408 | logprob = -0.7789 | KL term = 0.1506901092529297\n",
      "Epoch 1780:         train accuracy = 0.3408 | logprob = -0.7724 | KL term = 0.15082286071777343\n",
      "Epoch 1800:         train accuracy = 0.3408 | logprob = -0.7661 | KL term = 0.15095408630371093\n",
      "Epoch 1820:         train accuracy = 0.3408 | logprob = -0.7600 | KL term = 0.15108380126953125\n",
      "Epoch 1840:         train accuracy = 0.3408 | logprob = -0.7542 | KL term = 0.15121208190917967\n",
      "Epoch 1860:         train accuracy = 0.3408 | logprob = -0.7487 | KL term = 0.1513389434814453\n",
      "Epoch 1880:         train accuracy = 0.3408 | logprob = -0.7434 | KL term = 0.15146444702148437\n",
      "Epoch 1900:         train accuracy = 0.3408 | logprob = -0.7383 | KL term = 0.151588623046875\n",
      "Epoch 1920:         train accuracy = 0.3408 | logprob = -0.7335 | KL term = 0.15171148681640625\n",
      "Epoch 1940:         train accuracy = 0.3408 | logprob = -0.7289 | KL term = 0.15183309936523437\n",
      "Epoch 1960:         train accuracy = 0.3408 | logprob = -0.7245 | KL term = 0.1519534912109375\n",
      "Epoch 1980:         train accuracy = 0.3408 | logprob = -0.7204 | KL term = 0.15207269287109376\n",
      "Epoch 2000:         train accuracy = 0.3408 | logprob = -0.7164 | KL term = 0.15219070434570312\n",
      "Epoch 2020:         train accuracy = 0.3408 | logprob = -0.7127 | KL term = 0.15230757141113282\n",
      "Epoch 2040:         train accuracy = 0.3408 | logprob = -0.7092 | KL term = 0.15242330932617187\n",
      "Epoch 2060:         train accuracy = 0.3408 | logprob = -0.7059 | KL term = 0.15253799438476562\n",
      "Epoch 2080:         train accuracy = 0.3408 | logprob = -0.7027 | KL term = 0.1526515808105469\n",
      "Epoch 2100:         train accuracy = 0.3408 | logprob = -0.6998 | KL term = 0.15276414489746093\n",
      "Epoch 2120:         train accuracy = 0.3408 | logprob = -0.6971 | KL term = 0.15287564086914063\n",
      "Epoch 2140:         train accuracy = 0.3408 | logprob = -0.6946 | KL term = 0.1529861755371094\n",
      "Epoch 2160:         train accuracy = 0.3408 | logprob = -0.6922 | KL term = 0.15309571838378908\n",
      "Epoch 2180:         train accuracy = 0.3408 | logprob = -0.6900 | KL term = 0.15320419311523437\n",
      "Epoch 2200:         train accuracy = 0.3408 | logprob = -0.6881 | KL term = 0.15330929565429688\n",
      "Epoch 2220:         train accuracy = 0.3407 | logprob = -0.6865 | KL term = 0.15340908813476561\n",
      "Epoch 2240:         train accuracy = 0.3407 | logprob = -0.6851 | KL term = 0.15350373840332032\n",
      "Epoch 2260:         train accuracy = 0.3407 | logprob = -0.6839 | KL term = 0.15359371948242187\n",
      "Epoch 2280:         train accuracy = 0.3407 | logprob = -0.6828 | KL term = 0.15367947387695313\n",
      "Epoch 2300:         train accuracy = 0.3407 | logprob = -0.6820 | KL term = 0.15376138305664064\n",
      "Epoch 2320:         train accuracy = 0.3407 | logprob = -0.6812 | KL term = 0.15383981323242188\n",
      "Epoch 2340:         train accuracy = 0.3407 | logprob = -0.6805 | KL term = 0.1539149932861328\n",
      "Epoch 2360:         train accuracy = 0.3407 | logprob = -0.6800 | KL term = 0.15398727416992186\n",
      "Epoch 2380:         train accuracy = 0.3407 | logprob = -0.6794 | KL term = 0.15405682373046875\n",
      "Epoch 2400:         train accuracy = 0.3407 | logprob = -0.6790 | KL term = 0.15412388610839844\n",
      "Epoch 2420:         train accuracy = 0.3407 | logprob = -0.6786 | KL term = 0.15418861389160157\n",
      "Epoch 2440:         train accuracy = 0.3407 | logprob = -0.6783 | KL term = 0.15425119018554687\n",
      "Epoch 2460:         train accuracy = 0.3407 | logprob = -0.6780 | KL term = 0.1543117980957031\n",
      "Epoch 2480:         train accuracy = 0.3407 | logprob = -0.6777 | KL term = 0.15437054443359374\n",
      "Epoch 2500:         train accuracy = 0.3407 | logprob = -0.6774 | KL term = 0.15442758178710939\n",
      "Epoch 2520:         train accuracy = 0.3407 | logprob = -0.6772 | KL term = 0.15448300170898438\n",
      "Epoch 2540:         train accuracy = 0.3407 | logprob = -0.6770 | KL term = 0.15453695678710938\n",
      "Epoch 2560:         train accuracy = 0.3407 | logprob = -0.6768 | KL term = 0.15458950805664062\n",
      "Epoch 2580:         train accuracy = 0.3407 | logprob = -0.6767 | KL term = 0.15464077758789063\n",
      "Epoch 2600:         train accuracy = 0.3407 | logprob = -0.6765 | KL term = 0.15469085693359375\n",
      "Epoch 2620:         train accuracy = 0.3407 | logprob = -0.6764 | KL term = 0.15473980712890625\n",
      "Epoch 2640:         train accuracy = 0.3407 | logprob = -0.6762 | KL term = 0.15478770446777343\n",
      "Epoch 2660:         train accuracy = 0.3407 | logprob = -0.6761 | KL term = 0.15483462524414063\n",
      "Epoch 2680:         train accuracy = 0.3407 | logprob = -0.6760 | KL term = 0.15488059997558593\n",
      "Epoch 2700:         train accuracy = 0.3407 | logprob = -0.6759 | KL term = 0.15492572021484374\n",
      "Epoch 2720:         train accuracy = 0.3407 | logprob = -0.6758 | KL term = 0.15497004699707032\n",
      "Epoch 2740:         train accuracy = 0.3407 | logprob = -0.6757 | KL term = 0.1550136260986328\n",
      "Epoch 2760:         train accuracy = 0.3407 | logprob = -0.6756 | KL term = 0.15505650329589843\n",
      "Epoch 2780:         train accuracy = 0.3407 | logprob = -0.6755 | KL term = 0.15509870910644533\n",
      "Epoch 2800:         train accuracy = 0.3407 | logprob = -0.6754 | KL term = 0.15514031982421875\n",
      "Epoch 2820:         train accuracy = 0.3407 | logprob = -0.6753 | KL term = 0.15518133544921875\n",
      "Epoch 2840:         train accuracy = 0.3407 | logprob = -0.6752 | KL term = 0.15522181701660157\n",
      "Epoch 2860:         train accuracy = 0.3406 | logprob = -0.6751 | KL term = 0.1552617950439453\n",
      "Epoch 2880:         train accuracy = 0.3406 | logprob = -0.6751 | KL term = 0.15530131530761718\n",
      "Epoch 2900:         train accuracy = 0.3406 | logprob = -0.6750 | KL term = 0.1553403778076172\n",
      "Epoch 2920:         train accuracy = 0.3406 | logprob = -0.6749 | KL term = 0.15537901306152344\n",
      "Epoch 2940:         train accuracy = 0.3406 | logprob = -0.6748 | KL term = 0.15541725158691405\n",
      "Epoch 2960:         train accuracy = 0.3406 | logprob = -0.6747 | KL term = 0.15545512390136718\n",
      "Epoch 2980:         train accuracy = 0.3406 | logprob = -0.6747 | KL term = 0.15549261474609374\n",
      "Epoch 3000:         train accuracy = 0.3406 | logprob = -0.6746 | KL term = 0.15552978515625\n",
      "Epoch 3020:         train accuracy = 0.3406 | logprob = -0.6745 | KL term = 0.15556668090820314\n",
      "Epoch 3040:         train accuracy = 0.3406 | logprob = -0.6744 | KL term = 0.155603271484375\n",
      "Epoch 3060:         train accuracy = 0.3406 | logprob = -0.6744 | KL term = 0.15563958740234374\n",
      "Epoch 3080:         train accuracy = 0.3406 | logprob = -0.6743 | KL term = 0.15567562866210938\n",
      "Epoch 3100:         train accuracy = 0.3406 | logprob = -0.6742 | KL term = 0.15571142578125\n",
      "Epoch 3120:         train accuracy = 0.3406 | logprob = -0.6741 | KL term = 0.15574697875976562\n",
      "Epoch 3140:         train accuracy = 0.3406 | logprob = -0.6741 | KL term = 0.15578231811523438\n",
      "Epoch 3160:         train accuracy = 0.3406 | logprob = -0.6740 | KL term = 0.15581741333007812\n",
      "Epoch 3180:         train accuracy = 0.3406 | logprob = -0.6739 | KL term = 0.155852294921875\n",
      "Epoch 3200:         train accuracy = 0.3405 | logprob = -0.6738 | KL term = 0.155886962890625\n",
      "Epoch 3220:         train accuracy = 0.3405 | logprob = -0.6738 | KL term = 0.15592141723632813\n",
      "Epoch 3240:         train accuracy = 0.3405 | logprob = -0.6737 | KL term = 0.1559556884765625\n",
      "Epoch 3260:         train accuracy = 0.3405 | logprob = -0.6736 | KL term = 0.15598977661132812\n",
      "Epoch 3280:         train accuracy = 0.3405 | logprob = -0.6736 | KL term = 0.156023681640625\n",
      "Epoch 3300:         train accuracy = 0.3405 | logprob = -0.6735 | KL term = 0.1560574188232422\n",
      "Epoch 3320:         train accuracy = 0.3405 | logprob = -0.6734 | KL term = 0.15609095764160155\n",
      "Epoch 3340:         train accuracy = 0.3405 | logprob = -0.6733 | KL term = 0.15612432861328124\n",
      "Epoch 3360:         train accuracy = 0.3405 | logprob = -0.6733 | KL term = 0.15615750122070313\n",
      "Epoch 3380:         train accuracy = 0.3405 | logprob = -0.6732 | KL term = 0.15619053649902342\n",
      "Epoch 3400:         train accuracy = 0.3405 | logprob = -0.6731 | KL term = 0.156223388671875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3420:         train accuracy = 0.3404 | logprob = -0.6730 | KL term = 0.15625607299804686\n",
      "Epoch 3440:         train accuracy = 0.3404 | logprob = -0.6730 | KL term = 0.15628857421875\n",
      "Epoch 3460:         train accuracy = 0.3404 | logprob = -0.6729 | KL term = 0.15632095336914062\n",
      "Epoch 3480:         train accuracy = 0.3404 | logprob = -0.6728 | KL term = 0.15635311889648437\n",
      "Epoch 3500:         train accuracy = 0.3404 | logprob = -0.6727 | KL term = 0.15638516235351563\n",
      "Epoch 3520:         train accuracy = 0.3404 | logprob = -0.6727 | KL term = 0.15641702270507812\n",
      "Epoch 3540:         train accuracy = 0.3404 | logprob = -0.6726 | KL term = 0.15644871520996093\n",
      "Epoch 3560:         train accuracy = 0.3403 | logprob = -0.6725 | KL term = 0.15648025512695313\n",
      "Epoch 3580:         train accuracy = 0.3403 | logprob = -0.6724 | KL term = 0.15651162719726563\n",
      "Epoch 3600:         train accuracy = 0.3403 | logprob = -0.6724 | KL term = 0.1565428466796875\n",
      "Epoch 3620:         train accuracy = 0.3403 | logprob = -0.6723 | KL term = 0.15657388305664063\n",
      "Epoch 3640:         train accuracy = 0.3403 | logprob = -0.6722 | KL term = 0.15660479736328126\n",
      "Epoch 3660:         train accuracy = 0.3402 | logprob = -0.6721 | KL term = 0.15663552856445312\n",
      "Epoch 3680:         train accuracy = 0.3402 | logprob = -0.6720 | KL term = 0.15666610717773438\n",
      "Epoch 3700:         train accuracy = 0.3402 | logprob = -0.6720 | KL term = 0.15669654846191405\n",
      "Epoch 3720:         train accuracy = 0.3402 | logprob = -0.6719 | KL term = 0.15672683715820312\n",
      "Epoch 3740:         train accuracy = 0.3402 | logprob = -0.6718 | KL term = 0.1567569580078125\n",
      "Epoch 3760:         train accuracy = 0.3401 | logprob = -0.6717 | KL term = 0.15678692626953125\n",
      "Epoch 3780:         train accuracy = 0.3401 | logprob = -0.6716 | KL term = 0.1568167724609375\n",
      "Epoch 3800:         train accuracy = 0.3401 | logprob = -0.6715 | KL term = 0.15684649658203126\n",
      "Epoch 3820:         train accuracy = 0.3400 | logprob = -0.6714 | KL term = 0.15687608337402345\n",
      "Epoch 3840:         train accuracy = 0.3400 | logprob = -0.6714 | KL term = 0.15690559387207031\n",
      "Epoch 3860:         train accuracy = 0.3400 | logprob = -0.6713 | KL term = 0.15693498229980468\n",
      "Epoch 3880:         train accuracy = 0.3399 | logprob = -0.6712 | KL term = 0.15696427917480468\n",
      "Epoch 3900:         train accuracy = 0.3399 | logprob = -0.6711 | KL term = 0.15699349975585938\n",
      "Epoch 3920:         train accuracy = 0.3398 | logprob = -0.6710 | KL term = 0.1570226745605469\n",
      "Epoch 3940:         train accuracy = 0.3398 | logprob = -0.6709 | KL term = 0.15705178833007813\n",
      "Epoch 3960:         train accuracy = 0.3397 | logprob = -0.6707 | KL term = 0.15708091735839844\n",
      "Epoch 3980:         train accuracy = 0.3397 | logprob = -0.6706 | KL term = 0.15711004638671874\n",
      "Epoch 4000:         train accuracy = 0.3396 | logprob = -0.6705 | KL term = 0.1571392364501953\n",
      "Epoch 4020:         train accuracy = 0.3396 | logprob = -0.6704 | KL term = 0.15716851806640625\n",
      "Epoch 4040:         train accuracy = 0.3395 | logprob = -0.6702 | KL term = 0.15719796752929688\n",
      "Epoch 4060:         train accuracy = 0.3394 | logprob = -0.6701 | KL term = 0.15722760009765624\n",
      "Epoch 4080:         train accuracy = 0.3393 | logprob = -0.6700 | KL term = 0.15725750732421875\n",
      "Epoch 4100:         train accuracy = 0.3392 | logprob = -0.6698 | KL term = 0.15728778076171876\n",
      "Epoch 4120:         train accuracy = 0.3391 | logprob = -0.6696 | KL term = 0.15731846618652343\n",
      "Epoch 4140:         train accuracy = 0.3390 | logprob = -0.6695 | KL term = 0.15734976196289063\n",
      "Epoch 4160:         train accuracy = 0.3389 | logprob = -0.6693 | KL term = 0.15738174438476563\n",
      "Epoch 4180:         train accuracy = 0.3388 | logprob = -0.6691 | KL term = 0.15741458129882813\n",
      "Epoch 4200:         train accuracy = 0.3386 | logprob = -0.6689 | KL term = 0.157448486328125\n",
      "Epoch 4220:         train accuracy = 0.3385 | logprob = -0.6686 | KL term = 0.15748367309570313\n",
      "Epoch 4240:         train accuracy = 0.3383 | logprob = -0.6684 | KL term = 0.1575204315185547\n",
      "Epoch 4260:         train accuracy = 0.3381 | logprob = -0.6681 | KL term = 0.15755908203125\n",
      "Epoch 4280:         train accuracy = 0.3379 | logprob = -0.6677 | KL term = 0.15759999084472656\n",
      "Epoch 4300:         train accuracy = 0.3376 | logprob = -0.6674 | KL term = 0.15764370727539062\n",
      "Epoch 4320:         train accuracy = 0.3373 | logprob = -0.6670 | KL term = 0.15769073486328125\n",
      "Epoch 4340:         train accuracy = 0.3370 | logprob = -0.6666 | KL term = 0.15774176025390624\n",
      "Epoch 4360:         train accuracy = 0.3366 | logprob = -0.6661 | KL term = 0.15779754638671875\n",
      "Epoch 4380:         train accuracy = 0.3362 | logprob = -0.6655 | KL term = 0.1578590087890625\n",
      "Epoch 4400:         train accuracy = 0.3357 | logprob = -0.6649 | KL term = 0.15792710876464844\n",
      "Epoch 4420:         train accuracy = 0.3352 | logprob = -0.6642 | KL term = 0.15800296020507812\n",
      "Epoch 4440:         train accuracy = 0.3347 | logprob = -0.6635 | KL term = 0.15808770751953125\n",
      "Epoch 4460:         train accuracy = 0.3341 | logprob = -0.6626 | KL term = 0.15818243408203125\n",
      "Epoch 4480:         train accuracy = 0.3334 | logprob = -0.6617 | KL term = 0.15828814697265625\n",
      "Epoch 4500:         train accuracy = 0.3327 | logprob = -0.6607 | KL term = 0.15840550231933595\n",
      "Epoch 4520:         train accuracy = 0.3320 | logprob = -0.6596 | KL term = 0.15853485107421875\n",
      "Epoch 4540:         train accuracy = 0.3313 | logprob = -0.6584 | KL term = 0.15867608642578124\n",
      "Epoch 4560:         train accuracy = 0.3306 | logprob = -0.6572 | KL term = 0.15882859802246094\n",
      "Epoch 4580:         train accuracy = 0.3299 | logprob = -0.6559 | KL term = 0.15899137878417968\n",
      "Epoch 4600:         train accuracy = 0.3292 | logprob = -0.6546 | KL term = 0.15916310119628907\n",
      "Epoch 4620:         train accuracy = 0.3285 | logprob = -0.6532 | KL term = 0.15934219360351562\n",
      "Epoch 4640:         train accuracy = 0.3279 | logprob = -0.6519 | KL term = 0.15952694702148437\n",
      "Epoch 4660:         train accuracy = 0.3273 | logprob = -0.6505 | KL term = 0.15971568298339844\n",
      "Epoch 4680:         train accuracy = 0.3266 | logprob = -0.6491 | KL term = 0.15990670776367188\n",
      "Epoch 4700:         train accuracy = 0.3261 | logprob = -0.6478 | KL term = 0.16009852600097657\n",
      "Epoch 4720:         train accuracy = 0.3255 | logprob = -0.6465 | KL term = 0.16028976440429688\n",
      "Epoch 4740:         train accuracy = 0.3250 | logprob = -0.6452 | KL term = 0.16047930908203126\n",
      "Epoch 4760:         train accuracy = 0.3245 | logprob = -0.6439 | KL term = 0.16066629028320312\n",
      "Epoch 4780:         train accuracy = 0.3239 | logprob = -0.6426 | KL term = 0.16085009765625\n",
      "Epoch 4800:         train accuracy = 0.3234 | logprob = -0.6413 | KL term = 0.16103033447265624\n",
      "Epoch 4820:         train accuracy = 0.3228 | logprob = -0.6399 | KL term = 0.16120684814453126\n",
      "Epoch 4840:         train accuracy = 0.3222 | logprob = -0.6386 | KL term = 0.16137969970703125\n",
      "Epoch 4860:         train accuracy = 0.3216 | logprob = -0.6372 | KL term = 0.1615491943359375\n",
      "Epoch 4880:         train accuracy = 0.3210 | logprob = -0.6357 | KL term = 0.1617158508300781\n",
      "Epoch 4900:         train accuracy = 0.3203 | logprob = -0.6342 | KL term = 0.16188035583496094\n",
      "Epoch 4920:         train accuracy = 0.3195 | logprob = -0.6326 | KL term = 0.1620436553955078\n",
      "Epoch 4940:         train accuracy = 0.3187 | logprob = -0.6308 | KL term = 0.16220698547363283\n",
      "Epoch 4960:         train accuracy = 0.3178 | logprob = -0.6289 | KL term = 0.162371826171875\n",
      "Epoch 4980:         train accuracy = 0.3169 | logprob = -0.6269 | KL term = 0.1625400390625\n",
      "Epoch 5000:         train accuracy = 0.3158 | logprob = -0.6246 | KL term = 0.16271395874023437\n",
      "Epoch 5020:         train accuracy = 0.3147 | logprob = -0.6221 | KL term = 0.16289627075195312\n",
      "Epoch 5040:         train accuracy = 0.3134 | logprob = -0.6193 | KL term = 0.16309039306640624\n",
      "Epoch 5060:         train accuracy = 0.3121 | logprob = -0.6162 | KL term = 0.16330026245117188\n",
      "Epoch 5080:         train accuracy = 0.3106 | logprob = -0.6127 | KL term = 0.16353048706054688\n",
      "Epoch 5100:         train accuracy = 0.3091 | logprob = -0.6087 | KL term = 0.163786376953125\n",
      "Epoch 5120:         train accuracy = 0.3074 | logprob = -0.6043 | KL term = 0.16407350158691406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5140:         train accuracy = 0.3056 | logprob = -0.5993 | KL term = 0.16439768981933595\n",
      "Epoch 5160:         train accuracy = 0.3038 | logprob = -0.5938 | KL term = 0.16476429748535157\n",
      "Epoch 5180:         train accuracy = 0.3019 | logprob = -0.5877 | KL term = 0.16517770385742186\n",
      "Epoch 5200:         train accuracy = 0.3001 | logprob = -0.5812 | KL term = 0.16564053344726562\n",
      "Epoch 5220:         train accuracy = 0.2984 | logprob = -0.5742 | KL term = 0.16615322875976563\n",
      "Epoch 5240:         train accuracy = 0.2971 | logprob = -0.5670 | KL term = 0.16671368408203124\n",
      "Epoch 5260:         train accuracy = 0.2961 | logprob = -0.5597 | KL term = 0.16731747436523436\n",
      "Epoch 5280:         train accuracy = 0.2952 | logprob = -0.5524 | KL term = 0.16795826721191406\n",
      "Epoch 5300:         train accuracy = 0.2946 | logprob = -0.5452 | KL term = 0.16862864685058593\n",
      "Epoch 5320:         train accuracy = 0.2942 | logprob = -0.5382 | KL term = 0.169320556640625\n",
      "Epoch 5340:         train accuracy = 0.2939 | logprob = -0.5315 | KL term = 0.17002615356445314\n",
      "Epoch 5360:         train accuracy = 0.2936 | logprob = -0.5252 | KL term = 0.17073812866210938\n",
      "Epoch 5380:         train accuracy = 0.2933 | logprob = -0.5192 | KL term = 0.17144992065429687\n",
      "Epoch 5400:         train accuracy = 0.2931 | logprob = -0.5135 | KL term = 0.17215597534179689\n",
      "Epoch 5420:         train accuracy = 0.2929 | logprob = -0.5082 | KL term = 0.17285186767578126\n",
      "Epoch 5440:         train accuracy = 0.2928 | logprob = -0.5033 | KL term = 0.1735340576171875\n",
      "Epoch 5460:         train accuracy = 0.2927 | logprob = -0.4987 | KL term = 0.17419992065429687\n",
      "Epoch 5480:         train accuracy = 0.2926 | logprob = -0.4945 | KL term = 0.17484768676757811\n",
      "Epoch 5500:         train accuracy = 0.2925 | logprob = -0.4906 | KL term = 0.17547625732421876\n",
      "Epoch 5520:         train accuracy = 0.2924 | logprob = -0.4871 | KL term = 0.1760850830078125\n",
      "Epoch 5540:         train accuracy = 0.2924 | logprob = -0.4839 | KL term = 0.176674072265625\n",
      "Epoch 5560:         train accuracy = 0.2924 | logprob = -0.4809 | KL term = 0.17724346923828124\n",
      "Epoch 5580:         train accuracy = 0.2923 | logprob = -0.4782 | KL term = 0.17779376220703125\n",
      "Epoch 5600:         train accuracy = 0.2923 | logprob = -0.4757 | KL term = 0.1783255920410156\n",
      "Epoch 5620:         train accuracy = 0.2922 | logprob = -0.4733 | KL term = 0.17883978271484374\n",
      "Epoch 5640:         train accuracy = 0.2922 | logprob = -0.4712 | KL term = 0.17933712768554688\n",
      "Epoch 5660:         train accuracy = 0.2922 | logprob = -0.4692 | KL term = 0.1798184814453125\n",
      "Epoch 5680:         train accuracy = 0.2922 | logprob = -0.4673 | KL term = 0.18028471374511718\n",
      "Epoch 5700:         train accuracy = 0.2922 | logprob = -0.4656 | KL term = 0.18073660278320314\n",
      "Epoch 5720:         train accuracy = 0.2921 | logprob = -0.4640 | KL term = 0.18117498779296876\n",
      "Epoch 5740:         train accuracy = 0.2921 | logprob = -0.4624 | KL term = 0.18160064697265624\n",
      "Epoch 5760:         train accuracy = 0.2921 | logprob = -0.4610 | KL term = 0.1820142822265625\n",
      "Epoch 5780:         train accuracy = 0.2921 | logprob = -0.4596 | KL term = 0.1824165802001953\n",
      "Epoch 5800:         train accuracy = 0.2920 | logprob = -0.4583 | KL term = 0.18280821228027344\n",
      "Epoch 5820:         train accuracy = 0.2920 | logprob = -0.4570 | KL term = 0.1831897735595703\n",
      "Epoch 5840:         train accuracy = 0.2920 | logprob = -0.4559 | KL term = 0.18356185913085937\n",
      "Epoch 5860:         train accuracy = 0.2920 | logprob = -0.4547 | KL term = 0.18392500305175782\n",
      "Epoch 5880:         train accuracy = 0.2920 | logprob = -0.4537 | KL term = 0.18427969360351562\n",
      "Epoch 5900:         train accuracy = 0.2920 | logprob = -0.4526 | KL term = 0.18462646484375\n",
      "Epoch 5920:         train accuracy = 0.2920 | logprob = -0.4517 | KL term = 0.1849656982421875\n",
      "Epoch 5940:         train accuracy = 0.2920 | logprob = -0.4507 | KL term = 0.18529782104492187\n",
      "Epoch 5960:         train accuracy = 0.2920 | logprob = -0.4498 | KL term = 0.18562326049804687\n",
      "Epoch 5980:         train accuracy = 0.2920 | logprob = -0.4489 | KL term = 0.18594229125976564\n",
      "Epoch 6000:         train accuracy = 0.2920 | logprob = -0.4481 | KL term = 0.18625537109375\n",
      "Epoch 6020:         train accuracy = 0.2920 | logprob = -0.4473 | KL term = 0.18656268310546875\n",
      "Epoch 6040:         train accuracy = 0.2920 | logprob = -0.4465 | KL term = 0.1868645782470703\n",
      "Epoch 6060:         train accuracy = 0.2920 | logprob = -0.4458 | KL term = 0.18716133117675782\n",
      "Epoch 6080:         train accuracy = 0.2920 | logprob = -0.4451 | KL term = 0.18745315551757813\n",
      "Epoch 6100:         train accuracy = 0.2920 | logprob = -0.4444 | KL term = 0.1877403106689453\n",
      "Epoch 6120:         train accuracy = 0.2920 | logprob = -0.4437 | KL term = 0.18802301025390625\n",
      "Epoch 6140:         train accuracy = 0.2920 | logprob = -0.4431 | KL term = 0.18830145263671874\n",
      "Epoch 6160:         train accuracy = 0.2920 | logprob = -0.4425 | KL term = 0.1885758056640625\n",
      "Epoch 6180:         train accuracy = 0.2921 | logprob = -0.4419 | KL term = 0.1888462371826172\n",
      "Epoch 6200:         train accuracy = 0.2921 | logprob = -0.4413 | KL term = 0.18911293029785156\n",
      "Epoch 6220:         train accuracy = 0.2921 | logprob = -0.4407 | KL term = 0.18937600708007812\n",
      "Epoch 6240:         train accuracy = 0.2921 | logprob = -0.4402 | KL term = 0.1896356201171875\n",
      "Epoch 6260:         train accuracy = 0.2921 | logprob = -0.4397 | KL term = 0.18989190673828124\n",
      "Epoch 6280:         train accuracy = 0.2921 | logprob = -0.4392 | KL term = 0.19014498901367188\n",
      "Epoch 6300:         train accuracy = 0.2921 | logprob = -0.4387 | KL term = 0.19039495849609375\n",
      "Epoch 6320:         train accuracy = 0.2921 | logprob = -0.4382 | KL term = 0.19064193725585937\n",
      "Epoch 6340:         train accuracy = 0.2921 | logprob = -0.4377 | KL term = 0.19088601684570314\n",
      "Epoch 6360:         train accuracy = 0.2921 | logprob = -0.4373 | KL term = 0.1911272888183594\n",
      "Epoch 6380:         train accuracy = 0.2921 | logprob = -0.4368 | KL term = 0.1913658447265625\n",
      "Epoch 6400:         train accuracy = 0.2921 | logprob = -0.4364 | KL term = 0.191601806640625\n",
      "Epoch 6420:         train accuracy = 0.2921 | logprob = -0.4360 | KL term = 0.191835205078125\n",
      "Epoch 6440:         train accuracy = 0.2922 | logprob = -0.4356 | KL term = 0.19206613159179686\n",
      "Epoch 6460:         train accuracy = 0.2922 | logprob = -0.4352 | KL term = 0.19229466247558594\n",
      "Epoch 6480:         train accuracy = 0.2922 | logprob = -0.4348 | KL term = 0.19252085876464844\n",
      "Epoch 6500:         train accuracy = 0.2922 | logprob = -0.4345 | KL term = 0.19274481201171875\n",
      "Epoch 6520:         train accuracy = 0.2922 | logprob = -0.4341 | KL term = 0.192966552734375\n",
      "Epoch 6540:         train accuracy = 0.2922 | logprob = -0.4338 | KL term = 0.1931861572265625\n",
      "Epoch 6560:         train accuracy = 0.2922 | logprob = -0.4334 | KL term = 0.1934036865234375\n",
      "Epoch 6580:         train accuracy = 0.2922 | logprob = -0.4331 | KL term = 0.19361920166015625\n",
      "Epoch 6600:         train accuracy = 0.2922 | logprob = -0.4328 | KL term = 0.19383270263671876\n",
      "Epoch 6620:         train accuracy = 0.2922 | logprob = -0.4325 | KL term = 0.1940443115234375\n",
      "Epoch 6640:         train accuracy = 0.2922 | logprob = -0.4322 | KL term = 0.19425404357910156\n",
      "Epoch 6660:         train accuracy = 0.2923 | logprob = -0.4319 | KL term = 0.1944619598388672\n",
      "Epoch 6680:         train accuracy = 0.2923 | logprob = -0.4316 | KL term = 0.1946680908203125\n",
      "Epoch 6700:         train accuracy = 0.2923 | logprob = -0.4313 | KL term = 0.19487249755859376\n",
      "Epoch 6720:         train accuracy = 0.2923 | logprob = -0.4310 | KL term = 0.1950751953125\n",
      "Epoch 6740:         train accuracy = 0.2923 | logprob = -0.4308 | KL term = 0.19527622985839843\n",
      "Epoch 6760:         train accuracy = 0.2923 | logprob = -0.4305 | KL term = 0.19547567749023437\n",
      "Epoch 6780:         train accuracy = 0.2923 | logprob = -0.4303 | KL term = 0.1956735382080078\n",
      "Epoch 6800:         train accuracy = 0.2923 | logprob = -0.4300 | KL term = 0.19586984252929687\n",
      "Epoch 6820:         train accuracy = 0.2923 | logprob = -0.4298 | KL term = 0.196064697265625\n",
      "Epoch 6840:         train accuracy = 0.2923 | logprob = -0.4295 | KL term = 0.19625807189941405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6860:         train accuracy = 0.2924 | logprob = -0.4293 | KL term = 0.19645001220703126\n",
      "Epoch 6880:         train accuracy = 0.2924 | logprob = -0.4291 | KL term = 0.19664057922363282\n",
      "Epoch 6900:         train accuracy = 0.2924 | logprob = -0.4289 | KL term = 0.19682977294921875\n",
      "Epoch 6920:         train accuracy = 0.2924 | logprob = -0.4286 | KL term = 0.19701762390136718\n",
      "Epoch 6940:         train accuracy = 0.2924 | logprob = -0.4284 | KL term = 0.19720416259765625\n",
      "Epoch 6960:         train accuracy = 0.2924 | logprob = -0.4282 | KL term = 0.19738946533203125\n",
      "Epoch 6980:         train accuracy = 0.2924 | logprob = -0.4280 | KL term = 0.197573486328125\n",
      "Epoch 7000:         train accuracy = 0.2924 | logprob = -0.4278 | KL term = 0.19775628662109376\n",
      "Epoch 7020:         train accuracy = 0.2924 | logprob = -0.4276 | KL term = 0.19793792724609374\n",
      "Epoch 7040:         train accuracy = 0.2924 | logprob = -0.4274 | KL term = 0.19811837768554688\n",
      "Epoch 7060:         train accuracy = 0.2924 | logprob = -0.4272 | KL term = 0.1982976989746094\n",
      "Epoch 7080:         train accuracy = 0.2924 | logprob = -0.4271 | KL term = 0.19847589111328126\n",
      "Epoch 7100:         train accuracy = 0.2924 | logprob = -0.4269 | KL term = 0.19865298461914063\n",
      "Epoch 7120:         train accuracy = 0.2924 | logprob = -0.4267 | KL term = 0.1988290557861328\n",
      "Epoch 7140:         train accuracy = 0.2925 | logprob = -0.4265 | KL term = 0.19900404357910156\n",
      "Epoch 7160:         train accuracy = 0.2925 | logprob = -0.4264 | KL term = 0.19917800903320312\n",
      "Epoch 7180:         train accuracy = 0.2925 | logprob = -0.4262 | KL term = 0.1993509826660156\n",
      "Epoch 7200:         train accuracy = 0.2925 | logprob = -0.4260 | KL term = 0.1995229949951172\n",
      "Epoch 7220:         train accuracy = 0.2925 | logprob = -0.4259 | KL term = 0.19969403076171874\n",
      "Epoch 7240:         train accuracy = 0.2925 | logprob = -0.4257 | KL term = 0.1998641357421875\n",
      "Epoch 7260:         train accuracy = 0.2925 | logprob = -0.4256 | KL term = 0.20003330993652343\n",
      "Epoch 7280:         train accuracy = 0.2925 | logprob = -0.4254 | KL term = 0.20020159912109375\n",
      "Epoch 7300:         train accuracy = 0.2925 | logprob = -0.4253 | KL term = 0.2003690185546875\n",
      "Epoch 7320:         train accuracy = 0.2925 | logprob = -0.4251 | KL term = 0.20053555297851564\n",
      "Epoch 7340:         train accuracy = 0.2925 | logprob = -0.4250 | KL term = 0.2007012176513672\n",
      "Epoch 7360:         train accuracy = 0.2925 | logprob = -0.4249 | KL term = 0.2008660888671875\n",
      "Epoch 7380:         train accuracy = 0.2925 | logprob = -0.4247 | KL term = 0.20103012084960936\n",
      "Epoch 7400:         train accuracy = 0.2925 | logprob = -0.4246 | KL term = 0.20119334411621093\n",
      "Epoch 7420:         train accuracy = 0.2925 | logprob = -0.4245 | KL term = 0.20135580444335938\n",
      "Epoch 7440:         train accuracy = 0.2925 | logprob = -0.4243 | KL term = 0.20151748657226562\n",
      "Epoch 7460:         train accuracy = 0.2925 | logprob = -0.4242 | KL term = 0.20167843627929688\n",
      "Epoch 7480:         train accuracy = 0.2925 | logprob = -0.4241 | KL term = 0.201838623046875\n",
      "Epoch 7500:         train accuracy = 0.2926 | logprob = -0.4240 | KL term = 0.20199807739257813\n",
      "Epoch 7520:         train accuracy = 0.2926 | logprob = -0.4239 | KL term = 0.2021568603515625\n",
      "Epoch 7540:         train accuracy = 0.2926 | logprob = -0.4237 | KL term = 0.20231492614746094\n",
      "Epoch 7560:         train accuracy = 0.2926 | logprob = -0.4236 | KL term = 0.20247232055664063\n",
      "Epoch 7580:         train accuracy = 0.2926 | logprob = -0.4235 | KL term = 0.2026290283203125\n",
      "Epoch 7600:         train accuracy = 0.2926 | logprob = -0.4234 | KL term = 0.20278509521484375\n",
      "Epoch 7620:         train accuracy = 0.2926 | logprob = -0.4233 | KL term = 0.20294049072265624\n",
      "Epoch 7640:         train accuracy = 0.2926 | logprob = -0.4232 | KL term = 0.20309526062011718\n",
      "Epoch 7660:         train accuracy = 0.2926 | logprob = -0.4231 | KL term = 0.20324940490722657\n",
      "Epoch 7680:         train accuracy = 0.2926 | logprob = -0.4230 | KL term = 0.2034029541015625\n",
      "Epoch 7700:         train accuracy = 0.2926 | logprob = -0.4229 | KL term = 0.20355589294433593\n",
      "Epoch 7720:         train accuracy = 0.2926 | logprob = -0.4228 | KL term = 0.203708251953125\n",
      "Epoch 7740:         train accuracy = 0.2926 | logprob = -0.4227 | KL term = 0.20386001586914063\n",
      "Epoch 7760:         train accuracy = 0.2926 | logprob = -0.4226 | KL term = 0.20401123046875\n",
      "Epoch 7780:         train accuracy = 0.2926 | logprob = -0.4225 | KL term = 0.20416184997558592\n",
      "Epoch 7800:         train accuracy = 0.2926 | logprob = -0.4224 | KL term = 0.20431195068359376\n",
      "Epoch 7820:         train accuracy = 0.2926 | logprob = -0.4223 | KL term = 0.20446151733398438\n",
      "Epoch 7840:         train accuracy = 0.2926 | logprob = -0.4222 | KL term = 0.20461053466796875\n",
      "Epoch 7860:         train accuracy = 0.2926 | logprob = -0.4221 | KL term = 0.20475904846191406\n",
      "Epoch 7880:         train accuracy = 0.2926 | logprob = -0.4220 | KL term = 0.20490705871582032\n",
      "Epoch 7900:         train accuracy = 0.2926 | logprob = -0.4219 | KL term = 0.2050545654296875\n",
      "Epoch 7920:         train accuracy = 0.2926 | logprob = -0.4219 | KL term = 0.2052015380859375\n",
      "Epoch 7940:         train accuracy = 0.2926 | logprob = -0.4218 | KL term = 0.2053480682373047\n",
      "Epoch 7960:         train accuracy = 0.2926 | logprob = -0.4217 | KL term = 0.20549411010742188\n",
      "Epoch 7980:         train accuracy = 0.2926 | logprob = -0.4216 | KL term = 0.20563967895507812\n",
      "Epoch 8000:         train accuracy = 0.2926 | logprob = -0.4215 | KL term = 0.20578477478027343\n",
      "Epoch 8020:         train accuracy = 0.2927 | logprob = -0.4215 | KL term = 0.2059294128417969\n",
      "Epoch 8040:         train accuracy = 0.2927 | logprob = -0.4214 | KL term = 0.20607363891601563\n",
      "Epoch 8060:         train accuracy = 0.2927 | logprob = -0.4213 | KL term = 0.20621739196777344\n",
      "Epoch 8080:         train accuracy = 0.2927 | logprob = -0.4212 | KL term = 0.20636074829101564\n",
      "Epoch 8100:         train accuracy = 0.2927 | logprob = -0.4211 | KL term = 0.20650364685058595\n",
      "Epoch 8120:         train accuracy = 0.2927 | logprob = -0.4211 | KL term = 0.2066461639404297\n",
      "Epoch 8140:         train accuracy = 0.2927 | logprob = -0.4210 | KL term = 0.20678826904296874\n",
      "Epoch 8160:         train accuracy = 0.2927 | logprob = -0.4209 | KL term = 0.2069299621582031\n",
      "Epoch 8180:         train accuracy = 0.2927 | logprob = -0.4209 | KL term = 0.20707125854492187\n",
      "Epoch 8200:         train accuracy = 0.2927 | logprob = -0.4208 | KL term = 0.20721214294433593\n",
      "Epoch 8220:         train accuracy = 0.2927 | logprob = -0.4207 | KL term = 0.2073526611328125\n",
      "Epoch 8240:         train accuracy = 0.2927 | logprob = -0.4207 | KL term = 0.2074927978515625\n",
      "Epoch 8260:         train accuracy = 0.2927 | logprob = -0.4206 | KL term = 0.207632568359375\n",
      "Epoch 8280:         train accuracy = 0.2927 | logprob = -0.4205 | KL term = 0.20777197265625\n",
      "Epoch 8300:         train accuracy = 0.2927 | logprob = -0.4205 | KL term = 0.2079110107421875\n",
      "Epoch 8320:         train accuracy = 0.2927 | logprob = -0.4204 | KL term = 0.20804969787597657\n",
      "Epoch 8340:         train accuracy = 0.2927 | logprob = -0.4203 | KL term = 0.20818801879882812\n",
      "Epoch 8360:         train accuracy = 0.2927 | logprob = -0.4203 | KL term = 0.20832603454589843\n",
      "Epoch 8380:         train accuracy = 0.2927 | logprob = -0.4202 | KL term = 0.2084636688232422\n",
      "Epoch 8400:         train accuracy = 0.2927 | logprob = -0.4202 | KL term = 0.2086009979248047\n",
      "Epoch 8420:         train accuracy = 0.2927 | logprob = -0.4201 | KL term = 0.20873800659179687\n",
      "Epoch 8440:         train accuracy = 0.2927 | logprob = -0.4200 | KL term = 0.20887466430664062\n",
      "Epoch 8460:         train accuracy = 0.2927 | logprob = -0.4200 | KL term = 0.20901100158691407\n",
      "Epoch 8480:         train accuracy = 0.2927 | logprob = -0.4199 | KL term = 0.20914703369140625\n",
      "Epoch 8500:         train accuracy = 0.2927 | logprob = -0.4199 | KL term = 0.20928277587890626\n",
      "Epoch 8520:         train accuracy = 0.2927 | logprob = -0.4198 | KL term = 0.20941819763183595\n",
      "Epoch 8540:         train accuracy = 0.2927 | logprob = -0.4198 | KL term = 0.20955332946777344\n",
      "Epoch 8560:         train accuracy = 0.2927 | logprob = -0.4197 | KL term = 0.20968815612792968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8580:         train accuracy = 0.2927 | logprob = -0.4197 | KL term = 0.20982270812988282\n",
      "Epoch 8600:         train accuracy = 0.2927 | logprob = -0.4196 | KL term = 0.20995700073242188\n",
      "Epoch 8620:         train accuracy = 0.2927 | logprob = -0.4196 | KL term = 0.21009097290039064\n",
      "Epoch 8640:         train accuracy = 0.2927 | logprob = -0.4195 | KL term = 0.21022470092773438\n",
      "Epoch 8660:         train accuracy = 0.2927 | logprob = -0.4195 | KL term = 0.21035813903808595\n",
      "Epoch 8680:         train accuracy = 0.2927 | logprob = -0.4194 | KL term = 0.21049130249023437\n",
      "Epoch 8700:         train accuracy = 0.2927 | logprob = -0.4194 | KL term = 0.2106242218017578\n",
      "Epoch 8720:         train accuracy = 0.2927 | logprob = -0.4193 | KL term = 0.21075689697265626\n",
      "Epoch 8740:         train accuracy = 0.2927 | logprob = -0.4193 | KL term = 0.21088926696777344\n",
      "Epoch 8760:         train accuracy = 0.2927 | logprob = -0.4192 | KL term = 0.21102142333984375\n",
      "Epoch 8780:         train accuracy = 0.2927 | logprob = -0.4192 | KL term = 0.21115330505371094\n",
      "Epoch 8800:         train accuracy = 0.2927 | logprob = -0.4191 | KL term = 0.21128494262695313\n",
      "Epoch 8820:         train accuracy = 0.2927 | logprob = -0.4191 | KL term = 0.21141635131835937\n",
      "Epoch 8840:         train accuracy = 0.2927 | logprob = -0.4190 | KL term = 0.2115474853515625\n",
      "Epoch 8860:         train accuracy = 0.2927 | logprob = -0.4190 | KL term = 0.21167840576171876\n",
      "Epoch 8880:         train accuracy = 0.2927 | logprob = -0.4190 | KL term = 0.21180909729003905\n",
      "Epoch 8900:         train accuracy = 0.2927 | logprob = -0.4189 | KL term = 0.21193954467773438\n",
      "Epoch 8920:         train accuracy = 0.2927 | logprob = -0.4189 | KL term = 0.21206976318359375\n",
      "Epoch 8940:         train accuracy = 0.2928 | logprob = -0.4188 | KL term = 0.21219976806640625\n",
      "Epoch 8960:         train accuracy = 0.2928 | logprob = -0.4188 | KL term = 0.21232957458496093\n",
      "Epoch 8980:         train accuracy = 0.2928 | logprob = -0.4188 | KL term = 0.21245913696289062\n",
      "Epoch 9000:         train accuracy = 0.2928 | logprob = -0.4187 | KL term = 0.21258848571777345\n",
      "Epoch 9020:         train accuracy = 0.2928 | logprob = -0.4187 | KL term = 0.21271763610839844\n",
      "Epoch 9040:         train accuracy = 0.2928 | logprob = -0.4186 | KL term = 0.21284658813476562\n",
      "Epoch 9060:         train accuracy = 0.2928 | logprob = -0.4186 | KL term = 0.21297532653808593\n",
      "Epoch 9080:         train accuracy = 0.2928 | logprob = -0.4186 | KL term = 0.21310385131835938\n",
      "Epoch 9100:         train accuracy = 0.2928 | logprob = -0.4185 | KL term = 0.213232177734375\n",
      "Epoch 9120:         train accuracy = 0.2928 | logprob = -0.4185 | KL term = 0.2133603515625\n",
      "Epoch 9140:         train accuracy = 0.2928 | logprob = -0.4185 | KL term = 0.21348834228515626\n",
      "Epoch 9160:         train accuracy = 0.2928 | logprob = -0.4184 | KL term = 0.21361611938476563\n",
      "Epoch 9180:         train accuracy = 0.2928 | logprob = -0.4184 | KL term = 0.21374371337890624\n",
      "Epoch 9200:         train accuracy = 0.2928 | logprob = -0.4183 | KL term = 0.21387112426757812\n",
      "Epoch 9220:         train accuracy = 0.2928 | logprob = -0.4183 | KL term = 0.21399833679199218\n",
      "Epoch 9240:         train accuracy = 0.2928 | logprob = -0.4183 | KL term = 0.21412538146972657\n",
      "Epoch 9260:         train accuracy = 0.2928 | logprob = -0.4182 | KL term = 0.21425222778320313\n",
      "Epoch 9280:         train accuracy = 0.2928 | logprob = -0.4182 | KL term = 0.21437890625\n",
      "Epoch 9300:         train accuracy = 0.2928 | logprob = -0.4182 | KL term = 0.21450541687011718\n",
      "Epoch 9320:         train accuracy = 0.2928 | logprob = -0.4181 | KL term = 0.21463177490234375\n",
      "Epoch 9340:         train accuracy = 0.2928 | logprob = -0.4181 | KL term = 0.2147579345703125\n",
      "Epoch 9360:         train accuracy = 0.2928 | logprob = -0.4181 | KL term = 0.21488394165039063\n",
      "Epoch 9380:         train accuracy = 0.2928 | logprob = -0.4180 | KL term = 0.21500979614257812\n",
      "Epoch 9400:         train accuracy = 0.2928 | logprob = -0.4180 | KL term = 0.21513546752929688\n",
      "Epoch 9420:         train accuracy = 0.2928 | logprob = -0.4180 | KL term = 0.21526097106933595\n",
      "Epoch 9440:         train accuracy = 0.2928 | logprob = -0.4180 | KL term = 0.2153863220214844\n",
      "Epoch 9460:         train accuracy = 0.2928 | logprob = -0.4179 | KL term = 0.21551150512695313\n",
      "Epoch 9480:         train accuracy = 0.2928 | logprob = -0.4179 | KL term = 0.21563656616210938\n",
      "Epoch 9500:         train accuracy = 0.2928 | logprob = -0.4179 | KL term = 0.21576145935058594\n",
      "Epoch 9520:         train accuracy = 0.2928 | logprob = -0.4178 | KL term = 0.21588621520996093\n",
      "Epoch 9540:         train accuracy = 0.2928 | logprob = -0.4178 | KL term = 0.21601081848144532\n",
      "Epoch 9560:         train accuracy = 0.2928 | logprob = -0.4178 | KL term = 0.21613528442382812\n",
      "Epoch 9580:         train accuracy = 0.2928 | logprob = -0.4178 | KL term = 0.2162595672607422\n",
      "Epoch 9600:         train accuracy = 0.2928 | logprob = -0.4177 | KL term = 0.21638375854492187\n",
      "Epoch 9620:         train accuracy = 0.2928 | logprob = -0.4177 | KL term = 0.21650778198242188\n",
      "Epoch 9640:         train accuracy = 0.2928 | logprob = -0.4177 | KL term = 0.2166316833496094\n",
      "Epoch 9660:         train accuracy = 0.2928 | logprob = -0.4176 | KL term = 0.21675543212890624\n",
      "Epoch 9680:         train accuracy = 0.2928 | logprob = -0.4176 | KL term = 0.2168790740966797\n",
      "Epoch 9700:         train accuracy = 0.2928 | logprob = -0.4176 | KL term = 0.21700254821777343\n",
      "Epoch 9720:         train accuracy = 0.2928 | logprob = -0.4176 | KL term = 0.21712591552734375\n",
      "Epoch 9740:         train accuracy = 0.2928 | logprob = -0.4175 | KL term = 0.2172491455078125\n",
      "Epoch 9760:         train accuracy = 0.2928 | logprob = -0.4175 | KL term = 0.21737225341796876\n",
      "Epoch 9780:         train accuracy = 0.2928 | logprob = -0.4175 | KL term = 0.2174952392578125\n",
      "Epoch 9800:         train accuracy = 0.2928 | logprob = -0.4175 | KL term = 0.21761807250976561\n",
      "Epoch 9820:         train accuracy = 0.2928 | logprob = -0.4174 | KL term = 0.21774081420898436\n",
      "Epoch 9840:         train accuracy = 0.2928 | logprob = -0.4174 | KL term = 0.2178634033203125\n",
      "Epoch 9860:         train accuracy = 0.2928 | logprob = -0.4174 | KL term = 0.2179858856201172\n",
      "Epoch 9880:         train accuracy = 0.2928 | logprob = -0.4174 | KL term = 0.21810824584960936\n",
      "Epoch 9900:         train accuracy = 0.2928 | logprob = -0.4174 | KL term = 0.21823048400878906\n",
      "Epoch 9920:         train accuracy = 0.2928 | logprob = -0.4173 | KL term = 0.21835256958007812\n",
      "Epoch 9940:         train accuracy = 0.2928 | logprob = -0.4173 | KL term = 0.218474609375\n",
      "Epoch 9960:         train accuracy = 0.2928 | logprob = -0.4173 | KL term = 0.21859649658203126\n",
      "Epoch 9980:         train accuracy = 0.2928 | logprob = -0.4173 | KL term = 0.21871826171875\n",
      "Epoch 10000:         train accuracy = 0.2928 | logprob = -0.4172 | KL term = 0.21883995056152344\n",
      "Epoch 10020:         train accuracy = 0.2928 | logprob = -0.4172 | KL term = 0.21896151733398436\n",
      "Epoch 10040:         train accuracy = 0.2928 | logprob = -0.4172 | KL term = 0.21908297729492188\n",
      "Epoch 10060:         train accuracy = 0.2928 | logprob = -0.4172 | KL term = 0.21920431518554687\n",
      "Epoch 10080:         train accuracy = 0.2928 | logprob = -0.4172 | KL term = 0.2193255615234375\n",
      "Epoch 10100:         train accuracy = 0.2928 | logprob = -0.4171 | KL term = 0.21944671630859375\n",
      "Epoch 10120:         train accuracy = 0.2928 | logprob = -0.4171 | KL term = 0.2195677795410156\n",
      "Epoch 10140:         train accuracy = 0.2928 | logprob = -0.4171 | KL term = 0.21968875122070314\n",
      "Epoch 10160:         train accuracy = 0.2928 | logprob = -0.4171 | KL term = 0.2198096008300781\n",
      "Epoch 10180:         train accuracy = 0.2928 | logprob = -0.4171 | KL term = 0.21993035888671875\n",
      "Epoch 10200:         train accuracy = 0.2928 | logprob = -0.4170 | KL term = 0.22005099487304688\n",
      "Epoch 10220:         train accuracy = 0.2928 | logprob = -0.4170 | KL term = 0.22017153930664063\n",
      "Epoch 10240:         train accuracy = 0.2928 | logprob = -0.4170 | KL term = 0.2202919921875\n",
      "Epoch 10260:         train accuracy = 0.2928 | logprob = -0.4170 | KL term = 0.220412353515625\n",
      "Epoch 10280:         train accuracy = 0.2928 | logprob = -0.4170 | KL term = 0.2205326232910156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10300:         train accuracy = 0.2928 | logprob = -0.4169 | KL term = 0.22065280151367186\n",
      "Epoch 10320:         train accuracy = 0.2928 | logprob = -0.4169 | KL term = 0.22077290344238282\n",
      "Epoch 10340:         train accuracy = 0.2928 | logprob = -0.4169 | KL term = 0.22089288330078125\n",
      "Epoch 10360:         train accuracy = 0.2928 | logprob = -0.4169 | KL term = 0.2210127716064453\n",
      "Epoch 10380:         train accuracy = 0.2928 | logprob = -0.4169 | KL term = 0.22113258361816407\n",
      "Epoch 10400:         train accuracy = 0.2928 | logprob = -0.4169 | KL term = 0.22125228881835937\n",
      "Epoch 10420:         train accuracy = 0.2928 | logprob = -0.4168 | KL term = 0.22137191772460937\n",
      "Epoch 10440:         train accuracy = 0.2929 | logprob = -0.4168 | KL term = 0.221491455078125\n",
      "Epoch 10460:         train accuracy = 0.2929 | logprob = -0.4168 | KL term = 0.22161093139648438\n",
      "Epoch 10480:         train accuracy = 0.2929 | logprob = -0.4168 | KL term = 0.22173031616210936\n",
      "Epoch 10500:         train accuracy = 0.2929 | logprob = -0.4168 | KL term = 0.22184959411621094\n",
      "Epoch 10520:         train accuracy = 0.2929 | logprob = -0.4167 | KL term = 0.22196881103515625\n",
      "Epoch 10540:         train accuracy = 0.2929 | logprob = -0.4167 | KL term = 0.2220879669189453\n",
      "Epoch 10560:         train accuracy = 0.2929 | logprob = -0.4167 | KL term = 0.2222070007324219\n",
      "Epoch 10580:         train accuracy = 0.2929 | logprob = -0.4167 | KL term = 0.22232601928710938\n",
      "Epoch 10600:         train accuracy = 0.2929 | logprob = -0.4167 | KL term = 0.2224449005126953\n",
      "Epoch 10620:         train accuracy = 0.2929 | logprob = -0.4167 | KL term = 0.22256375122070313\n",
      "Epoch 10640:         train accuracy = 0.2929 | logprob = -0.4167 | KL term = 0.2226824951171875\n",
      "Epoch 10660:         train accuracy = 0.2929 | logprob = -0.4166 | KL term = 0.22280117797851562\n",
      "Epoch 10680:         train accuracy = 0.2929 | logprob = -0.4166 | KL term = 0.22291983032226562\n",
      "Epoch 10700:         train accuracy = 0.2929 | logprob = -0.4166 | KL term = 0.22303837585449218\n",
      "Epoch 10720:         train accuracy = 0.2929 | logprob = -0.4166 | KL term = 0.22315684509277345\n",
      "Epoch 10740:         train accuracy = 0.2929 | logprob = -0.4166 | KL term = 0.2232751922607422\n",
      "Epoch 10760:         train accuracy = 0.2929 | logprob = -0.4166 | KL term = 0.2233935089111328\n",
      "Epoch 10780:         train accuracy = 0.2929 | logprob = -0.4166 | KL term = 0.22351176452636717\n",
      "Epoch 10800:         train accuracy = 0.2929 | logprob = -0.4165 | KL term = 0.22362994384765625\n",
      "Epoch 10820:         train accuracy = 0.2929 | logprob = -0.4165 | KL term = 0.22374810791015626\n",
      "Epoch 10840:         train accuracy = 0.2929 | logprob = -0.4165 | KL term = 0.22386614990234374\n",
      "Epoch 10860:         train accuracy = 0.2929 | logprob = -0.4165 | KL term = 0.2239841003417969\n",
      "Epoch 10880:         train accuracy = 0.2929 | logprob = -0.4165 | KL term = 0.22410203552246094\n",
      "Epoch 10900:         train accuracy = 0.2929 | logprob = -0.4165 | KL term = 0.22421987915039063\n",
      "Epoch 10920:         train accuracy = 0.2929 | logprob = -0.4165 | KL term = 0.22433767700195312\n",
      "Epoch 10940:         train accuracy = 0.2929 | logprob = -0.4164 | KL term = 0.22445541381835937\n",
      "Epoch 10960:         train accuracy = 0.2929 | logprob = -0.4164 | KL term = 0.2245730743408203\n",
      "Epoch 10980:         train accuracy = 0.2929 | logprob = -0.4164 | KL term = 0.22469062805175782\n",
      "Epoch 11000:         train accuracy = 0.2929 | logprob = -0.4164 | KL term = 0.22480818176269532\n",
      "Epoch 11020:         train accuracy = 0.2929 | logprob = -0.4164 | KL term = 0.22492562866210938\n",
      "Epoch 11040:         train accuracy = 0.2929 | logprob = -0.4164 | KL term = 0.22504301452636719\n",
      "Epoch 11060:         train accuracy = 0.2929 | logprob = -0.4164 | KL term = 0.22516036987304688\n",
      "Epoch 11080:         train accuracy = 0.2929 | logprob = -0.4164 | KL term = 0.22527764892578125\n",
      "Epoch 11100:         train accuracy = 0.2929 | logprob = -0.4163 | KL term = 0.22539491271972656\n",
      "Epoch 11120:         train accuracy = 0.2929 | logprob = -0.4163 | KL term = 0.22551211547851563\n",
      "Epoch 11140:         train accuracy = 0.2929 | logprob = -0.4163 | KL term = 0.2256292724609375\n",
      "Epoch 11160:         train accuracy = 0.2929 | logprob = -0.4163 | KL term = 0.22574638366699218\n",
      "Epoch 11180:         train accuracy = 0.2929 | logprob = -0.4163 | KL term = 0.2258634033203125\n",
      "Epoch 11200:         train accuracy = 0.2929 | logprob = -0.4163 | KL term = 0.22598037719726563\n",
      "Epoch 11220:         train accuracy = 0.2929 | logprob = -0.4163 | KL term = 0.2260972900390625\n",
      "Epoch 11240:         train accuracy = 0.2929 | logprob = -0.4163 | KL term = 0.226214111328125\n",
      "Epoch 11260:         train accuracy = 0.2929 | logprob = -0.4163 | KL term = 0.22633091735839844\n",
      "Epoch 11280:         train accuracy = 0.2929 | logprob = -0.4162 | KL term = 0.22644766235351563\n",
      "Epoch 11300:         train accuracy = 0.2929 | logprob = -0.4162 | KL term = 0.2265643310546875\n",
      "Epoch 11320:         train accuracy = 0.2929 | logprob = -0.4162 | KL term = 0.22668099975585937\n",
      "Epoch 11340:         train accuracy = 0.2929 | logprob = -0.4162 | KL term = 0.22679759216308593\n",
      "Epoch 11360:         train accuracy = 0.2929 | logprob = -0.4162 | KL term = 0.22691412353515625\n",
      "Epoch 11380:         train accuracy = 0.2929 | logprob = -0.4162 | KL term = 0.2270305938720703\n",
      "Epoch 11400:         train accuracy = 0.2929 | logprob = -0.4162 | KL term = 0.2271470489501953\n",
      "Epoch 11420:         train accuracy = 0.2929 | logprob = -0.4162 | KL term = 0.22726345825195313\n",
      "Epoch 11440:         train accuracy = 0.2929 | logprob = -0.4162 | KL term = 0.2273798065185547\n",
      "Epoch 11460:         train accuracy = 0.2929 | logprob = -0.4161 | KL term = 0.22749609375\n",
      "Epoch 11480:         train accuracy = 0.2929 | logprob = -0.4161 | KL term = 0.22761233520507812\n",
      "Epoch 11500:         train accuracy = 0.2929 | logprob = -0.4161 | KL term = 0.22772854614257812\n",
      "Epoch 11520:         train accuracy = 0.2929 | logprob = -0.4161 | KL term = 0.22784474182128905\n",
      "Epoch 11540:         train accuracy = 0.2929 | logprob = -0.4161 | KL term = 0.22796084594726562\n",
      "Epoch 11560:         train accuracy = 0.2929 | logprob = -0.4161 | KL term = 0.228076904296875\n",
      "Epoch 11580:         train accuracy = 0.2929 | logprob = -0.4161 | KL term = 0.22819293212890626\n",
      "Epoch 11600:         train accuracy = 0.2929 | logprob = -0.4161 | KL term = 0.22830892944335937\n",
      "Epoch 11620:         train accuracy = 0.2929 | logprob = -0.4161 | KL term = 0.22842489624023438\n",
      "Epoch 11640:         train accuracy = 0.2929 | logprob = -0.4161 | KL term = 0.22854080200195312\n",
      "Epoch 11660:         train accuracy = 0.2929 | logprob = -0.4161 | KL term = 0.2286566619873047\n",
      "Epoch 11680:         train accuracy = 0.2929 | logprob = -0.4160 | KL term = 0.22877249145507814\n",
      "Epoch 11700:         train accuracy = 0.2929 | logprob = -0.4160 | KL term = 0.22888827514648438\n",
      "Epoch 11720:         train accuracy = 0.2929 | logprob = -0.4160 | KL term = 0.22900404357910156\n",
      "Epoch 11740:         train accuracy = 0.2929 | logprob = -0.4160 | KL term = 0.2291197509765625\n",
      "Epoch 11760:         train accuracy = 0.2929 | logprob = -0.4160 | KL term = 0.22923541259765626\n",
      "Epoch 11780:         train accuracy = 0.2929 | logprob = -0.4160 | KL term = 0.22935104370117188\n",
      "Epoch 11800:         train accuracy = 0.2929 | logprob = -0.4160 | KL term = 0.22946664428710936\n",
      "Epoch 11820:         train accuracy = 0.2929 | logprob = -0.4160 | KL term = 0.22958219909667968\n",
      "Epoch 11840:         train accuracy = 0.2929 | logprob = -0.4160 | KL term = 0.22969772338867187\n",
      "Epoch 11860:         train accuracy = 0.2929 | logprob = -0.4160 | KL term = 0.22981320190429688\n",
      "Epoch 11880:         train accuracy = 0.2929 | logprob = -0.4160 | KL term = 0.22992861938476564\n",
      "Epoch 11900:         train accuracy = 0.2929 | logprob = -0.4160 | KL term = 0.23004400634765626\n",
      "Epoch 11920:         train accuracy = 0.2929 | logprob = -0.4159 | KL term = 0.23015937805175782\n",
      "Epoch 11940:         train accuracy = 0.2929 | logprob = -0.4159 | KL term = 0.23027474975585938\n",
      "Epoch 11960:         train accuracy = 0.2929 | logprob = -0.4159 | KL term = 0.2303900604248047\n",
      "Epoch 11980:         train accuracy = 0.2929 | logprob = -0.4159 | KL term = 0.23050531005859376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12000:         train accuracy = 0.2929 | logprob = -0.4159 | KL term = 0.2306205291748047\n",
      "Epoch 12020:         train accuracy = 0.2929 | logprob = -0.4159 | KL term = 0.2307357177734375\n",
      "Epoch 12040:         train accuracy = 0.2929 | logprob = -0.4159 | KL term = 0.23085086059570312\n",
      "Epoch 12060:         train accuracy = 0.2929 | logprob = -0.4159 | KL term = 0.23096597290039061\n",
      "Epoch 12080:         train accuracy = 0.2929 | logprob = -0.4159 | KL term = 0.23108103942871094\n",
      "Epoch 12100:         train accuracy = 0.2929 | logprob = -0.4159 | KL term = 0.23119610595703124\n",
      "Epoch 12120:         train accuracy = 0.2929 | logprob = -0.4159 | KL term = 0.2313111572265625\n",
      "Epoch 12140:         train accuracy = 0.2929 | logprob = -0.4159 | KL term = 0.2314261474609375\n",
      "Epoch 12160:         train accuracy = 0.2929 | logprob = -0.4159 | KL term = 0.23154110717773438\n",
      "Epoch 12180:         train accuracy = 0.2929 | logprob = -0.4158 | KL term = 0.231656005859375\n",
      "Epoch 12200:         train accuracy = 0.2929 | logprob = -0.4158 | KL term = 0.23177090454101562\n",
      "Epoch 12220:         train accuracy = 0.2929 | logprob = -0.4158 | KL term = 0.23188575744628906\n",
      "Epoch 12240:         train accuracy = 0.2929 | logprob = -0.4158 | KL term = 0.23200057983398437\n",
      "Epoch 12260:         train accuracy = 0.2929 | logprob = -0.4158 | KL term = 0.23211537170410157\n",
      "Epoch 12280:         train accuracy = 0.2929 | logprob = -0.4158 | KL term = 0.2322301025390625\n",
      "Epoch 12300:         train accuracy = 0.2929 | logprob = -0.4158 | KL term = 0.2323448486328125\n",
      "Epoch 12320:         train accuracy = 0.2929 | logprob = -0.4158 | KL term = 0.2324595947265625\n",
      "Epoch 12340:         train accuracy = 0.2929 | logprob = -0.4158 | KL term = 0.23257408142089844\n",
      "Epoch 12360:         train accuracy = 0.2929 | logprob = -0.4158 | KL term = 0.23268890380859375\n",
      "Epoch 12380:         train accuracy = 0.2929 | logprob = -0.4158 | KL term = 0.23280349731445313\n",
      "Epoch 12400:         train accuracy = 0.2929 | logprob = -0.4158 | KL term = 0.23291802978515624\n",
      "Epoch 12420:         train accuracy = 0.2929 | logprob = -0.4158 | KL term = 0.2330325927734375\n",
      "Epoch 12440:         train accuracy = 0.2929 | logprob = -0.4158 | KL term = 0.2331470947265625\n",
      "Epoch 12460:         train accuracy = 0.2929 | logprob = -0.4158 | KL term = 0.23326156616210938\n",
      "Epoch 12480:         train accuracy = 0.2929 | logprob = -0.4157 | KL term = 0.23337603759765624\n",
      "Epoch 12500:         train accuracy = 0.2929 | logprob = -0.4157 | KL term = 0.23349053955078125\n",
      "Epoch 12520:         train accuracy = 0.2929 | logprob = -0.4157 | KL term = 0.23360494995117187\n",
      "Epoch 12540:         train accuracy = 0.2929 | logprob = -0.4157 | KL term = 0.23371939086914062\n",
      "Epoch 12560:         train accuracy = 0.2929 | logprob = -0.4157 | KL term = 0.23383377075195313\n",
      "Epoch 12580:         train accuracy = 0.2929 | logprob = -0.4157 | KL term = 0.23394842529296875\n",
      "Epoch 12600:         train accuracy = 0.2929 | logprob = -0.4157 | KL term = 0.23406234741210938\n",
      "Epoch 12620:         train accuracy = 0.2929 | logprob = -0.4157 | KL term = 0.23417669677734376\n",
      "Epoch 12640:         train accuracy = 0.2929 | logprob = -0.4157 | KL term = 0.2342908935546875\n",
      "Epoch 12660:         train accuracy = 0.2929 | logprob = -0.4157 | KL term = 0.23440509033203125\n",
      "Epoch 12680:         train accuracy = 0.2929 | logprob = -0.4157 | KL term = 0.234519287109375\n",
      "Epoch 12700:         train accuracy = 0.2929 | logprob = -0.4157 | KL term = 0.23463343811035156\n",
      "Epoch 12720:         train accuracy = 0.2929 | logprob = -0.4157 | KL term = 0.23474758911132812\n",
      "Epoch 12740:         train accuracy = 0.2929 | logprob = -0.4157 | KL term = 0.2348616943359375\n",
      "Epoch 12760:         train accuracy = 0.2929 | logprob = -0.4157 | KL term = 0.2349757843017578\n",
      "Epoch 12780:         train accuracy = 0.2929 | logprob = -0.4157 | KL term = 0.23508993530273437\n",
      "Epoch 12800:         train accuracy = 0.2929 | logprob = -0.4157 | KL term = 0.23520404052734376\n",
      "Epoch 12820:         train accuracy = 0.2929 | logprob = -0.4157 | KL term = 0.23531796264648439\n",
      "Epoch 12840:         train accuracy = 0.2929 | logprob = -0.4157 | KL term = 0.2354320068359375\n",
      "Epoch 12860:         train accuracy = 0.2929 | logprob = -0.4156 | KL term = 0.2355459747314453\n",
      "Epoch 12880:         train accuracy = 0.2929 | logprob = -0.4156 | KL term = 0.23565997314453124\n",
      "Epoch 12900:         train accuracy = 0.2929 | logprob = -0.4156 | KL term = 0.23577392578125\n",
      "Epoch 12920:         train accuracy = 0.2929 | logprob = -0.4156 | KL term = 0.23588784790039063\n",
      "Epoch 12940:         train accuracy = 0.2929 | logprob = -0.4156 | KL term = 0.2360019073486328\n",
      "Epoch 12960:         train accuracy = 0.2929 | logprob = -0.4156 | KL term = 0.23611557006835937\n",
      "Epoch 12980:         train accuracy = 0.2929 | logprob = -0.4156 | KL term = 0.23622946166992187\n",
      "Epoch 13000:         train accuracy = 0.2929 | logprob = -0.4156 | KL term = 0.23634323120117187\n",
      "Epoch 13020:         train accuracy = 0.2929 | logprob = -0.4156 | KL term = 0.23645697021484374\n",
      "Epoch 13040:         train accuracy = 0.2929 | logprob = -0.4156 | KL term = 0.23657073974609374\n",
      "Epoch 13060:         train accuracy = 0.2929 | logprob = -0.4156 | KL term = 0.2366844482421875\n",
      "Epoch 13080:         train accuracy = 0.2929 | logprob = -0.4156 | KL term = 0.23679820251464845\n",
      "Epoch 13100:         train accuracy = 0.2929 | logprob = -0.4156 | KL term = 0.2369119110107422\n",
      "Epoch 13120:         train accuracy = 0.2929 | logprob = -0.4156 | KL term = 0.237025634765625\n",
      "Epoch 13140:         train accuracy = 0.2929 | logprob = -0.4156 | KL term = 0.2371390838623047\n",
      "Epoch 13160:         train accuracy = 0.2929 | logprob = -0.4156 | KL term = 0.2372528076171875\n",
      "Epoch 13180:         train accuracy = 0.2929 | logprob = -0.4156 | KL term = 0.23736637878417968\n",
      "Epoch 13200:         train accuracy = 0.2929 | logprob = -0.4156 | KL term = 0.23747991943359376\n",
      "Epoch 13220:         train accuracy = 0.2929 | logprob = -0.4156 | KL term = 0.23759349060058593\n",
      "Epoch 13240:         train accuracy = 0.2929 | logprob = -0.4156 | KL term = 0.23770703125\n",
      "Epoch 13260:         train accuracy = 0.2929 | logprob = -0.4156 | KL term = 0.23782058715820312\n",
      "Epoch 13280:         train accuracy = 0.2929 | logprob = -0.4156 | KL term = 0.23793408203125\n",
      "Epoch 13300:         train accuracy = 0.2929 | logprob = -0.4155 | KL term = 0.23804757690429687\n",
      "Epoch 13320:         train accuracy = 0.2929 | logprob = -0.4155 | KL term = 0.23816064453125\n",
      "Epoch 13340:         train accuracy = 0.2929 | logprob = -0.4155 | KL term = 0.2382744598388672\n",
      "Epoch 13360:         train accuracy = 0.2929 | logprob = -0.4155 | KL term = 0.23838778686523437\n",
      "Epoch 13380:         train accuracy = 0.2929 | logprob = -0.4155 | KL term = 0.23850119018554689\n",
      "Epoch 13400:         train accuracy = 0.2929 | logprob = -0.4155 | KL term = 0.23861447143554687\n",
      "Epoch 13420:         train accuracy = 0.2929 | logprob = -0.4155 | KL term = 0.23872779846191405\n",
      "Epoch 13440:         train accuracy = 0.2929 | logprob = -0.4155 | KL term = 0.23884109497070313\n",
      "Epoch 13460:         train accuracy = 0.2929 | logprob = -0.4155 | KL term = 0.23895437622070312\n",
      "Epoch 13480:         train accuracy = 0.2929 | logprob = -0.4155 | KL term = 0.2390676727294922\n",
      "Epoch 13500:         train accuracy = 0.2929 | logprob = -0.4155 | KL term = 0.23918093872070312\n",
      "Epoch 13520:         train accuracy = 0.2929 | logprob = -0.4155 | KL term = 0.23929412841796874\n",
      "Epoch 13540:         train accuracy = 0.2929 | logprob = -0.4155 | KL term = 0.23940765380859375\n",
      "Epoch 13560:         train accuracy = 0.2929 | logprob = -0.4155 | KL term = 0.2395205078125\n",
      "Epoch 13580:         train accuracy = 0.2929 | logprob = -0.4155 | KL term = 0.23963374328613282\n",
      "Epoch 13600:         train accuracy = 0.2929 | logprob = -0.4155 | KL term = 0.239746826171875\n",
      "Epoch 13620:         train accuracy = 0.2929 | logprob = -0.4155 | KL term = 0.23985995483398437\n",
      "Epoch 13640:         train accuracy = 0.2929 | logprob = -0.4155 | KL term = 0.2399730682373047\n",
      "Epoch 13660:         train accuracy = 0.2929 | logprob = -0.4155 | KL term = 0.240086181640625\n",
      "Epoch 13680:         train accuracy = 0.2929 | logprob = -0.4155 | KL term = 0.2401992645263672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13700:         train accuracy = 0.2929 | logprob = -0.4155 | KL term = 0.24031234741210938\n",
      "Epoch 13720:         train accuracy = 0.2929 | logprob = -0.4155 | KL term = 0.24042556762695313\n",
      "Epoch 13740:         train accuracy = 0.2929 | logprob = -0.4155 | KL term = 0.24053854370117186\n",
      "Epoch 13760:         train accuracy = 0.2929 | logprob = -0.4155 | KL term = 0.24065118408203126\n",
      "Epoch 13780:         train accuracy = 0.2929 | logprob = -0.4155 | KL term = 0.24076422119140625\n",
      "Epoch 13800:         train accuracy = 0.2929 | logprob = -0.4155 | KL term = 0.24087716674804688\n",
      "Epoch 13820:         train accuracy = 0.2929 | logprob = -0.4155 | KL term = 0.24099008178710937\n",
      "Epoch 13840:         train accuracy = 0.2929 | logprob = -0.4155 | KL term = 0.24110299682617187\n",
      "Epoch 13860:         train accuracy = 0.2929 | logprob = -0.4155 | KL term = 0.24121589660644532\n",
      "Epoch 13880:         train accuracy = 0.2929 | logprob = -0.4154 | KL term = 0.2413287811279297\n",
      "Epoch 13900:         train accuracy = 0.2929 | logprob = -0.4154 | KL term = 0.24144161987304688\n",
      "Epoch 13920:         train accuracy = 0.2929 | logprob = -0.4154 | KL term = 0.2415540008544922\n",
      "Epoch 13940:         train accuracy = 0.2929 | logprob = -0.4154 | KL term = 0.24166729736328124\n",
      "Epoch 13960:         train accuracy = 0.2929 | logprob = -0.4154 | KL term = 0.24177999877929687\n",
      "Epoch 13980:         train accuracy = 0.2929 | logprob = -0.4154 | KL term = 0.24189260864257814\n",
      "Epoch 14000:         train accuracy = 0.2929 | logprob = -0.4154 | KL term = 0.24200531005859374\n",
      "Epoch 14020:         train accuracy = 0.2929 | logprob = -0.4154 | KL term = 0.24171609497070312\n",
      "Epoch 14040:         train accuracy = 0.2929 | logprob = -0.4154 | KL term = 0.23993484497070314\n",
      "Epoch 14060:         train accuracy = 0.2929 | logprob = -0.4154 | KL term = 0.2364219207763672\n",
      "Epoch 14080:         train accuracy = 0.2929 | logprob = -0.4154 | KL term = 0.2312707977294922\n",
      "Epoch 14100:         train accuracy = 0.2929 | logprob = -0.4155 | KL term = 0.2247149658203125\n",
      "Epoch 14120:         train accuracy = 0.2929 | logprob = -0.4155 | KL term = 0.21710577392578126\n",
      "Epoch 14140:         train accuracy = 0.2929 | logprob = -0.4155 | KL term = 0.2088927459716797\n",
      "Epoch 14160:         train accuracy = 0.2929 | logprob = -0.4156 | KL term = 0.20056991577148436\n",
      "Epoch 14180:         train accuracy = 0.2928 | logprob = -0.4157 | KL term = 0.19253343200683593\n",
      "Epoch 14200:         train accuracy = 0.2923 | logprob = -0.4157 | KL term = 0.18496334838867187\n",
      "Epoch 14220:         train accuracy = 0.2913 | logprob = -0.4152 | KL term = 0.1781225891113281\n",
      "Epoch 14240:         train accuracy = 0.2895 | logprob = -0.4140 | KL term = 0.1723060302734375\n",
      "Epoch 14260:         train accuracy = 0.2875 | logprob = -0.4121 | KL term = 0.16728515625\n",
      "Epoch 14280:         train accuracy = 0.2821 | logprob = -0.4062 | KL term = 0.16292642211914063\n",
      "Epoch 14300:         train accuracy = 0.2791 | logprob = -0.4018 | KL term = 0.15945758056640624\n",
      "Epoch 14320:         train accuracy = 0.2781 | logprob = -0.3987 | KL term = 0.1559288330078125\n",
      "Epoch 14340:         train accuracy = 0.2776 | logprob = -0.3964 | KL term = 0.1530401306152344\n",
      "Epoch 14360:         train accuracy = 0.2771 | logprob = -0.3946 | KL term = 0.15054470825195312\n",
      "Epoch 14380:         train accuracy = 0.2767 | logprob = -0.3930 | KL term = 0.1483519287109375\n",
      "Epoch 14400:         train accuracy = 0.2762 | logprob = -0.3914 | KL term = 0.14644122314453126\n",
      "Epoch 14420:         train accuracy = 0.2758 | logprob = -0.3897 | KL term = 0.1448031005859375\n",
      "Epoch 14440:         train accuracy = 0.2752 | logprob = -0.3876 | KL term = 0.14344136047363282\n",
      "Epoch 14460:         train accuracy = 0.2744 | logprob = -0.3849 | KL term = 0.14236825561523436\n",
      "Epoch 14480:         train accuracy = 0.2734 | logprob = -0.3810 | KL term = 0.14159782409667968\n",
      "Epoch 14500:         train accuracy = 0.2720 | logprob = -0.3757 | KL term = 0.1411282043457031\n",
      "Epoch 14520:         train accuracy = 0.2703 | logprob = -0.3685 | KL term = 0.14092681884765626\n",
      "Epoch 14540:         train accuracy = 0.2682 | logprob = -0.3585 | KL term = 0.14092059326171874\n",
      "Epoch 14560:         train accuracy = 0.2658 | logprob = -0.3450 | KL term = 0.14106280517578124\n",
      "Epoch 14580:         train accuracy = 0.2635 | logprob = -0.3295 | KL term = 0.14121217346191406\n",
      "Epoch 14600:         train accuracy = 0.2620 | logprob = -0.3159 | KL term = 0.1411692199707031\n",
      "Epoch 14620:         train accuracy = 0.2611 | logprob = -0.3056 | KL term = 0.14093438720703125\n",
      "Epoch 14640:         train accuracy = 0.2606 | logprob = -0.2977 | KL term = 0.14060076904296875\n",
      "Epoch 14660:         train accuracy = 0.2603 | logprob = -0.2916 | KL term = 0.14021578979492189\n",
      "Epoch 14680:         train accuracy = 0.2602 | logprob = -0.2868 | KL term = 0.1397903289794922\n",
      "Epoch 14700:         train accuracy = 0.2600 | logprob = -0.2829 | KL term = 0.13933859252929687\n",
      "Epoch 14720:         train accuracy = 0.2599 | logprob = -0.2797 | KL term = 0.138873046875\n",
      "Epoch 14740:         train accuracy = 0.2598 | logprob = -0.2770 | KL term = 0.13840036010742188\n",
      "Epoch 14760:         train accuracy = 0.2598 | logprob = -0.2748 | KL term = 0.1379258270263672\n",
      "Epoch 14780:         train accuracy = 0.2597 | logprob = -0.2729 | KL term = 0.1374531555175781\n",
      "Epoch 14800:         train accuracy = 0.2597 | logprob = -0.2713 | KL term = 0.1369849853515625\n",
      "Epoch 14820:         train accuracy = 0.2597 | logprob = -0.2699 | KL term = 0.13652322387695312\n",
      "Epoch 14840:         train accuracy = 0.2596 | logprob = -0.2687 | KL term = 0.13606869506835936\n",
      "Epoch 14860:         train accuracy = 0.2596 | logprob = -0.2676 | KL term = 0.13562420654296875\n",
      "Epoch 14880:         train accuracy = 0.2596 | logprob = -0.2667 | KL term = 0.13518756103515625\n",
      "Epoch 14900:         train accuracy = 0.2596 | logprob = -0.2660 | KL term = 0.13476033020019532\n",
      "Epoch 14920:         train accuracy = 0.2596 | logprob = -0.2653 | KL term = 0.13434262084960938\n",
      "Epoch 14940:         train accuracy = 0.2596 | logprob = -0.2647 | KL term = 0.13393475341796876\n",
      "Epoch 14960:         train accuracy = 0.2596 | logprob = -0.2642 | KL term = 0.13353680419921876\n",
      "Epoch 14980:         train accuracy = 0.2596 | logprob = -0.2638 | KL term = 0.1331488037109375\n",
      "Epoch 15000:         train accuracy = 0.2596 | logprob = -0.2634 | KL term = 0.132770751953125\n",
      "Epoch 15020:         train accuracy = 0.2596 | logprob = -0.2630 | KL term = 0.13247218322753906\n",
      "Epoch 15040:         train accuracy = 0.2596 | logprob = -0.2626 | KL term = 0.132244873046875\n",
      "Epoch 15060:         train accuracy = 0.2596 | logprob = -0.2623 | KL term = 0.1320519256591797\n",
      "Epoch 15080:         train accuracy = 0.2596 | logprob = -0.2619 | KL term = 0.13189710998535156\n",
      "Epoch 15100:         train accuracy = 0.2596 | logprob = -0.2616 | KL term = 0.13177236938476564\n",
      "Epoch 15120:         train accuracy = 0.2596 | logprob = -0.2612 | KL term = 0.1316730194091797\n",
      "Epoch 15140:         train accuracy = 0.2596 | logprob = -0.2609 | KL term = 0.1315952606201172\n",
      "Epoch 15160:         train accuracy = 0.2596 | logprob = -0.2606 | KL term = 0.13153622436523438\n",
      "Epoch 15180:         train accuracy = 0.2596 | logprob = -0.2602 | KL term = 0.1314931640625\n",
      "Epoch 15200:         train accuracy = 0.2596 | logprob = -0.2599 | KL term = 0.1314638671875\n",
      "Epoch 15220:         train accuracy = 0.2596 | logprob = -0.2596 | KL term = 0.13144627380371093\n",
      "Epoch 15240:         train accuracy = 0.2596 | logprob = -0.2593 | KL term = 0.1314384002685547\n",
      "Epoch 15260:         train accuracy = 0.2596 | logprob = -0.2591 | KL term = 0.131440185546875\n",
      "Epoch 15280:         train accuracy = 0.2596 | logprob = -0.2588 | KL term = 0.1314487762451172\n",
      "Epoch 15300:         train accuracy = 0.2596 | logprob = -0.2585 | KL term = 0.13146360778808594\n",
      "Epoch 15320:         train accuracy = 0.2596 | logprob = -0.2583 | KL term = 0.13148387145996093\n",
      "Epoch 15340:         train accuracy = 0.2596 | logprob = -0.2580 | KL term = 0.1315087127685547\n",
      "Epoch 15360:         train accuracy = 0.2595 | logprob = -0.2578 | KL term = 0.13153744506835938\n",
      "Epoch 15380:         train accuracy = 0.2595 | logprob = -0.2576 | KL term = 0.13156942749023437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15400:         train accuracy = 0.2595 | logprob = -0.2573 | KL term = 0.13160408020019532\n",
      "Epoch 15420:         train accuracy = 0.2596 | logprob = -0.2571 | KL term = 0.1316414489746094\n",
      "Epoch 15440:         train accuracy = 0.2595 | logprob = -0.2569 | KL term = 0.13167938232421875\n",
      "Epoch 15460:         train accuracy = 0.2595 | logprob = -0.2567 | KL term = 0.1317197265625\n",
      "Epoch 15480:         train accuracy = 0.2595 | logprob = -0.2565 | KL term = 0.13176104736328126\n",
      "Epoch 15500:         train accuracy = 0.2595 | logprob = -0.2563 | KL term = 0.13180320739746093\n",
      "Epoch 15520:         train accuracy = 0.2595 | logprob = -0.2561 | KL term = 0.1318460693359375\n",
      "Epoch 15540:         train accuracy = 0.2595 | logprob = -0.2559 | KL term = 0.13188943481445312\n",
      "Epoch 15560:         train accuracy = 0.2595 | logprob = -0.2557 | KL term = 0.13193316650390624\n",
      "Epoch 15580:         train accuracy = 0.2595 | logprob = -0.2556 | KL term = 0.13197706604003906\n",
      "Epoch 15600:         train accuracy = 0.2595 | logprob = -0.2554 | KL term = 0.1320210266113281\n",
      "Epoch 15620:         train accuracy = 0.2595 | logprob = -0.2552 | KL term = 0.13206442260742188\n",
      "Epoch 15640:         train accuracy = 0.2595 | logprob = -0.2551 | KL term = 0.13210848999023436\n",
      "Epoch 15660:         train accuracy = 0.2595 | logprob = -0.2549 | KL term = 0.13215225219726562\n",
      "Epoch 15680:         train accuracy = 0.2595 | logprob = -0.2548 | KL term = 0.13219561767578125\n",
      "Epoch 15700:         train accuracy = 0.2595 | logprob = -0.2546 | KL term = 0.1322386932373047\n",
      "Epoch 15720:         train accuracy = 0.2595 | logprob = -0.2545 | KL term = 0.13228146362304688\n",
      "Epoch 15740:         train accuracy = 0.2595 | logprob = -0.2544 | KL term = 0.1323238830566406\n",
      "Epoch 15760:         train accuracy = 0.2595 | logprob = -0.2542 | KL term = 0.13236595153808595\n",
      "Epoch 15780:         train accuracy = 0.2595 | logprob = -0.2541 | KL term = 0.1324076385498047\n",
      "Epoch 15800:         train accuracy = 0.2595 | logprob = -0.2540 | KL term = 0.1324489440917969\n",
      "Epoch 15820:         train accuracy = 0.2595 | logprob = -0.2538 | KL term = 0.13248980712890626\n",
      "Epoch 15840:         train accuracy = 0.2595 | logprob = -0.2537 | KL term = 0.13253048706054688\n",
      "Epoch 15860:         train accuracy = 0.2595 | logprob = -0.2536 | KL term = 0.13257044982910157\n",
      "Epoch 15880:         train accuracy = 0.2595 | logprob = -0.2535 | KL term = 0.13260993957519532\n",
      "Epoch 15900:         train accuracy = 0.2595 | logprob = -0.2534 | KL term = 0.13264930725097657\n",
      "Epoch 15920:         train accuracy = 0.2595 | logprob = -0.2533 | KL term = 0.13268821716308593\n",
      "Epoch 15940:         train accuracy = 0.2595 | logprob = -0.2532 | KL term = 0.13272683715820313\n",
      "Epoch 15960:         train accuracy = 0.2595 | logprob = -0.2531 | KL term = 0.13276515197753908\n",
      "Epoch 15980:         train accuracy = 0.2594 | logprob = -0.2530 | KL term = 0.13280322265625\n",
      "Epoch 16000:         train accuracy = 0.2594 | logprob = -0.2529 | KL term = 0.13284112548828125\n",
      "Epoch 16020:         train accuracy = 0.2594 | logprob = -0.2528 | KL term = 0.13287835693359376\n",
      "Epoch 16040:         train accuracy = 0.2594 | logprob = -0.2527 | KL term = 0.13291650390625\n",
      "Epoch 16060:         train accuracy = 0.2594 | logprob = -0.2526 | KL term = 0.13295401000976562\n",
      "Epoch 16080:         train accuracy = 0.2594 | logprob = -0.2525 | KL term = 0.13299188232421874\n",
      "Epoch 16100:         train accuracy = 0.2594 | logprob = -0.2524 | KL term = 0.13303009033203125\n",
      "Epoch 16120:         train accuracy = 0.2594 | logprob = -0.2523 | KL term = 0.1330689697265625\n",
      "Epoch 16140:         train accuracy = 0.2594 | logprob = -0.2522 | KL term = 0.13310890197753905\n",
      "Epoch 16160:         train accuracy = 0.2594 | logprob = -0.2522 | KL term = 0.13315040588378907\n",
      "Epoch 16180:         train accuracy = 0.2593 | logprob = -0.2521 | KL term = 0.13319442749023438\n",
      "Epoch 16200:         train accuracy = 0.2593 | logprob = -0.2520 | KL term = 0.13324270629882812\n",
      "Epoch 16220:         train accuracy = 0.2593 | logprob = -0.2519 | KL term = 0.1332960662841797\n",
      "Epoch 16240:         train accuracy = 0.2592 | logprob = -0.2517 | KL term = 0.1333602294921875\n",
      "Epoch 16260:         train accuracy = 0.2592 | logprob = -0.2516 | KL term = 0.1334407653808594\n",
      "Epoch 16280:         train accuracy = 0.2590 | logprob = -0.2514 | KL term = 0.13354855346679687\n",
      "Epoch 16300:         train accuracy = 0.2588 | logprob = -0.2511 | KL term = 0.13369706726074218\n",
      "Epoch 16320:         train accuracy = 0.2585 | logprob = -0.2507 | KL term = 0.133896484375\n",
      "Epoch 16340:         train accuracy = 0.2581 | logprob = -0.2501 | KL term = 0.13414495849609376\n",
      "Epoch 16360:         train accuracy = 0.2576 | logprob = -0.2493 | KL term = 0.13443626403808595\n",
      "Epoch 16380:         train accuracy = 0.2569 | logprob = -0.2484 | KL term = 0.13477322387695312\n",
      "Epoch 16400:         train accuracy = 0.2562 | logprob = -0.2472 | KL term = 0.13516481018066406\n",
      "Epoch 16420:         train accuracy = 0.2553 | logprob = -0.2458 | KL term = 0.13562603759765626\n",
      "Epoch 16440:         train accuracy = 0.2543 | logprob = -0.2440 | KL term = 0.13620236206054687\n",
      "Epoch 16460:         train accuracy = 0.2529 | logprob = -0.2417 | KL term = 0.13703387451171875\n",
      "Epoch 16480:         train accuracy = 0.2506 | logprob = -0.2379 | KL term = 0.13860641479492186\n",
      "Epoch 16500:         train accuracy = 0.2462 | logprob = -0.2303 | KL term = 0.14191598510742187\n",
      "Epoch 16520:         train accuracy = 0.2411 | logprob = -0.2200 | KL term = 0.14603755187988282\n",
      "Epoch 16540:         train accuracy = 0.2367 | logprob = -0.2096 | KL term = 0.1498025665283203\n",
      "Epoch 16560:         train accuracy = 0.2326 | logprob = -0.1988 | KL term = 0.15339376831054688\n",
      "Epoch 16580:         train accuracy = 0.2285 | logprob = -0.1863 | KL term = 0.15697463989257812\n",
      "Epoch 16600:         train accuracy = 0.2232 | logprob = -0.1692 | KL term = 0.16082077026367186\n",
      "Epoch 16620:         train accuracy = 0.2156 | logprob = -0.1432 | KL term = 0.16512786865234375\n",
      "Epoch 16640:         train accuracy = 0.2060 | logprob = -0.1075 | KL term = 0.1698714599609375\n",
      "Epoch 16660:         train accuracy = 0.1961 | logprob = -0.0692 | KL term = 0.17438775634765624\n",
      "Epoch 16680:         train accuracy = 0.1871 | logprob = -0.0352 | KL term = 0.1779019775390625\n",
      "Epoch 16700:         train accuracy = 0.1792 | logprob = -0.0063 | KL term = 0.18047900390625\n",
      "Epoch 16720:         train accuracy = 0.1722 | logprob = 0.0186 | KL term = 0.18258074951171874\n",
      "Epoch 16740:         train accuracy = 0.1661 | logprob = 0.0404 | KL term = 0.18447409057617187\n",
      "Epoch 16760:         train accuracy = 0.1606 | logprob = 0.0598 | KL term = 0.18625949096679686\n",
      "Epoch 16780:         train accuracy = 0.1557 | logprob = 0.0772 | KL term = 0.18799786376953126\n",
      "Epoch 16800:         train accuracy = 0.1513 | logprob = 0.0930 | KL term = 0.1897286376953125\n",
      "Epoch 16820:         train accuracy = 0.1474 | logprob = 0.1074 | KL term = 0.19146876525878906\n",
      "Epoch 16840:         train accuracy = 0.1440 | logprob = 0.1206 | KL term = 0.19321446228027345\n",
      "Epoch 16860:         train accuracy = 0.1411 | logprob = 0.1327 | KL term = 0.19493255615234376\n",
      "Epoch 16880:         train accuracy = 0.1384 | logprob = 0.1438 | KL term = 0.19656484985351563\n",
      "Epoch 16900:         train accuracy = 0.1360 | logprob = 0.1540 | KL term = 0.19806393432617186\n",
      "Epoch 16920:         train accuracy = 0.1339 | logprob = 0.1635 | KL term = 0.19941830444335937\n",
      "Epoch 16940:         train accuracy = 0.1319 | logprob = 0.1725 | KL term = 0.20063861083984375\n",
      "Epoch 16960:         train accuracy = 0.1302 | logprob = 0.1807 | KL term = 0.20173558044433593\n",
      "Epoch 16980:         train accuracy = 0.1287 | logprob = 0.1882 | KL term = 0.20271450805664062\n",
      "Epoch 17000:         train accuracy = 0.1273 | logprob = 0.1949 | KL term = 0.20359608459472656\n",
      "Epoch 17020:         train accuracy = 0.1258 | logprob = 0.2011 | KL term = 0.20443203735351562\n",
      "Epoch 17040:         train accuracy = 0.1245 | logprob = 0.2069 | KL term = 0.20522515869140626\n",
      "Epoch 17060:         train accuracy = 0.1234 | logprob = 0.2120 | KL term = 0.2059189147949219\n",
      "Epoch 17080:         train accuracy = 0.1226 | logprob = 0.2166 | KL term = 0.20649223327636718\n",
      "Epoch 17100:         train accuracy = 0.1219 | logprob = 0.2206 | KL term = 0.20696038818359375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17120:         train accuracy = 0.1213 | logprob = 0.2242 | KL term = 0.2073403015136719\n",
      "Epoch 17140:         train accuracy = 0.1207 | logprob = 0.2275 | KL term = 0.20764523315429687\n",
      "Epoch 17160:         train accuracy = 0.1203 | logprob = 0.2304 | KL term = 0.20788577270507813\n",
      "Epoch 17180:         train accuracy = 0.1198 | logprob = 0.2331 | KL term = 0.20807131958007813\n",
      "Epoch 17200:         train accuracy = 0.1195 | logprob = 0.2355 | KL term = 0.2082093505859375\n",
      "Epoch 17220:         train accuracy = 0.1191 | logprob = 0.2376 | KL term = 0.2083074645996094\n",
      "Epoch 17240:         train accuracy = 0.1188 | logprob = 0.2396 | KL term = 0.20837234497070312\n",
      "Epoch 17260:         train accuracy = 0.1185 | logprob = 0.2415 | KL term = 0.20841015625\n",
      "Epoch 17280:         train accuracy = 0.1182 | logprob = 0.2431 | KL term = 0.20842672729492187\n",
      "Epoch 17300:         train accuracy = 0.1180 | logprob = 0.2446 | KL term = 0.20842697143554687\n",
      "Epoch 17320:         train accuracy = 0.1178 | logprob = 0.2460 | KL term = 0.20841531372070313\n",
      "Epoch 17340:         train accuracy = 0.1176 | logprob = 0.2473 | KL term = 0.20839556884765625\n",
      "Epoch 17360:         train accuracy = 0.1174 | logprob = 0.2484 | KL term = 0.20837051391601563\n",
      "Epoch 17380:         train accuracy = 0.1172 | logprob = 0.2495 | KL term = 0.2083441162109375\n",
      "Epoch 17400:         train accuracy = 0.1171 | logprob = 0.2505 | KL term = 0.20831646728515624\n",
      "Epoch 17420:         train accuracy = 0.1170 | logprob = 0.2514 | KL term = 0.20828848266601563\n",
      "Epoch 17440:         train accuracy = 0.1169 | logprob = 0.2523 | KL term = 0.20826048278808593\n",
      "Epoch 17460:         train accuracy = 0.1167 | logprob = 0.2531 | KL term = 0.20823220825195313\n",
      "Epoch 17480:         train accuracy = 0.1166 | logprob = 0.2538 | KL term = 0.20820333862304688\n",
      "Epoch 17500:         train accuracy = 0.1166 | logprob = 0.2545 | KL term = 0.20817366027832032\n",
      "Epoch 17520:         train accuracy = 0.1165 | logprob = 0.2552 | KL term = 0.20814332580566405\n",
      "Epoch 17540:         train accuracy = 0.1164 | logprob = 0.2558 | KL term = 0.20811210632324217\n",
      "Epoch 17560:         train accuracy = 0.1163 | logprob = 0.2564 | KL term = 0.20808003234863282\n",
      "Epoch 17580:         train accuracy = 0.1163 | logprob = 0.2569 | KL term = 0.20804771423339843\n",
      "Epoch 17600:         train accuracy = 0.1162 | logprob = 0.2574 | KL term = 0.208014892578125\n",
      "Epoch 17620:         train accuracy = 0.1162 | logprob = 0.2579 | KL term = 0.20798190307617187\n",
      "Epoch 17640:         train accuracy = 0.1161 | logprob = 0.2584 | KL term = 0.2079488525390625\n",
      "Epoch 17660:         train accuracy = 0.1161 | logprob = 0.2588 | KL term = 0.20791574096679688\n",
      "Epoch 17680:         train accuracy = 0.1160 | logprob = 0.2592 | KL term = 0.20788265991210939\n",
      "Epoch 17700:         train accuracy = 0.1160 | logprob = 0.2596 | KL term = 0.2078494873046875\n",
      "Epoch 17720:         train accuracy = 0.1160 | logprob = 0.2599 | KL term = 0.20781668090820313\n",
      "Epoch 17740:         train accuracy = 0.1159 | logprob = 0.2603 | KL term = 0.20778321838378908\n",
      "Epoch 17760:         train accuracy = 0.1159 | logprob = 0.2606 | KL term = 0.20774993896484376\n",
      "Epoch 17780:         train accuracy = 0.1159 | logprob = 0.2609 | KL term = 0.20771607971191405\n",
      "Epoch 17800:         train accuracy = 0.1158 | logprob = 0.2612 | KL term = 0.2076817626953125\n",
      "Epoch 17820:         train accuracy = 0.1158 | logprob = 0.2615 | KL term = 0.2076468505859375\n",
      "Epoch 17840:         train accuracy = 0.1158 | logprob = 0.2618 | KL term = 0.20761131286621093\n",
      "Epoch 17860:         train accuracy = 0.1157 | logprob = 0.2620 | KL term = 0.2075750732421875\n",
      "Epoch 17880:         train accuracy = 0.1157 | logprob = 0.2623 | KL term = 0.20753811645507814\n",
      "Epoch 17900:         train accuracy = 0.1157 | logprob = 0.2625 | KL term = 0.2075003967285156\n",
      "Epoch 17920:         train accuracy = 0.1157 | logprob = 0.2628 | KL term = 0.20746209716796876\n",
      "Epoch 17940:         train accuracy = 0.1157 | logprob = 0.2630 | KL term = 0.20742286682128908\n",
      "Epoch 17960:         train accuracy = 0.1157 | logprob = 0.2632 | KL term = 0.20738278198242188\n",
      "Epoch 17980:         train accuracy = 0.1156 | logprob = 0.2634 | KL term = 0.2073419952392578\n",
      "Epoch 18000:         train accuracy = 0.1156 | logprob = 0.2636 | KL term = 0.20730039978027343\n",
      "Epoch 18020:         train accuracy = 0.1156 | logprob = 0.2638 | KL term = 0.2072579345703125\n",
      "Epoch 18040:         train accuracy = 0.1156 | logprob = 0.2640 | KL term = 0.2072146911621094\n",
      "Epoch 18060:         train accuracy = 0.1156 | logprob = 0.2642 | KL term = 0.20717068481445314\n",
      "Epoch 18080:         train accuracy = 0.1156 | logprob = 0.2643 | KL term = 0.20712588500976561\n",
      "Epoch 18100:         train accuracy = 0.1156 | logprob = 0.2645 | KL term = 0.2070806884765625\n",
      "Epoch 18120:         train accuracy = 0.1155 | logprob = 0.2646 | KL term = 0.207034423828125\n",
      "Epoch 18140:         train accuracy = 0.1155 | logprob = 0.2648 | KL term = 0.20698797607421876\n",
      "Epoch 18160:         train accuracy = 0.1155 | logprob = 0.2649 | KL term = 0.20694061279296874\n",
      "Epoch 18180:         train accuracy = 0.1155 | logprob = 0.2651 | KL term = 0.206892578125\n",
      "Epoch 18200:         train accuracy = 0.1155 | logprob = 0.2652 | KL term = 0.20684393310546875\n",
      "Epoch 18220:         train accuracy = 0.1155 | logprob = 0.2654 | KL term = 0.20679463195800782\n",
      "Epoch 18240:         train accuracy = 0.1155 | logprob = 0.2655 | KL term = 0.2067447509765625\n",
      "Epoch 18260:         train accuracy = 0.1155 | logprob = 0.2656 | KL term = 0.20669427490234374\n",
      "Epoch 18280:         train accuracy = 0.1155 | logprob = 0.2657 | KL term = 0.20664329528808595\n",
      "Epoch 18300:         train accuracy = 0.1155 | logprob = 0.2659 | KL term = 0.20659190368652344\n",
      "Epoch 18320:         train accuracy = 0.1154 | logprob = 0.2660 | KL term = 0.20654008483886718\n",
      "Epoch 18340:         train accuracy = 0.1154 | logprob = 0.2661 | KL term = 0.2064880828857422\n",
      "Epoch 18360:         train accuracy = 0.1154 | logprob = 0.2662 | KL term = 0.20643536376953125\n",
      "Epoch 18380:         train accuracy = 0.1154 | logprob = 0.2663 | KL term = 0.20638221740722656\n",
      "Epoch 18400:         train accuracy = 0.1154 | logprob = 0.2664 | KL term = 0.20632862854003906\n",
      "Epoch 18420:         train accuracy = 0.1154 | logprob = 0.2665 | KL term = 0.206274658203125\n",
      "Epoch 18440:         train accuracy = 0.1154 | logprob = 0.2666 | KL term = 0.20622030639648437\n",
      "Epoch 18460:         train accuracy = 0.1154 | logprob = 0.2667 | KL term = 0.20616558837890625\n",
      "Epoch 18480:         train accuracy = 0.1154 | logprob = 0.2668 | KL term = 0.20611026000976562\n",
      "Epoch 18500:         train accuracy = 0.1154 | logprob = 0.2669 | KL term = 0.2060554962158203\n",
      "Epoch 18520:         train accuracy = 0.1154 | logprob = 0.2669 | KL term = 0.20600057983398437\n",
      "Epoch 18540:         train accuracy = 0.1153 | logprob = 0.2670 | KL term = 0.205945068359375\n",
      "Epoch 18560:         train accuracy = 0.1153 | logprob = 0.2671 | KL term = 0.20588935852050783\n",
      "Epoch 18580:         train accuracy = 0.1153 | logprob = 0.2672 | KL term = 0.20583340454101562\n",
      "Epoch 18600:         train accuracy = 0.1153 | logprob = 0.2673 | KL term = 0.20577725219726561\n",
      "Epoch 18620:         train accuracy = 0.1153 | logprob = 0.2673 | KL term = 0.205720947265625\n",
      "Epoch 18640:         train accuracy = 0.1153 | logprob = 0.2674 | KL term = 0.20566444396972655\n",
      "Epoch 18660:         train accuracy = 0.1153 | logprob = 0.2675 | KL term = 0.20560780334472656\n",
      "Epoch 18680:         train accuracy = 0.1153 | logprob = 0.2675 | KL term = 0.20555120849609376\n",
      "Epoch 18700:         train accuracy = 0.1153 | logprob = 0.2676 | KL term = 0.20549510192871093\n",
      "Epoch 18720:         train accuracy = 0.1153 | logprob = 0.2677 | KL term = 0.20543869018554686\n",
      "Epoch 18740:         train accuracy = 0.1153 | logprob = 0.2677 | KL term = 0.20538227844238283\n",
      "Epoch 18760:         train accuracy = 0.1153 | logprob = 0.2678 | KL term = 0.20532579040527343\n",
      "Epoch 18780:         train accuracy = 0.1153 | logprob = 0.2679 | KL term = 0.20526925659179687\n",
      "Epoch 18800:         train accuracy = 0.1153 | logprob = 0.2679 | KL term = 0.20521269226074218\n",
      "Epoch 18820:         train accuracy = 0.1153 | logprob = 0.2680 | KL term = 0.20515617370605468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18840:         train accuracy = 0.1153 | logprob = 0.2680 | KL term = 0.20509967041015625\n",
      "Epoch 18860:         train accuracy = 0.1153 | logprob = 0.2681 | KL term = 0.20504336547851562\n",
      "Epoch 18880:         train accuracy = 0.1152 | logprob = 0.2681 | KL term = 0.20498760986328124\n",
      "Epoch 18900:         train accuracy = 0.1152 | logprob = 0.2682 | KL term = 0.2049320068359375\n",
      "Epoch 18920:         train accuracy = 0.1152 | logprob = 0.2682 | KL term = 0.2048763427734375\n",
      "Epoch 18940:         train accuracy = 0.1152 | logprob = 0.2683 | KL term = 0.2048207092285156\n",
      "Epoch 18960:         train accuracy = 0.1152 | logprob = 0.2683 | KL term = 0.20476516723632812\n",
      "Epoch 18980:         train accuracy = 0.1152 | logprob = 0.2684 | KL term = 0.20470970153808593\n",
      "Epoch 19000:         train accuracy = 0.1152 | logprob = 0.2684 | KL term = 0.2046543426513672\n",
      "Epoch 19020:         train accuracy = 0.1152 | logprob = 0.2685 | KL term = 0.20459913635253907\n",
      "Epoch 19040:         train accuracy = 0.1152 | logprob = 0.2685 | KL term = 0.2045443115234375\n",
      "Epoch 19060:         train accuracy = 0.1152 | logprob = 0.2686 | KL term = 0.2044903564453125\n",
      "Epoch 19080:         train accuracy = 0.1152 | logprob = 0.2686 | KL term = 0.20443624877929686\n",
      "Epoch 19100:         train accuracy = 0.1152 | logprob = 0.2687 | KL term = 0.2043822479248047\n",
      "Epoch 19120:         train accuracy = 0.1152 | logprob = 0.2687 | KL term = 0.20432833862304686\n",
      "Epoch 19140:         train accuracy = 0.1152 | logprob = 0.2687 | KL term = 0.20427452087402342\n",
      "Epoch 19160:         train accuracy = 0.1152 | logprob = 0.2688 | KL term = 0.20422080993652345\n",
      "Epoch 19180:         train accuracy = 0.1152 | logprob = 0.2688 | KL term = 0.204167236328125\n",
      "Epoch 19200:         train accuracy = 0.1152 | logprob = 0.2689 | KL term = 0.20411384582519532\n",
      "Epoch 19220:         train accuracy = 0.1152 | logprob = 0.2689 | KL term = 0.2040611572265625\n",
      "Epoch 19240:         train accuracy = 0.1152 | logprob = 0.2689 | KL term = 0.20400906372070313\n",
      "Epoch 19260:         train accuracy = 0.1152 | logprob = 0.2690 | KL term = 0.20395697021484374\n",
      "Epoch 19280:         train accuracy = 0.1152 | logprob = 0.2690 | KL term = 0.20390496826171875\n",
      "Epoch 19300:         train accuracy = 0.1152 | logprob = 0.2690 | KL term = 0.20385308837890626\n",
      "Epoch 19320:         train accuracy = 0.1152 | logprob = 0.2691 | KL term = 0.20380126953125\n",
      "Epoch 19340:         train accuracy = 0.1152 | logprob = 0.2691 | KL term = 0.20374957275390626\n",
      "Epoch 19360:         train accuracy = 0.1152 | logprob = 0.2691 | KL term = 0.2036980438232422\n",
      "Epoch 19380:         train accuracy = 0.1152 | logprob = 0.2692 | KL term = 0.20364682006835938\n",
      "Epoch 19400:         train accuracy = 0.1152 | logprob = 0.2692 | KL term = 0.203596923828125\n",
      "Epoch 19420:         train accuracy = 0.1151 | logprob = 0.2692 | KL term = 0.20354762268066406\n",
      "Epoch 19440:         train accuracy = 0.1151 | logprob = 0.2693 | KL term = 0.20349842834472656\n",
      "Epoch 19460:         train accuracy = 0.1151 | logprob = 0.2693 | KL term = 0.20344924926757812\n",
      "Epoch 19480:         train accuracy = 0.1151 | logprob = 0.2693 | KL term = 0.20340017700195312\n",
      "Epoch 19500:         train accuracy = 0.1151 | logprob = 0.2694 | KL term = 0.20335124206542968\n",
      "Epoch 19520:         train accuracy = 0.1151 | logprob = 0.2694 | KL term = 0.20330247497558593\n",
      "Epoch 19540:         train accuracy = 0.1151 | logprob = 0.2694 | KL term = 0.20325390625\n",
      "Epoch 19560:         train accuracy = 0.1151 | logprob = 0.2695 | KL term = 0.20320556640625\n",
      "Epoch 19580:         train accuracy = 0.1151 | logprob = 0.2695 | KL term = 0.203157470703125\n",
      "Epoch 19600:         train accuracy = 0.1151 | logprob = 0.2695 | KL term = 0.20310971069335937\n",
      "Epoch 19620:         train accuracy = 0.1151 | logprob = 0.2696 | KL term = 0.20306439208984375\n",
      "Epoch 19640:         train accuracy = 0.1151 | logprob = 0.2696 | KL term = 0.20301995849609375\n",
      "Epoch 19660:         train accuracy = 0.1151 | logprob = 0.2696 | KL term = 0.20297567749023437\n",
      "Epoch 19680:         train accuracy = 0.1151 | logprob = 0.2697 | KL term = 0.20293148803710936\n",
      "Epoch 19700:         train accuracy = 0.1151 | logprob = 0.2697 | KL term = 0.20288742065429688\n",
      "Epoch 19720:         train accuracy = 0.1151 | logprob = 0.2697 | KL term = 0.20284365844726562\n",
      "Epoch 19740:         train accuracy = 0.1151 | logprob = 0.2697 | KL term = 0.2028001708984375\n",
      "Epoch 19760:         train accuracy = 0.1151 | logprob = 0.2698 | KL term = 0.20275706481933595\n",
      "Epoch 19780:         train accuracy = 0.1151 | logprob = 0.2698 | KL term = 0.20271435546875\n",
      "Epoch 19800:         train accuracy = 0.1151 | logprob = 0.2698 | KL term = 0.20267208862304686\n",
      "Epoch 19820:         train accuracy = 0.1151 | logprob = 0.2699 | KL term = 0.20263027954101562\n",
      "Epoch 19840:         train accuracy = 0.1151 | logprob = 0.2699 | KL term = 0.20258926391601562\n",
      "Epoch 19860:         train accuracy = 0.1151 | logprob = 0.2699 | KL term = 0.20255194091796874\n",
      "Epoch 19880:         train accuracy = 0.1151 | logprob = 0.2699 | KL term = 0.20251510620117188\n",
      "Epoch 19900:         train accuracy = 0.1151 | logprob = 0.2700 | KL term = 0.20247848510742186\n",
      "Epoch 19920:         train accuracy = 0.1151 | logprob = 0.2700 | KL term = 0.20244207763671876\n",
      "Epoch 19940:         train accuracy = 0.1151 | logprob = 0.2700 | KL term = 0.20240606689453125\n",
      "Epoch 19960:         train accuracy = 0.1151 | logprob = 0.2701 | KL term = 0.20237051391601563\n",
      "Epoch 19980:         train accuracy = 0.1150 | logprob = 0.2701 | KL term = 0.20233552551269532\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "run(toy_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将之前的数据集整体增大10倍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-11, 16)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def base_model_10(x):\n",
    "    return 10*(-(x+0.5)*np.sin(3 * np.pi *x))\n",
    "\n",
    "def noise_model_10(x):\n",
    "    return 10*(0.45*(x+0.5)**2)\n",
    "\n",
    "def sample_data_10(x):\n",
    "    return base_model_10(x) + np.random.normal(0, noise_model_10(x))\n",
    "\n",
    "data_size = {'train': 500, 'valid': 100, 'test': 100}\n",
    "toy_data = []\n",
    "for section in ['train', 'valid', 'test']:\n",
    "    x = (np.random.rand(data_size['train'], 1) - 0.5)\n",
    "    toy_data.append([x, sample_data_10(x).reshape(-1)])    \n",
    "x = np.arange(-1,1,1/100)\n",
    "toy_data.append([[[_] for _ in x], base_model_10(x)])\n",
    "\n",
    "pu.toy_results_plot(toy_data, {'mean':base_model_10, 'std':noise_model_10})\n",
    "plt.ylim([-11,16])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同样的方式进行训练，并得到DVI和MCVI之间的比较"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "* RUN ID: 20200104_234748_28154 \n",
      "********************************************************************************\n",
      "{'x_dim': 1, 'y_dim': 2, 'hidden_dims': [5, 5, 5], 'nonlinearity': 'relu', 'adapter': {'in': {'scale': [[1.0]], 'shift': [[0.0]]}, 'out': {'scale': [[1.0, 0.83]], 'shift': [[0.0, -3.5]]}}, 'method': 'bayes', 'style': 'heteroskedastic', 'homo_logvar_scale': -3.2188758248682006, 'prior_type': ['empirical', 'wider_he', 'wider_he'], 'n_epochs': 20000, 'batch_size': 500, 'learning_rate': 0.001, 'lambda': 1.0, 'warmup_updates': {'lambda': 14000.0}, 'anneal_updates': {'lambda': 1000.0}, 'optimizer': 'adam', 'gradient_clip': 0.1, 'data_fraction': 1.0, 'sections_to_run': ['train'], 'dataset_size': 500}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:         train accuracy = 4.3635 | logprob = -inf | KL term = 0.06878518676757812\n",
      "Epoch 20:         train accuracy = 4.3204 | logprob = -inf | KL term = 0.07073880004882813\n",
      "Epoch 40:         train accuracy = 4.2759 | logprob = -inf | KL term = 0.07277230072021484\n",
      "Epoch 60:         train accuracy = 4.2179 | logprob = -inf | KL term = 0.0748834228515625\n",
      "Epoch 80:         train accuracy = 4.1555 | logprob = -inf | KL term = 0.0770750961303711\n",
      "Epoch 100:         train accuracy = 4.0947 | logprob = -inf | KL term = 0.07934889221191406\n",
      "Epoch 120:         train accuracy = 4.0382 | logprob = -inf | KL term = 0.08170535278320312\n",
      "Epoch 140:         train accuracy = 3.9845 | logprob = -inf | KL term = 0.08413069152832031\n",
      "Epoch 160:         train accuracy = 3.9006 | logprob = -10542647963041986663501606682624.0000 | KL term = 0.08604893493652344\n",
      "Epoch 180:         train accuracy = 3.8233 | logprob = -28144321948781160440004608.0000 | KL term = 0.08766114807128907\n",
      "Epoch 200:         train accuracy = 3.7633 | logprob = -676726290763665637376.0000 | KL term = 0.08929671478271485\n",
      "Epoch 220:         train accuracy = 3.7175 | logprob = -113035851239260160.0000 | KL term = 0.0910377197265625\n",
      "Epoch 240:         train accuracy = 3.6811 | logprob = -96620255379456.0000 | KL term = 0.09287060546875\n",
      "Epoch 260:         train accuracy = 3.6513 | logprob = -323309502464.0000 | KL term = 0.09475192260742188\n",
      "Epoch 280:         train accuracy = 3.6274 | logprob = -3354930176.0000 | KL term = 0.09669346618652344\n",
      "Epoch 300:         train accuracy = 3.6079 | logprob = -87865160.0000 | KL term = 0.09872021484375\n",
      "Epoch 320:         train accuracy = 3.5918 | logprob = -4898847.0000 | KL term = 0.10077925872802734\n",
      "Epoch 340:         train accuracy = 3.5788 | logprob = -503497.5938 | KL term = 0.10286051940917969\n",
      "Epoch 360:         train accuracy = 3.5686 | logprob = -83570.3047 | KL term = 0.10495071411132813\n",
      "Epoch 380:         train accuracy = 3.5605 | logprob = -20265.8457 | KL term = 0.10700285339355468\n",
      "Epoch 400:         train accuracy = 3.5543 | logprob = -6706.0684 | KL term = 0.1090735321044922\n",
      "Epoch 420:         train accuracy = 3.5494 | logprob = -2865.8721 | KL term = 0.11119895935058594\n",
      "Epoch 440:         train accuracy = 3.5453 | logprob = -1506.2947 | KL term = 0.1133922348022461\n",
      "Epoch 460:         train accuracy = 3.5422 | logprob = -931.1634 | KL term = 0.11569219970703125\n",
      "Epoch 480:         train accuracy = 3.5403 | logprob = -651.6943 | KL term = 0.11808482360839843\n",
      "Epoch 500:         train accuracy = 3.5391 | logprob = -500.3241 | KL term = 0.12055180358886719\n",
      "Epoch 520:         train accuracy = 3.5383 | logprob = -410.8941 | KL term = 0.12303388977050782\n",
      "Epoch 540:         train accuracy = 3.5379 | logprob = -354.3070 | KL term = 0.1255292205810547\n",
      "Epoch 560:         train accuracy = 3.5376 | logprob = -316.4794 | KL term = 0.12794422912597656\n",
      "Epoch 580:         train accuracy = 3.5377 | logprob = -290.0156 | KL term = 0.13030889892578126\n",
      "Epoch 600:         train accuracy = 3.5380 | logprob = -270.7407 | KL term = 0.13244010925292968\n",
      "Epoch 620:         train accuracy = 3.5384 | logprob = -256.1902 | KL term = 0.1343630828857422\n",
      "Epoch 640:         train accuracy = 3.5378 | logprob = -244.8409 | KL term = 0.13612234497070314\n",
      "Epoch 660:         train accuracy = 3.5369 | logprob = -235.6916 | KL term = 0.1377315673828125\n",
      "Epoch 680:         train accuracy = 3.5364 | logprob = -228.0988 | KL term = 0.13919613647460938\n",
      "Epoch 700:         train accuracy = 3.5362 | logprob = -221.6215 | KL term = 0.14050505065917968\n",
      "Epoch 720:         train accuracy = 3.5365 | logprob = -215.9436 | KL term = 0.14168397521972656\n",
      "Epoch 740:         train accuracy = 3.5371 | logprob = -210.8474 | KL term = 0.1427845916748047\n",
      "Epoch 760:         train accuracy = 3.5377 | logprob = -206.1647 | KL term = 0.14379248046875\n",
      "Epoch 780:         train accuracy = 3.5385 | logprob = -201.7502 | KL term = 0.144670166015625\n",
      "Epoch 800:         train accuracy = 3.5392 | logprob = -197.4904 | KL term = 0.14543740844726563\n",
      "Epoch 820:         train accuracy = 3.5401 | logprob = -193.2991 | KL term = 0.14610952758789061\n",
      "Epoch 840:         train accuracy = 3.5410 | logprob = -189.1189 | KL term = 0.14670742797851563\n",
      "Epoch 860:         train accuracy = 3.5418 | logprob = -184.9182 | KL term = 0.14723440551757813\n",
      "Epoch 880:         train accuracy = 3.5425 | logprob = -180.6719 | KL term = 0.1476685791015625\n",
      "Epoch 900:         train accuracy = 3.5431 | logprob = -176.3624 | KL term = 0.14805087280273438\n",
      "Epoch 920:         train accuracy = 3.5435 | logprob = -171.9816 | KL term = 0.14842156982421875\n",
      "Epoch 940:         train accuracy = 3.5438 | logprob = -167.5305 | KL term = 0.14881517028808594\n",
      "Epoch 960:         train accuracy = 3.5439 | logprob = -163.0193 | KL term = 0.14925892639160157\n",
      "Epoch 980:         train accuracy = 3.5440 | logprob = -158.4597 | KL term = 0.14979928588867186\n",
      "Epoch 1000:         train accuracy = 3.5443 | logprob = -153.8436 | KL term = 0.15044020080566406\n",
      "Epoch 1020:         train accuracy = 3.5446 | logprob = -149.1730 | KL term = 0.15114080810546876\n",
      "Epoch 1040:         train accuracy = 3.5449 | logprob = -144.4630 | KL term = 0.1518681182861328\n",
      "Epoch 1060:         train accuracy = 3.5452 | logprob = -139.7321 | KL term = 0.1526033172607422\n",
      "Epoch 1080:         train accuracy = 3.5454 | logprob = -135.0008 | KL term = 0.1533165283203125\n",
      "Epoch 1100:         train accuracy = 3.5453 | logprob = -130.2868 | KL term = 0.15396694946289063\n",
      "Epoch 1120:         train accuracy = 3.5452 | logprob = -125.6101 | KL term = 0.15458660888671874\n",
      "Epoch 1140:         train accuracy = 3.5453 | logprob = -120.9874 | KL term = 0.1552457275390625\n",
      "Epoch 1160:         train accuracy = 3.5454 | logprob = -116.4310 | KL term = 0.15591386413574218\n",
      "Epoch 1180:         train accuracy = 3.5454 | logprob = -111.9376 | KL term = 0.15655497741699217\n",
      "Epoch 1200:         train accuracy = 3.5452 | logprob = -107.5126 | KL term = 0.15719049072265626\n",
      "Epoch 1220:         train accuracy = 3.5450 | logprob = -103.1670 | KL term = 0.15782626342773437\n",
      "Epoch 1240:         train accuracy = 3.5447 | logprob = -98.9125 | KL term = 0.15848678588867188\n",
      "Epoch 1260:         train accuracy = 3.5443 | logprob = -94.7599 | KL term = 0.1591678466796875\n",
      "Epoch 1280:         train accuracy = 3.5439 | logprob = -90.7141 | KL term = 0.15987899780273437\n",
      "Epoch 1300:         train accuracy = 3.5435 | logprob = -86.7694 | KL term = 0.16064080810546874\n",
      "Epoch 1320:         train accuracy = 3.5430 | logprob = -82.8716 | KL term = 0.16144747924804687\n",
      "Epoch 1340:         train accuracy = 3.5423 | logprob = -79.0018 | KL term = 0.16225177001953126\n",
      "Epoch 1360:         train accuracy = 3.5414 | logprob = -75.1605 | KL term = 0.16307676696777343\n",
      "Epoch 1380:         train accuracy = 3.5402 | logprob = -71.3553 | KL term = 0.163948974609375\n",
      "Epoch 1400:         train accuracy = 3.5389 | logprob = -67.5959 | KL term = 0.16487564086914064\n",
      "Epoch 1420:         train accuracy = 3.5375 | logprob = -63.8932 | KL term = 0.1658420867919922\n",
      "Epoch 1440:         train accuracy = 3.5359 | logprob = -60.2586 | KL term = 0.16682867431640624\n",
      "Epoch 1460:         train accuracy = 3.5343 | logprob = -56.7034 | KL term = 0.16782414245605468\n",
      "Epoch 1480:         train accuracy = 3.5326 | logprob = -53.2384 | KL term = 0.16881015014648437\n",
      "Epoch 1500:         train accuracy = 3.5310 | logprob = -49.8717 | KL term = 0.16976150512695312\n",
      "Epoch 1520:         train accuracy = 3.5296 | logprob = -46.6082 | KL term = 0.1706339416503906\n",
      "Epoch 1540:         train accuracy = 3.5282 | logprob = -43.4490 | KL term = 0.17142591857910155\n",
      "Epoch 1560:         train accuracy = 3.5270 | logprob = -40.3933 | KL term = 0.17212307739257812\n",
      "Epoch 1580:         train accuracy = 3.5257 | logprob = -37.4390 | KL term = 0.17271711730957032\n",
      "Epoch 1600:         train accuracy = 3.5241 | logprob = -34.5819 | KL term = 0.17320928955078124\n",
      "Epoch 1620:         train accuracy = 3.5222 | logprob = -31.8178 | KL term = 0.1736376495361328\n",
      "Epoch 1640:         train accuracy = 3.5196 | logprob = -29.1472 | KL term = 0.17406100463867188\n",
      "Epoch 1660:         train accuracy = 3.5164 | logprob = -26.5776 | KL term = 0.17451356506347657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1680:         train accuracy = 3.5125 | logprob = -24.1234 | KL term = 0.1750203857421875\n",
      "Epoch 1700:         train accuracy = 3.5079 | logprob = -21.8053 | KL term = 0.17559906005859374\n",
      "Epoch 1720:         train accuracy = 3.5027 | logprob = -19.6519 | KL term = 0.17627027893066408\n",
      "Epoch 1740:         train accuracy = 3.4969 | logprob = -17.6836 | KL term = 0.1770633544921875\n",
      "Epoch 1760:         train accuracy = 3.4911 | logprob = -15.9102 | KL term = 0.17802879333496094\n",
      "Epoch 1780:         train accuracy = 3.4867 | logprob = -14.3182 | KL term = 0.17921037292480468\n",
      "Epoch 1800:         train accuracy = 3.4850 | logprob = -12.8752 | KL term = 0.180427978515625\n",
      "Epoch 1820:         train accuracy = 3.4852 | logprob = -11.5665 | KL term = 0.18165565490722657\n",
      "Epoch 1840:         train accuracy = 3.4867 | logprob = -10.3878 | KL term = 0.18291177368164063\n",
      "Epoch 1860:         train accuracy = 3.4892 | logprob = -9.3261 | KL term = 0.18417933654785157\n",
      "Epoch 1880:         train accuracy = 3.4927 | logprob = -8.3662 | KL term = 0.18545744323730468\n",
      "Epoch 1900:         train accuracy = 3.4970 | logprob = -7.5037 | KL term = 0.18673736572265626\n",
      "Epoch 1920:         train accuracy = 3.5020 | logprob = -6.7350 | KL term = 0.1880201416015625\n",
      "Epoch 1940:         train accuracy = 3.5074 | logprob = -6.0565 | KL term = 0.18930966186523437\n",
      "Epoch 1960:         train accuracy = 3.5135 | logprob = -5.4650 | KL term = 0.19059965515136718\n",
      "Epoch 1980:         train accuracy = 3.5207 | logprob = -4.9569 | KL term = 0.19188186645507813\n",
      "Epoch 2000:         train accuracy = 3.5282 | logprob = -4.5277 | KL term = 0.19315139770507814\n",
      "Epoch 2020:         train accuracy = 3.5354 | logprob = -4.1727 | KL term = 0.19440353393554688\n",
      "Epoch 2040:         train accuracy = 3.5420 | logprob = -3.8863 | KL term = 0.19562960815429686\n",
      "Epoch 2060:         train accuracy = 3.5476 | logprob = -3.6624 | KL term = 0.19680320739746093\n",
      "Epoch 2080:         train accuracy = 3.5521 | logprob = -3.4921 | KL term = 0.197888671875\n",
      "Epoch 2100:         train accuracy = 3.5552 | logprob = -3.3655 | KL term = 0.1988792724609375\n",
      "Epoch 2120:         train accuracy = 3.5571 | logprob = -3.2723 | KL term = 0.19977436828613282\n",
      "Epoch 2140:         train accuracy = 3.5580 | logprob = -3.2033 | KL term = 0.20054794311523438\n",
      "Epoch 2160:         train accuracy = 3.5584 | logprob = -3.1515 | KL term = 0.20119659423828126\n",
      "Epoch 2180:         train accuracy = 3.5588 | logprob = -3.1123 | KL term = 0.20174481201171876\n",
      "Epoch 2200:         train accuracy = 3.5591 | logprob = -3.0825 | KL term = 0.2022110290527344\n",
      "Epoch 2220:         train accuracy = 3.5596 | logprob = -3.0596 | KL term = 0.20260304260253906\n",
      "Epoch 2240:         train accuracy = 3.5599 | logprob = -3.0418 | KL term = 0.2029364013671875\n",
      "Epoch 2260:         train accuracy = 3.5603 | logprob = -3.0273 | KL term = 0.20323675537109376\n",
      "Epoch 2280:         train accuracy = 3.5606 | logprob = -3.0152 | KL term = 0.20351516723632812\n",
      "Epoch 2300:         train accuracy = 3.5609 | logprob = -3.0047 | KL term = 0.20377545166015626\n",
      "Epoch 2320:         train accuracy = 3.5612 | logprob = -2.9955 | KL term = 0.20402078247070313\n",
      "Epoch 2340:         train accuracy = 3.5615 | logprob = -2.9873 | KL term = 0.2042532958984375\n",
      "Epoch 2360:         train accuracy = 3.5617 | logprob = -2.9800 | KL term = 0.20447454833984374\n",
      "Epoch 2380:         train accuracy = 3.5619 | logprob = -2.9734 | KL term = 0.20468618774414063\n",
      "Epoch 2400:         train accuracy = 3.5620 | logprob = -2.9674 | KL term = 0.20488973999023438\n",
      "Epoch 2420:         train accuracy = 3.5622 | logprob = -2.9618 | KL term = 0.20508650207519533\n",
      "Epoch 2440:         train accuracy = 3.5623 | logprob = -2.9564 | KL term = 0.20527757263183594\n",
      "Epoch 2460:         train accuracy = 3.5623 | logprob = -2.9514 | KL term = 0.20546383666992188\n",
      "Epoch 2480:         train accuracy = 3.5624 | logprob = -2.9466 | KL term = 0.20564605712890624\n",
      "Epoch 2500:         train accuracy = 3.5624 | logprob = -2.9420 | KL term = 0.20582489013671876\n",
      "Epoch 2520:         train accuracy = 3.5624 | logprob = -2.9375 | KL term = 0.2060009002685547\n",
      "Epoch 2540:         train accuracy = 3.5624 | logprob = -2.9331 | KL term = 0.20617454528808593\n",
      "Epoch 2560:         train accuracy = 3.5624 | logprob = -2.9288 | KL term = 0.20634626770019532\n",
      "Epoch 2580:         train accuracy = 3.5623 | logprob = -2.9246 | KL term = 0.2065164031982422\n",
      "Epoch 2600:         train accuracy = 3.5623 | logprob = -2.9204 | KL term = 0.20668524169921876\n",
      "Epoch 2620:         train accuracy = 3.5622 | logprob = -2.9163 | KL term = 0.2068531494140625\n",
      "Epoch 2640:         train accuracy = 3.5621 | logprob = -2.9122 | KL term = 0.2070203399658203\n",
      "Epoch 2660:         train accuracy = 3.5620 | logprob = -2.9081 | KL term = 0.20718707275390624\n",
      "Epoch 2680:         train accuracy = 3.5620 | logprob = -2.9041 | KL term = 0.20735348510742188\n",
      "Epoch 2700:         train accuracy = 3.5619 | logprob = -2.9000 | KL term = 0.20751974487304686\n",
      "Epoch 2720:         train accuracy = 3.5619 | logprob = -2.8960 | KL term = 0.2076861114501953\n",
      "Epoch 2740:         train accuracy = 3.5619 | logprob = -2.8919 | KL term = 0.2078526611328125\n",
      "Epoch 2760:         train accuracy = 3.5619 | logprob = -2.8878 | KL term = 0.20801953125\n",
      "Epoch 2780:         train accuracy = 3.5619 | logprob = -2.8837 | KL term = 0.20818684387207032\n",
      "Epoch 2800:         train accuracy = 3.5620 | logprob = -2.8796 | KL term = 0.20835478210449218\n",
      "Epoch 2820:         train accuracy = 3.5621 | logprob = -2.8755 | KL term = 0.20852339172363282\n",
      "Epoch 2840:         train accuracy = 3.5622 | logprob = -2.8714 | KL term = 0.20869281005859375\n",
      "Epoch 2860:         train accuracy = 3.5624 | logprob = -2.8672 | KL term = 0.20886309814453125\n",
      "Epoch 2880:         train accuracy = 3.5626 | logprob = -2.8630 | KL term = 0.20903436279296875\n",
      "Epoch 2900:         train accuracy = 3.5629 | logprob = -2.8588 | KL term = 0.2092067108154297\n",
      "Epoch 2920:         train accuracy = 3.5632 | logprob = -2.8545 | KL term = 0.20938018798828126\n",
      "Epoch 2940:         train accuracy = 3.5636 | logprob = -2.8502 | KL term = 0.20955494689941406\n",
      "Epoch 2960:         train accuracy = 3.5642 | logprob = -2.8459 | KL term = 0.2097310028076172\n",
      "Epoch 2980:         train accuracy = 3.5649 | logprob = -2.8416 | KL term = 0.209908447265625\n",
      "Epoch 3000:         train accuracy = 3.5656 | logprob = -2.8372 | KL term = 0.21008741760253907\n",
      "Epoch 3020:         train accuracy = 3.5664 | logprob = -2.8329 | KL term = 0.2102679443359375\n",
      "Epoch 3040:         train accuracy = 3.5674 | logprob = -2.8285 | KL term = 0.2104501495361328\n",
      "Epoch 3060:         train accuracy = 3.5683 | logprob = -2.8241 | KL term = 0.21063410949707032\n",
      "Epoch 3080:         train accuracy = 3.5695 | logprob = -2.8196 | KL term = 0.21081988525390624\n",
      "Epoch 3100:         train accuracy = 3.5707 | logprob = -2.8152 | KL term = 0.21100762939453124\n",
      "Epoch 3120:         train accuracy = 3.5721 | logprob = -2.8108 | KL term = 0.21119735717773438\n",
      "Epoch 3140:         train accuracy = 3.5737 | logprob = -2.8063 | KL term = 0.21138917541503907\n",
      "Epoch 3160:         train accuracy = 3.5755 | logprob = -2.8019 | KL term = 0.2115832061767578\n",
      "Epoch 3180:         train accuracy = 3.5774 | logprob = -2.7975 | KL term = 0.21177952575683595\n",
      "Epoch 3200:         train accuracy = 3.5794 | logprob = -2.7931 | KL term = 0.21197817993164061\n",
      "Epoch 3220:         train accuracy = 3.5817 | logprob = -2.7887 | KL term = 0.21217929077148437\n",
      "Epoch 3240:         train accuracy = 3.5841 | logprob = -2.7844 | KL term = 0.21238290405273438\n",
      "Epoch 3260:         train accuracy = 3.5866 | logprob = -2.7801 | KL term = 0.21258908081054687\n",
      "Epoch 3280:         train accuracy = 3.5891 | logprob = -2.7759 | KL term = 0.21279788208007813\n",
      "Epoch 3300:         train accuracy = 3.5918 | logprob = -2.7717 | KL term = 0.21300933837890626\n",
      "Epoch 3320:         train accuracy = 3.5945 | logprob = -2.7675 | KL term = 0.21322354125976561\n",
      "Epoch 3340:         train accuracy = 3.5974 | logprob = -2.7635 | KL term = 0.21344039916992188\n",
      "Epoch 3360:         train accuracy = 3.6004 | logprob = -2.7595 | KL term = 0.21366001892089845\n",
      "Epoch 3380:         train accuracy = 3.6034 | logprob = -2.7556 | KL term = 0.21388233947753907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3400:         train accuracy = 3.6065 | logprob = -2.7518 | KL term = 0.2141073760986328\n",
      "Epoch 3420:         train accuracy = 3.6097 | logprob = -2.7481 | KL term = 0.21433506774902344\n",
      "Epoch 3440:         train accuracy = 3.6128 | logprob = -2.7445 | KL term = 0.21456533813476564\n",
      "Epoch 3460:         train accuracy = 3.6160 | logprob = -2.7410 | KL term = 0.21479811096191406\n",
      "Epoch 3480:         train accuracy = 3.6193 | logprob = -2.7375 | KL term = 0.21503337097167968\n",
      "Epoch 3500:         train accuracy = 3.6225 | logprob = -2.7342 | KL term = 0.21527093505859374\n",
      "Epoch 3520:         train accuracy = 3.6257 | logprob = -2.7310 | KL term = 0.21551075744628906\n",
      "Epoch 3540:         train accuracy = 3.6291 | logprob = -2.7279 | KL term = 0.215752685546875\n",
      "Epoch 3560:         train accuracy = 3.6324 | logprob = -2.7249 | KL term = 0.2159966278076172\n",
      "Epoch 3580:         train accuracy = 3.6356 | logprob = -2.7220 | KL term = 0.21624249267578124\n",
      "Epoch 3600:         train accuracy = 3.6389 | logprob = -2.7191 | KL term = 0.21649012756347658\n",
      "Epoch 3620:         train accuracy = 3.6420 | logprob = -2.7164 | KL term = 0.2167394256591797\n",
      "Epoch 3640:         train accuracy = 3.6451 | logprob = -2.7137 | KL term = 0.21699024963378907\n",
      "Epoch 3660:         train accuracy = 3.6482 | logprob = -2.7112 | KL term = 0.21724252319335938\n",
      "Epoch 3680:         train accuracy = 3.6511 | logprob = -2.7087 | KL term = 0.2174961242675781\n",
      "Epoch 3700:         train accuracy = 3.6542 | logprob = -2.7062 | KL term = 0.21775099182128907\n",
      "Epoch 3720:         train accuracy = 3.6572 | logprob = -2.7039 | KL term = 0.2180070343017578\n",
      "Epoch 3740:         train accuracy = 3.6601 | logprob = -2.7016 | KL term = 0.21826423645019533\n",
      "Epoch 3760:         train accuracy = 3.6630 | logprob = -2.6993 | KL term = 0.21852253723144532\n",
      "Epoch 3780:         train accuracy = 3.6659 | logprob = -2.6971 | KL term = 0.2187819061279297\n",
      "Epoch 3800:         train accuracy = 3.6688 | logprob = -2.6950 | KL term = 0.21904234313964843\n",
      "Epoch 3820:         train accuracy = 3.6716 | logprob = -2.6929 | KL term = 0.21930386352539064\n",
      "Epoch 3840:         train accuracy = 3.6744 | logprob = -2.6908 | KL term = 0.21956645202636718\n",
      "Epoch 3860:         train accuracy = 3.6772 | logprob = -2.6888 | KL term = 0.2198301696777344\n",
      "Epoch 3880:         train accuracy = 3.6800 | logprob = -2.6867 | KL term = 0.22009510803222657\n",
      "Epoch 3900:         train accuracy = 3.6829 | logprob = -2.6848 | KL term = 0.22036125183105468\n",
      "Epoch 3920:         train accuracy = 3.6858 | logprob = -2.6828 | KL term = 0.22062869262695312\n",
      "Epoch 3940:         train accuracy = 3.6888 | logprob = -2.6808 | KL term = 0.22089749145507812\n",
      "Epoch 3960:         train accuracy = 3.6918 | logprob = -2.6789 | KL term = 0.22116778564453124\n",
      "Epoch 3980:         train accuracy = 3.6949 | logprob = -2.6769 | KL term = 0.22143959045410155\n",
      "Epoch 4000:         train accuracy = 3.6981 | logprob = -2.6750 | KL term = 0.2217130126953125\n",
      "Epoch 4020:         train accuracy = 3.7015 | logprob = -2.6731 | KL term = 0.2219881591796875\n",
      "Epoch 4040:         train accuracy = 3.7049 | logprob = -2.6711 | KL term = 0.22226513671875\n",
      "Epoch 4060:         train accuracy = 3.7085 | logprob = -2.6692 | KL term = 0.22254397583007812\n",
      "Epoch 4080:         train accuracy = 3.7124 | logprob = -2.6673 | KL term = 0.22282484436035158\n",
      "Epoch 4100:         train accuracy = 3.7166 | logprob = -2.6653 | KL term = 0.22310783386230468\n",
      "Epoch 4120:         train accuracy = 3.7209 | logprob = -2.6633 | KL term = 0.22339306640625\n",
      "Epoch 4140:         train accuracy = 3.7257 | logprob = -2.6613 | KL term = 0.22368060302734374\n",
      "Epoch 4160:         train accuracy = 3.7308 | logprob = -2.6593 | KL term = 0.22397064208984374\n",
      "Epoch 4180:         train accuracy = 3.7361 | logprob = -2.6573 | KL term = 0.2242632598876953\n",
      "Epoch 4200:         train accuracy = 3.7417 | logprob = -2.6552 | KL term = 0.22455865478515624\n",
      "Epoch 4220:         train accuracy = 3.7478 | logprob = -2.6531 | KL term = 0.22485696411132813\n",
      "Epoch 4240:         train accuracy = 3.7543 | logprob = -2.6510 | KL term = 0.22515837097167968\n",
      "Epoch 4260:         train accuracy = 3.7613 | logprob = -2.6489 | KL term = 0.22546310424804689\n",
      "Epoch 4280:         train accuracy = 3.7687 | logprob = -2.6467 | KL term = 0.2257713623046875\n",
      "Epoch 4300:         train accuracy = 3.7765 | logprob = -2.6444 | KL term = 0.2260833740234375\n",
      "Epoch 4320:         train accuracy = 3.7849 | logprob = -2.6421 | KL term = 0.22639944458007813\n",
      "Epoch 4340:         train accuracy = 3.7937 | logprob = -2.6398 | KL term = 0.22671983337402343\n",
      "Epoch 4360:         train accuracy = 3.8031 | logprob = -2.6374 | KL term = 0.22704486083984374\n",
      "Epoch 4380:         train accuracy = 3.8130 | logprob = -2.6349 | KL term = 0.227374755859375\n",
      "Epoch 4400:         train accuracy = 3.8235 | logprob = -2.6324 | KL term = 0.22770993041992188\n",
      "Epoch 4420:         train accuracy = 3.8343 | logprob = -2.6298 | KL term = 0.22805064392089844\n",
      "Epoch 4440:         train accuracy = 3.8458 | logprob = -2.6272 | KL term = 0.2283972625732422\n",
      "Epoch 4460:         train accuracy = 3.8581 | logprob = -2.6244 | KL term = 0.2287500762939453\n",
      "Epoch 4480:         train accuracy = 3.8711 | logprob = -2.6216 | KL term = 0.22910940551757814\n",
      "Epoch 4500:         train accuracy = 3.8850 | logprob = -2.6187 | KL term = 0.22947549438476564\n",
      "Epoch 4520:         train accuracy = 3.9001 | logprob = -2.6157 | KL term = 0.22984854125976562\n",
      "Epoch 4540:         train accuracy = 3.9160 | logprob = -2.6126 | KL term = 0.23022857666015625\n",
      "Epoch 4560:         train accuracy = 3.9330 | logprob = -2.6094 | KL term = 0.23061569213867186\n",
      "Epoch 4580:         train accuracy = 3.9515 | logprob = -2.6061 | KL term = 0.23100968933105467\n",
      "Epoch 4600:         train accuracy = 3.9717 | logprob = -2.6028 | KL term = 0.2314103240966797\n",
      "Epoch 4620:         train accuracy = 3.9950 | logprob = -2.5994 | KL term = 0.23181706237792968\n",
      "Epoch 4640:         train accuracy = 4.0196 | logprob = -2.5960 | KL term = 0.2322292938232422\n",
      "Epoch 4660:         train accuracy = 4.0451 | logprob = -2.5926 | KL term = 0.23264614868164063\n",
      "Epoch 4680:         train accuracy = 4.0711 | logprob = -2.5892 | KL term = 0.23306660461425782\n",
      "Epoch 4700:         train accuracy = 4.0973 | logprob = -2.5858 | KL term = 0.233489501953125\n",
      "Epoch 4720:         train accuracy = 4.1239 | logprob = -2.5824 | KL term = 0.23391357421875\n",
      "Epoch 4740:         train accuracy = 4.1512 | logprob = -2.5792 | KL term = 0.23433741760253907\n",
      "Epoch 4760:         train accuracy = 4.1777 | logprob = -2.5760 | KL term = 0.2347596740722656\n",
      "Epoch 4780:         train accuracy = 4.2036 | logprob = -2.5730 | KL term = 0.23517892456054687\n",
      "Epoch 4800:         train accuracy = 4.2297 | logprob = -2.5700 | KL term = 0.23559393310546875\n",
      "Epoch 4820:         train accuracy = 4.2549 | logprob = -2.5672 | KL term = 0.23600355529785155\n",
      "Epoch 4840:         train accuracy = 4.2789 | logprob = -2.5646 | KL term = 0.2364067840576172\n",
      "Epoch 4860:         train accuracy = 4.3015 | logprob = -2.5620 | KL term = 0.23680287170410155\n",
      "Epoch 4880:         train accuracy = 4.3223 | logprob = -2.5596 | KL term = 0.23719131469726562\n",
      "Epoch 4900:         train accuracy = 4.3412 | logprob = -2.5573 | KL term = 0.23757176208496095\n",
      "Epoch 4920:         train accuracy = 4.3585 | logprob = -2.5550 | KL term = 0.23794412231445314\n",
      "Epoch 4940:         train accuracy = 4.3738 | logprob = -2.5529 | KL term = 0.2383084716796875\n",
      "Epoch 4960:         train accuracy = 4.3873 | logprob = -2.5509 | KL term = 0.23866506958007813\n",
      "Epoch 4980:         train accuracy = 4.3990 | logprob = -2.5489 | KL term = 0.23901426696777345\n",
      "Epoch 5000:         train accuracy = 4.4092 | logprob = -2.5470 | KL term = 0.23935655212402343\n",
      "Epoch 5020:         train accuracy = 4.4180 | logprob = -2.5451 | KL term = 0.2396923828125\n",
      "Epoch 5040:         train accuracy = 4.4253 | logprob = -2.5433 | KL term = 0.24002229309082032\n",
      "Epoch 5060:         train accuracy = 4.4312 | logprob = -2.5415 | KL term = 0.24034686279296874\n",
      "Epoch 5080:         train accuracy = 4.4360 | logprob = -2.5397 | KL term = 0.24066650390625\n",
      "Epoch 5100:         train accuracy = 4.4397 | logprob = -2.5380 | KL term = 0.24098175048828124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5120:         train accuracy = 4.4424 | logprob = -2.5363 | KL term = 0.2412930908203125\n",
      "Epoch 5140:         train accuracy = 4.4443 | logprob = -2.5347 | KL term = 0.24160086059570313\n",
      "Epoch 5160:         train accuracy = 4.4454 | logprob = -2.5330 | KL term = 0.24190545654296874\n",
      "Epoch 5180:         train accuracy = 4.4459 | logprob = -2.5314 | KL term = 0.24220718383789064\n",
      "Epoch 5200:         train accuracy = 4.4458 | logprob = -2.5298 | KL term = 0.24250631713867188\n",
      "Epoch 5220:         train accuracy = 4.4451 | logprob = -2.5283 | KL term = 0.2428031005859375\n",
      "Epoch 5240:         train accuracy = 4.4439 | logprob = -2.5267 | KL term = 0.24309768676757812\n",
      "Epoch 5260:         train accuracy = 4.4423 | logprob = -2.5252 | KL term = 0.2433902893066406\n",
      "Epoch 5280:         train accuracy = 4.4404 | logprob = -2.5236 | KL term = 0.24368106079101562\n",
      "Epoch 5300:         train accuracy = 4.4381 | logprob = -2.5221 | KL term = 0.24397010803222657\n",
      "Epoch 5320:         train accuracy = 4.4355 | logprob = -2.5206 | KL term = 0.244257568359375\n",
      "Epoch 5340:         train accuracy = 4.4327 | logprob = -2.5192 | KL term = 0.24454348754882813\n",
      "Epoch 5360:         train accuracy = 4.4295 | logprob = -2.5177 | KL term = 0.2448280029296875\n",
      "Epoch 5380:         train accuracy = 4.4261 | logprob = -2.5163 | KL term = 0.24511111450195314\n",
      "Epoch 5400:         train accuracy = 4.4224 | logprob = -2.5148 | KL term = 0.24539297485351563\n",
      "Epoch 5420:         train accuracy = 4.4185 | logprob = -2.5134 | KL term = 0.24567364501953126\n",
      "Epoch 5440:         train accuracy = 4.4144 | logprob = -2.5120 | KL term = 0.24595310974121093\n",
      "Epoch 5460:         train accuracy = 4.4101 | logprob = -2.5106 | KL term = 0.2462314910888672\n",
      "Epoch 5480:         train accuracy = 4.4056 | logprob = -2.5092 | KL term = 0.24650883483886718\n",
      "Epoch 5500:         train accuracy = 4.4009 | logprob = -2.5078 | KL term = 0.24678518676757813\n",
      "Epoch 5520:         train accuracy = 4.3960 | logprob = -2.5064 | KL term = 0.2470605773925781\n",
      "Epoch 5540:         train accuracy = 4.3909 | logprob = -2.5051 | KL term = 0.24733509826660155\n",
      "Epoch 5560:         train accuracy = 4.3857 | logprob = -2.5037 | KL term = 0.24760874938964844\n",
      "Epoch 5580:         train accuracy = 4.3804 | logprob = -2.5024 | KL term = 0.24788162231445313\n",
      "Epoch 5600:         train accuracy = 4.3748 | logprob = -2.5011 | KL term = 0.24815374755859376\n",
      "Epoch 5620:         train accuracy = 4.3691 | logprob = -2.4997 | KL term = 0.2484251708984375\n",
      "Epoch 5640:         train accuracy = 4.3633 | logprob = -2.4984 | KL term = 0.24869590759277344\n",
      "Epoch 5660:         train accuracy = 4.3573 | logprob = -2.4971 | KL term = 0.24896604919433593\n",
      "Epoch 5680:         train accuracy = 4.3512 | logprob = -2.4958 | KL term = 0.24923558044433594\n",
      "Epoch 5700:         train accuracy = 4.3450 | logprob = -2.4945 | KL term = 0.2495045928955078\n",
      "Epoch 5720:         train accuracy = 4.3386 | logprob = -2.4932 | KL term = 0.2497730712890625\n",
      "Epoch 5740:         train accuracy = 4.3321 | logprob = -2.4920 | KL term = 0.2500410919189453\n",
      "Epoch 5760:         train accuracy = 4.3255 | logprob = -2.4907 | KL term = 0.25030863952636717\n",
      "Epoch 5780:         train accuracy = 4.3188 | logprob = -2.4894 | KL term = 0.2505758056640625\n",
      "Epoch 5800:         train accuracy = 4.3120 | logprob = -2.4882 | KL term = 0.25084255981445314\n",
      "Epoch 5820:         train accuracy = 4.3051 | logprob = -2.4869 | KL term = 0.25110894775390624\n",
      "Epoch 5840:         train accuracy = 4.2981 | logprob = -2.4857 | KL term = 0.25137503051757815\n",
      "Epoch 5860:         train accuracy = 4.2910 | logprob = -2.4845 | KL term = 0.25164080810546874\n",
      "Epoch 5880:         train accuracy = 4.2839 | logprob = -2.4832 | KL term = 0.25190628051757813\n",
      "Epoch 5900:         train accuracy = 4.2768 | logprob = -2.4820 | KL term = 0.25217152404785154\n",
      "Epoch 5920:         train accuracy = 4.2696 | logprob = -2.4808 | KL term = 0.25243650817871094\n",
      "Epoch 5940:         train accuracy = 4.2623 | logprob = -2.4796 | KL term = 0.2527012786865234\n",
      "Epoch 5960:         train accuracy = 4.2550 | logprob = -2.4784 | KL term = 0.25296588134765624\n",
      "Epoch 5980:         train accuracy = 4.2477 | logprob = -2.4773 | KL term = 0.25323028564453126\n",
      "Epoch 6000:         train accuracy = 4.2404 | logprob = -2.4761 | KL term = 0.2534945373535156\n",
      "Epoch 6020:         train accuracy = 4.2331 | logprob = -2.4749 | KL term = 0.2537586669921875\n",
      "Epoch 6040:         train accuracy = 4.2257 | logprob = -2.4738 | KL term = 0.2540226745605469\n",
      "Epoch 6060:         train accuracy = 4.2184 | logprob = -2.4726 | KL term = 0.25428659057617187\n",
      "Epoch 6080:         train accuracy = 4.2111 | logprob = -2.4715 | KL term = 0.2545504150390625\n",
      "Epoch 6100:         train accuracy = 4.2038 | logprob = -2.4703 | KL term = 0.254814208984375\n",
      "Epoch 6120:         train accuracy = 4.1965 | logprob = -2.4692 | KL term = 0.25507794189453126\n",
      "Epoch 6140:         train accuracy = 4.1893 | logprob = -2.4681 | KL term = 0.2553416748046875\n",
      "Epoch 6160:         train accuracy = 4.1821 | logprob = -2.4670 | KL term = 0.2556053924560547\n",
      "Epoch 6180:         train accuracy = 4.1750 | logprob = -2.4659 | KL term = 0.25586915588378906\n",
      "Epoch 6200:         train accuracy = 4.1679 | logprob = -2.4648 | KL term = 0.2561329345703125\n",
      "Epoch 6220:         train accuracy = 4.1608 | logprob = -2.4637 | KL term = 0.25639678955078127\n",
      "Epoch 6240:         train accuracy = 4.1538 | logprob = -2.4627 | KL term = 0.25666070556640624\n",
      "Epoch 6260:         train accuracy = 4.1469 | logprob = -2.4616 | KL term = 0.25692474365234375\n",
      "Epoch 6280:         train accuracy = 4.1400 | logprob = -2.4606 | KL term = 0.25718890380859377\n",
      "Epoch 6300:         train accuracy = 4.1332 | logprob = -2.4595 | KL term = 0.25745318603515627\n",
      "Epoch 6320:         train accuracy = 4.1264 | logprob = -2.4585 | KL term = 0.25771762084960936\n",
      "Epoch 6340:         train accuracy = 4.1198 | logprob = -2.4575 | KL term = 0.2579822692871094\n",
      "Epoch 6360:         train accuracy = 4.1132 | logprob = -2.4565 | KL term = 0.2582471008300781\n",
      "Epoch 6380:         train accuracy = 4.1067 | logprob = -2.4555 | KL term = 0.25851214599609373\n",
      "Epoch 6400:         train accuracy = 4.1003 | logprob = -2.4545 | KL term = 0.2587774963378906\n",
      "Epoch 6420:         train accuracy = 4.0940 | logprob = -2.4535 | KL term = 0.2590430908203125\n",
      "Epoch 6440:         train accuracy = 4.0877 | logprob = -2.4525 | KL term = 0.2593089599609375\n",
      "Epoch 6460:         train accuracy = 4.0816 | logprob = -2.4515 | KL term = 0.2595751647949219\n",
      "Epoch 6480:         train accuracy = 4.0756 | logprob = -2.4506 | KL term = 0.2598416748046875\n",
      "Epoch 6500:         train accuracy = 4.0696 | logprob = -2.4496 | KL term = 0.2601085205078125\n",
      "Epoch 6520:         train accuracy = 4.0638 | logprob = -2.4486 | KL term = 0.26037576293945314\n",
      "Epoch 6540:         train accuracy = 4.0582 | logprob = -2.4477 | KL term = 0.26064334106445314\n",
      "Epoch 6560:         train accuracy = 4.0526 | logprob = -2.4468 | KL term = 0.26091131591796873\n",
      "Epoch 6580:         train accuracy = 4.0472 | logprob = -2.4458 | KL term = 0.2611796875\n",
      "Epoch 6600:         train accuracy = 4.0418 | logprob = -2.4449 | KL term = 0.26144842529296874\n",
      "Epoch 6620:         train accuracy = 4.0365 | logprob = -2.4440 | KL term = 0.261717529296875\n",
      "Epoch 6640:         train accuracy = 4.0314 | logprob = -2.4431 | KL term = 0.26198696899414065\n",
      "Epoch 6660:         train accuracy = 4.0263 | logprob = -2.4422 | KL term = 0.2622567749023437\n",
      "Epoch 6680:         train accuracy = 4.0213 | logprob = -2.4413 | KL term = 0.2625268859863281\n",
      "Epoch 6700:         train accuracy = 4.0164 | logprob = -2.4404 | KL term = 0.26279730224609377\n",
      "Epoch 6720:         train accuracy = 4.0115 | logprob = -2.4396 | KL term = 0.2630679321289062\n",
      "Epoch 6740:         train accuracy = 4.0068 | logprob = -2.4387 | KL term = 0.26333880615234373\n",
      "Epoch 6760:         train accuracy = 4.0021 | logprob = -2.4378 | KL term = 0.26360977172851563\n",
      "Epoch 6780:         train accuracy = 3.9975 | logprob = -2.4370 | KL term = 0.26388079833984374\n",
      "Epoch 6800:         train accuracy = 3.9929 | logprob = -2.4361 | KL term = 0.26415185546875\n",
      "Epoch 6820:         train accuracy = 3.9885 | logprob = -2.4353 | KL term = 0.2644228515625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6840:         train accuracy = 3.9841 | logprob = -2.4344 | KL term = 0.264693603515625\n",
      "Epoch 6860:         train accuracy = 3.9798 | logprob = -2.4336 | KL term = 0.26496405029296877\n",
      "Epoch 6880:         train accuracy = 3.9755 | logprob = -2.4328 | KL term = 0.265234130859375\n",
      "Epoch 6900:         train accuracy = 3.9713 | logprob = -2.4320 | KL term = 0.2655035400390625\n",
      "Epoch 6920:         train accuracy = 3.9672 | logprob = -2.4312 | KL term = 0.26577215576171875\n",
      "Epoch 6940:         train accuracy = 3.9631 | logprob = -2.4304 | KL term = 0.2660397033691406\n",
      "Epoch 6960:         train accuracy = 3.9590 | logprob = -2.4295 | KL term = 0.26630584716796873\n",
      "Epoch 6980:         train accuracy = 3.9550 | logprob = -2.4287 | KL term = 0.26657012939453123\n",
      "Epoch 7000:         train accuracy = 3.9509 | logprob = -2.4280 | KL term = 0.26683197021484373\n",
      "Epoch 7020:         train accuracy = 3.9470 | logprob = -2.4272 | KL term = 0.2670904235839844\n",
      "Epoch 7040:         train accuracy = 3.9430 | logprob = -2.4264 | KL term = 0.26734420776367185\n",
      "Epoch 7060:         train accuracy = 3.9390 | logprob = -2.4255 | KL term = 0.2675914306640625\n",
      "Epoch 7080:         train accuracy = 3.9349 | logprob = -2.4247 | KL term = 0.26782870483398435\n",
      "Epoch 7100:         train accuracy = 3.9307 | logprob = -2.4238 | KL term = 0.2680498962402344\n",
      "Epoch 7120:         train accuracy = 3.9259 | logprob = -2.4226 | KL term = 0.268243408203125\n",
      "Epoch 7140:         train accuracy = 3.9195 | logprob = -2.4204 | KL term = 0.26838772583007814\n",
      "Epoch 7160:         train accuracy = 3.9095 | logprob = -2.4154 | KL term = 0.26845953369140624\n",
      "Epoch 7180:         train accuracy = 3.8925 | logprob = -2.4052 | KL term = 0.2684995422363281\n",
      "Epoch 7200:         train accuracy = 3.8698 | logprob = -2.3942 | KL term = 0.268673828125\n",
      "Epoch 7220:         train accuracy = 3.8485 | logprob = -2.3864 | KL term = 0.2690868835449219\n",
      "Epoch 7240:         train accuracy = 3.8324 | logprob = -2.3809 | KL term = 0.26959686279296874\n",
      "Epoch 7260:         train accuracy = 3.8229 | logprob = -2.3770 | KL term = 0.27009762573242185\n",
      "Epoch 7280:         train accuracy = 3.8178 | logprob = -2.3741 | KL term = 0.27057040405273436\n",
      "Epoch 7300:         train accuracy = 3.8143 | logprob = -2.3718 | KL term = 0.2710185241699219\n",
      "Epoch 7320:         train accuracy = 3.8116 | logprob = -2.3698 | KL term = 0.2714483642578125\n",
      "Epoch 7340:         train accuracy = 3.8092 | logprob = -2.3681 | KL term = 0.2718642578125\n",
      "Epoch 7360:         train accuracy = 3.8069 | logprob = -2.3664 | KL term = 0.2722689819335937\n",
      "Epoch 7380:         train accuracy = 3.8045 | logprob = -2.3649 | KL term = 0.2726646728515625\n",
      "Epoch 7400:         train accuracy = 3.8019 | logprob = -2.3634 | KL term = 0.27305313110351564\n",
      "Epoch 7420:         train accuracy = 3.7991 | logprob = -2.3619 | KL term = 0.27343609619140624\n",
      "Epoch 7440:         train accuracy = 3.7961 | logprob = -2.3604 | KL term = 0.2738151550292969\n",
      "Epoch 7460:         train accuracy = 3.7929 | logprob = -2.3590 | KL term = 0.274191650390625\n",
      "Epoch 7480:         train accuracy = 3.7896 | logprob = -2.3575 | KL term = 0.2745667724609375\n",
      "Epoch 7500:         train accuracy = 3.7861 | logprob = -2.3561 | KL term = 0.27494158935546875\n",
      "Epoch 7520:         train accuracy = 3.7824 | logprob = -2.3546 | KL term = 0.27531695556640623\n",
      "Epoch 7540:         train accuracy = 3.7786 | logprob = -2.3531 | KL term = 0.27569366455078126\n",
      "Epoch 7560:         train accuracy = 3.7747 | logprob = -2.3516 | KL term = 0.27607244873046877\n",
      "Epoch 7580:         train accuracy = 3.7707 | logprob = -2.3501 | KL term = 0.2764541015625\n",
      "Epoch 7600:         train accuracy = 3.7666 | logprob = -2.3486 | KL term = 0.2768393859863281\n",
      "Epoch 7620:         train accuracy = 3.7623 | logprob = -2.3470 | KL term = 0.2772291259765625\n",
      "Epoch 7640:         train accuracy = 3.7579 | logprob = -2.3454 | KL term = 0.27762417602539063\n",
      "Epoch 7660:         train accuracy = 3.7535 | logprob = -2.3437 | KL term = 0.27802557373046877\n",
      "Epoch 7680:         train accuracy = 3.7488 | logprob = -2.3420 | KL term = 0.2784345703125\n",
      "Epoch 7700:         train accuracy = 3.7441 | logprob = -2.3402 | KL term = 0.2788524475097656\n",
      "Epoch 7720:         train accuracy = 3.7391 | logprob = -2.3383 | KL term = 0.2792807922363281\n",
      "Epoch 7740:         train accuracy = 3.7340 | logprob = -2.3364 | KL term = 0.27972149658203127\n",
      "Epoch 7760:         train accuracy = 3.7286 | logprob = -2.3343 | KL term = 0.28017669677734375\n",
      "Epoch 7780:         train accuracy = 3.7229 | logprob = -2.3322 | KL term = 0.28064892578125\n",
      "Epoch 7800:         train accuracy = 3.7168 | logprob = -2.3298 | KL term = 0.2811412353515625\n",
      "Epoch 7820:         train accuracy = 3.7103 | logprob = -2.3273 | KL term = 0.28165740966796876\n",
      "Epoch 7840:         train accuracy = 3.7033 | logprob = -2.3246 | KL term = 0.28220196533203123\n",
      "Epoch 7860:         train accuracy = 3.6956 | logprob = -2.3216 | KL term = 0.28278012084960935\n",
      "Epoch 7880:         train accuracy = 3.6873 | logprob = -2.3183 | KL term = 0.2833977966308594\n",
      "Epoch 7900:         train accuracy = 3.6781 | logprob = -2.3147 | KL term = 0.2840606689453125\n",
      "Epoch 7920:         train accuracy = 3.6681 | logprob = -2.3106 | KL term = 0.28477325439453127\n",
      "Epoch 7940:         train accuracy = 3.6569 | logprob = -2.3059 | KL term = 0.285537841796875\n",
      "Epoch 7960:         train accuracy = 3.6446 | logprob = -2.3007 | KL term = 0.28635443115234377\n",
      "Epoch 7980:         train accuracy = 3.6310 | logprob = -2.2947 | KL term = 0.2872208251953125\n",
      "Epoch 8000:         train accuracy = 3.6158 | logprob = -2.2879 | KL term = 0.28813412475585937\n",
      "Epoch 8020:         train accuracy = 3.5987 | logprob = -2.2800 | KL term = 0.28909149169921877\n",
      "Epoch 8040:         train accuracy = 3.5798 | logprob = -2.2707 | KL term = 0.29009146118164064\n",
      "Epoch 8060:         train accuracy = 3.5595 | logprob = -2.2599 | KL term = 0.2911339111328125\n",
      "Epoch 8080:         train accuracy = 3.5386 | logprob = -2.2474 | KL term = 0.29221923828125\n",
      "Epoch 8100:         train accuracy = 3.5187 | logprob = -2.2332 | KL term = 0.293344970703125\n",
      "Epoch 8120:         train accuracy = 3.5010 | logprob = -2.2176 | KL term = 0.29450079345703123\n",
      "Epoch 8140:         train accuracy = 3.4850 | logprob = -2.2014 | KL term = 0.2956644897460938\n",
      "Epoch 8160:         train accuracy = 3.4706 | logprob = -2.1853 | KL term = 0.2968095703125\n",
      "Epoch 8180:         train accuracy = 3.4582 | logprob = -2.1698 | KL term = 0.2979215087890625\n",
      "Epoch 8200:         train accuracy = 3.4459 | logprob = -2.1551 | KL term = 0.2989955444335938\n",
      "Epoch 8220:         train accuracy = 3.4338 | logprob = -2.1411 | KL term = 0.300031982421875\n",
      "Epoch 8240:         train accuracy = 3.4221 | logprob = -2.1281 | KL term = 0.3010347595214844\n",
      "Epoch 8260:         train accuracy = 3.4107 | logprob = -2.1158 | KL term = 0.3020097045898438\n",
      "Epoch 8280:         train accuracy = 3.3995 | logprob = -2.1042 | KL term = 0.3029635009765625\n",
      "Epoch 8300:         train accuracy = 3.3887 | logprob = -2.0934 | KL term = 0.3039028930664063\n",
      "Epoch 8320:         train accuracy = 3.3788 | logprob = -2.0832 | KL term = 0.3048345031738281\n",
      "Epoch 8340:         train accuracy = 3.3694 | logprob = -2.0736 | KL term = 0.3057642822265625\n",
      "Epoch 8360:         train accuracy = 3.3605 | logprob = -2.0646 | KL term = 0.306696044921875\n",
      "Epoch 8380:         train accuracy = 3.3520 | logprob = -2.0562 | KL term = 0.30763043212890623\n",
      "Epoch 8400:         train accuracy = 3.3438 | logprob = -2.0483 | KL term = 0.30856781005859374\n",
      "Epoch 8420:         train accuracy = 3.3360 | logprob = -2.0409 | KL term = 0.3095078430175781\n",
      "Epoch 8440:         train accuracy = 3.3285 | logprob = -2.0340 | KL term = 0.3104495849609375\n",
      "Epoch 8460:         train accuracy = 3.3215 | logprob = -2.0274 | KL term = 0.3113919982910156\n",
      "Epoch 8480:         train accuracy = 3.3148 | logprob = -2.0212 | KL term = 0.31233441162109377\n",
      "Epoch 8500:         train accuracy = 3.3083 | logprob = -2.0153 | KL term = 0.3132767333984375\n",
      "Epoch 8520:         train accuracy = 3.3020 | logprob = -2.0096 | KL term = 0.31421905517578125\n",
      "Epoch 8540:         train accuracy = 3.2959 | logprob = -2.0042 | KL term = 0.31516204833984374\n",
      "Epoch 8560:         train accuracy = 3.2901 | logprob = -1.9989 | KL term = 0.316106689453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8580:         train accuracy = 3.2843 | logprob = -1.9938 | KL term = 0.31705413818359374\n",
      "Epoch 8600:         train accuracy = 3.2788 | logprob = -1.9889 | KL term = 0.31800619506835937\n",
      "Epoch 8620:         train accuracy = 3.2735 | logprob = -1.9840 | KL term = 0.31896533203125\n",
      "Epoch 8640:         train accuracy = 3.2683 | logprob = -1.9793 | KL term = 0.319934814453125\n",
      "Epoch 8660:         train accuracy = 3.2634 | logprob = -1.9746 | KL term = 0.3209187927246094\n",
      "Epoch 8680:         train accuracy = 3.2584 | logprob = -1.9699 | KL term = 0.32192095947265625\n",
      "Epoch 8700:         train accuracy = 3.2529 | logprob = -1.9652 | KL term = 0.3229417419433594\n",
      "Epoch 8720:         train accuracy = 3.2470 | logprob = -1.9606 | KL term = 0.3239762878417969\n",
      "Epoch 8740:         train accuracy = 3.2406 | logprob = -1.9561 | KL term = 0.32501776123046877\n",
      "Epoch 8760:         train accuracy = 3.2338 | logprob = -1.9516 | KL term = 0.326061279296875\n",
      "Epoch 8780:         train accuracy = 3.2266 | logprob = -1.9473 | KL term = 0.3271048583984375\n",
      "Epoch 8800:         train accuracy = 3.2191 | logprob = -1.9432 | KL term = 0.32814825439453127\n",
      "Epoch 8820:         train accuracy = 3.2114 | logprob = -1.9391 | KL term = 0.32919189453125\n",
      "Epoch 8840:         train accuracy = 3.2035 | logprob = -1.9353 | KL term = 0.3302361145019531\n",
      "Epoch 8860:         train accuracy = 3.1955 | logprob = -1.9315 | KL term = 0.3312813720703125\n",
      "Epoch 8880:         train accuracy = 3.1875 | logprob = -1.9279 | KL term = 0.33232830810546876\n",
      "Epoch 8900:         train accuracy = 3.1794 | logprob = -1.9244 | KL term = 0.333378173828125\n",
      "Epoch 8920:         train accuracy = 3.1713 | logprob = -1.9211 | KL term = 0.33443289184570313\n",
      "Epoch 8940:         train accuracy = 3.1631 | logprob = -1.9178 | KL term = 0.3354952392578125\n",
      "Epoch 8960:         train accuracy = 3.1549 | logprob = -1.9146 | KL term = 0.33656863403320314\n",
      "Epoch 8980:         train accuracy = 3.1466 | logprob = -1.9114 | KL term = 0.3376571044921875\n",
      "Epoch 9000:         train accuracy = 3.1381 | logprob = -1.9083 | KL term = 0.33876416015625\n",
      "Epoch 9020:         train accuracy = 3.1296 | logprob = -1.9051 | KL term = 0.33989199829101563\n",
      "Epoch 9040:         train accuracy = 3.1210 | logprob = -1.9018 | KL term = 0.34104013061523436\n",
      "Epoch 9060:         train accuracy = 3.1125 | logprob = -1.8985 | KL term = 0.342205078125\n",
      "Epoch 9080:         train accuracy = 3.1040 | logprob = -1.8951 | KL term = 0.3433807373046875\n",
      "Epoch 9100:         train accuracy = 3.0957 | logprob = -1.8916 | KL term = 0.34455960083007814\n",
      "Epoch 9120:         train accuracy = 3.0877 | logprob = -1.8882 | KL term = 0.34573419189453125\n",
      "Epoch 9140:         train accuracy = 3.0800 | logprob = -1.8847 | KL term = 0.3468977966308594\n",
      "Epoch 9160:         train accuracy = 3.0728 | logprob = -1.8813 | KL term = 0.34804510498046876\n",
      "Epoch 9180:         train accuracy = 3.0660 | logprob = -1.8780 | KL term = 0.3491725158691406\n",
      "Epoch 9200:         train accuracy = 3.0597 | logprob = -1.8747 | KL term = 0.35027783203125\n",
      "Epoch 9220:         train accuracy = 3.0538 | logprob = -1.8714 | KL term = 0.3513603515625\n",
      "Epoch 9240:         train accuracy = 3.0482 | logprob = -1.8682 | KL term = 0.35242022705078124\n",
      "Epoch 9260:         train accuracy = 3.0430 | logprob = -1.8651 | KL term = 0.35345867919921875\n",
      "Epoch 9280:         train accuracy = 3.0381 | logprob = -1.8620 | KL term = 0.3544771728515625\n",
      "Epoch 9300:         train accuracy = 3.0335 | logprob = -1.8589 | KL term = 0.35547772216796875\n",
      "Epoch 9320:         train accuracy = 3.0290 | logprob = -1.8559 | KL term = 0.35646246337890625\n",
      "Epoch 9340:         train accuracy = 3.0247 | logprob = -1.8529 | KL term = 0.35743365478515626\n",
      "Epoch 9360:         train accuracy = 3.0204 | logprob = -1.8498 | KL term = 0.35839361572265627\n",
      "Epoch 9380:         train accuracy = 3.0163 | logprob = -1.8468 | KL term = 0.3593446044921875\n",
      "Epoch 9400:         train accuracy = 3.0122 | logprob = -1.8438 | KL term = 0.3602886962890625\n",
      "Epoch 9420:         train accuracy = 3.0082 | logprob = -1.8408 | KL term = 0.36122793579101564\n",
      "Epoch 9440:         train accuracy = 3.0042 | logprob = -1.8377 | KL term = 0.36216421508789065\n",
      "Epoch 9460:         train accuracy = 3.0002 | logprob = -1.8347 | KL term = 0.3630991516113281\n",
      "Epoch 9480:         train accuracy = 2.9963 | logprob = -1.8316 | KL term = 0.36403421020507815\n",
      "Epoch 9500:         train accuracy = 2.9923 | logprob = -1.8286 | KL term = 0.3649705810546875\n",
      "Epoch 9520:         train accuracy = 2.9884 | logprob = -1.8255 | KL term = 0.3659092102050781\n",
      "Epoch 9540:         train accuracy = 2.9846 | logprob = -1.8224 | KL term = 0.3668507080078125\n",
      "Epoch 9560:         train accuracy = 2.9808 | logprob = -1.8194 | KL term = 0.3677955017089844\n",
      "Epoch 9580:         train accuracy = 2.9772 | logprob = -1.8163 | KL term = 0.36874359130859374\n",
      "Epoch 9600:         train accuracy = 2.9736 | logprob = -1.8133 | KL term = 0.3696948547363281\n",
      "Epoch 9620:         train accuracy = 2.9702 | logprob = -1.8102 | KL term = 0.3706488952636719\n",
      "Epoch 9640:         train accuracy = 2.9669 | logprob = -1.8072 | KL term = 0.3716051025390625\n",
      "Epoch 9660:         train accuracy = 2.9639 | logprob = -1.8043 | KL term = 0.37256277465820314\n",
      "Epoch 9680:         train accuracy = 2.9609 | logprob = -1.8013 | KL term = 0.3735211181640625\n",
      "Epoch 9700:         train accuracy = 2.9582 | logprob = -1.7984 | KL term = 0.37447915649414065\n",
      "Epoch 9720:         train accuracy = 2.9555 | logprob = -1.7956 | KL term = 0.3754360961914063\n",
      "Epoch 9740:         train accuracy = 2.9531 | logprob = -1.7928 | KL term = 0.37639105224609376\n",
      "Epoch 9760:         train accuracy = 2.9508 | logprob = -1.7900 | KL term = 0.37734317016601565\n",
      "Epoch 9780:         train accuracy = 2.9486 | logprob = -1.7873 | KL term = 0.3782917785644531\n",
      "Epoch 9800:         train accuracy = 2.9466 | logprob = -1.7846 | KL term = 0.37923614501953123\n",
      "Epoch 9820:         train accuracy = 2.9447 | logprob = -1.7820 | KL term = 0.38017587280273435\n",
      "Epoch 9840:         train accuracy = 2.9429 | logprob = -1.7794 | KL term = 0.3811104431152344\n",
      "Epoch 9860:         train accuracy = 2.9412 | logprob = -1.7768 | KL term = 0.3820396118164063\n",
      "Epoch 9880:         train accuracy = 2.9396 | logprob = -1.7743 | KL term = 0.3829611206054688\n",
      "Epoch 9900:         train accuracy = 2.9380 | logprob = -1.7718 | KL term = 0.38387591552734374\n",
      "Epoch 9920:         train accuracy = 2.9366 | logprob = -1.7694 | KL term = 0.3847850952148438\n",
      "Epoch 9940:         train accuracy = 2.9351 | logprob = -1.7670 | KL term = 0.38568896484375\n",
      "Epoch 9960:         train accuracy = 2.9337 | logprob = -1.7646 | KL term = 0.38658758544921873\n",
      "Epoch 9980:         train accuracy = 2.9324 | logprob = -1.7623 | KL term = 0.38748129272460935\n",
      "Epoch 10000:         train accuracy = 2.9310 | logprob = -1.7600 | KL term = 0.3883642578125\n",
      "Epoch 10020:         train accuracy = 2.9298 | logprob = -1.7577 | KL term = 0.389242919921875\n",
      "Epoch 10040:         train accuracy = 2.9285 | logprob = -1.7554 | KL term = 0.39011810302734373\n",
      "Epoch 10060:         train accuracy = 2.9272 | logprob = -1.7532 | KL term = 0.3909903564453125\n",
      "Epoch 10080:         train accuracy = 2.9260 | logprob = -1.7510 | KL term = 0.391857666015625\n",
      "Epoch 10100:         train accuracy = 2.9249 | logprob = -1.7489 | KL term = 0.392716796875\n",
      "Epoch 10120:         train accuracy = 2.9238 | logprob = -1.7467 | KL term = 0.39357437133789064\n",
      "Epoch 10140:         train accuracy = 2.9227 | logprob = -1.7446 | KL term = 0.3944316711425781\n",
      "Epoch 10160:         train accuracy = 2.9215 | logprob = -1.7425 | KL term = 0.39528890991210935\n",
      "Epoch 10180:         train accuracy = 2.9206 | logprob = -1.7404 | KL term = 0.39613735961914065\n",
      "Epoch 10200:         train accuracy = 2.9197 | logprob = -1.7383 | KL term = 0.39698468017578126\n",
      "Epoch 10220:         train accuracy = 2.9186 | logprob = -1.7362 | KL term = 0.3978340759277344\n",
      "Epoch 10240:         train accuracy = 2.9174 | logprob = -1.7341 | KL term = 0.398686767578125\n",
      "Epoch 10260:         train accuracy = 2.9161 | logprob = -1.7321 | KL term = 0.39954296875\n",
      "Epoch 10280:         train accuracy = 2.9151 | logprob = -1.7300 | KL term = 0.40039178466796876\n",
      "Epoch 10300:         train accuracy = 2.9140 | logprob = -1.7280 | KL term = 0.40124221801757814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10320:         train accuracy = 2.9126 | logprob = -1.7259 | KL term = 0.40209735107421873\n",
      "Epoch 10340:         train accuracy = 2.9111 | logprob = -1.7239 | KL term = 0.40295849609375\n",
      "Epoch 10360:         train accuracy = 2.9093 | logprob = -1.7218 | KL term = 0.4038265686035156\n",
      "Epoch 10380:         train accuracy = 2.9076 | logprob = -1.7197 | KL term = 0.40469091796875\n",
      "Epoch 10400:         train accuracy = 2.9060 | logprob = -1.7176 | KL term = 0.4055584411621094\n",
      "Epoch 10420:         train accuracy = 2.9039 | logprob = -1.7155 | KL term = 0.40643182373046877\n",
      "Epoch 10440:         train accuracy = 2.9015 | logprob = -1.7134 | KL term = 0.4073118591308594\n",
      "Epoch 10460:         train accuracy = 2.8988 | logprob = -1.7113 | KL term = 0.40819720458984377\n",
      "Epoch 10480:         train accuracy = 2.8958 | logprob = -1.7092 | KL term = 0.409074951171875\n",
      "Epoch 10500:         train accuracy = 2.8927 | logprob = -1.7071 | KL term = 0.4099520263671875\n",
      "Epoch 10520:         train accuracy = 2.8889 | logprob = -1.7050 | KL term = 0.410830810546875\n",
      "Epoch 10540:         train accuracy = 2.8845 | logprob = -1.7028 | KL term = 0.41171295166015626\n",
      "Epoch 10560:         train accuracy = 2.8798 | logprob = -1.7007 | KL term = 0.4125957336425781\n",
      "Epoch 10580:         train accuracy = 2.8751 | logprob = -1.6986 | KL term = 0.4134720458984375\n",
      "Epoch 10600:         train accuracy = 2.8698 | logprob = -1.6964 | KL term = 0.4143526611328125\n",
      "Epoch 10620:         train accuracy = 2.8639 | logprob = -1.6942 | KL term = 0.41524270629882815\n",
      "Epoch 10640:         train accuracy = 2.8570 | logprob = -1.6919 | KL term = 0.4161470642089844\n",
      "Epoch 10660:         train accuracy = 2.8497 | logprob = -1.6894 | KL term = 0.417054931640625\n",
      "Epoch 10680:         train accuracy = 2.8414 | logprob = -1.6868 | KL term = 0.41798284912109374\n",
      "Epoch 10700:         train accuracy = 2.8310 | logprob = -1.6837 | KL term = 0.418943359375\n",
      "Epoch 10720:         train accuracy = 2.8175 | logprob = -1.6801 | KL term = 0.41995059204101565\n",
      "Epoch 10740:         train accuracy = 2.7993 | logprob = -1.6753 | KL term = 0.42101019287109376\n",
      "Epoch 10760:         train accuracy = 2.7753 | logprob = -1.6680 | KL term = 0.42215719604492186\n",
      "Epoch 10780:         train accuracy = 2.7460 | logprob = -1.6574 | KL term = 0.42342041015625\n",
      "Epoch 10800:         train accuracy = 2.7222 | logprob = -1.6472 | KL term = 0.42470291137695315\n",
      "Epoch 10820:         train accuracy = 2.7055 | logprob = -1.6385 | KL term = 0.42592147827148436\n",
      "Epoch 10840:         train accuracy = 2.6931 | logprob = -1.6314 | KL term = 0.4270673828125\n",
      "Epoch 10860:         train accuracy = 2.6861 | logprob = -1.6260 | KL term = 0.42814385986328124\n",
      "Epoch 10880:         train accuracy = 2.6831 | logprob = -1.6215 | KL term = 0.4291573181152344\n",
      "Epoch 10900:         train accuracy = 2.6820 | logprob = -1.6175 | KL term = 0.4301181640625\n",
      "Epoch 10920:         train accuracy = 2.6814 | logprob = -1.6139 | KL term = 0.4310392150878906\n",
      "Epoch 10940:         train accuracy = 2.6812 | logprob = -1.6106 | KL term = 0.4319249267578125\n",
      "Epoch 10960:         train accuracy = 2.6810 | logprob = -1.6075 | KL term = 0.432781005859375\n",
      "Epoch 10980:         train accuracy = 2.6804 | logprob = -1.6046 | KL term = 0.4336099853515625\n",
      "Epoch 11000:         train accuracy = 2.6798 | logprob = -1.6019 | KL term = 0.43441546630859373\n",
      "Epoch 11020:         train accuracy = 2.6797 | logprob = -1.5993 | KL term = 0.43519772338867185\n",
      "Epoch 11040:         train accuracy = 2.6798 | logprob = -1.5968 | KL term = 0.435960205078125\n",
      "Epoch 11060:         train accuracy = 2.6800 | logprob = -1.5945 | KL term = 0.436704833984375\n",
      "Epoch 11080:         train accuracy = 2.6803 | logprob = -1.5921 | KL term = 0.43743316650390623\n",
      "Epoch 11100:         train accuracy = 2.6807 | logprob = -1.5899 | KL term = 0.4381463317871094\n",
      "Epoch 11120:         train accuracy = 2.6811 | logprob = -1.5877 | KL term = 0.4388477783203125\n",
      "Epoch 11140:         train accuracy = 2.6816 | logprob = -1.5855 | KL term = 0.439541748046875\n",
      "Epoch 11160:         train accuracy = 2.6819 | logprob = -1.5833 | KL term = 0.44022933959960936\n",
      "Epoch 11180:         train accuracy = 2.6821 | logprob = -1.5812 | KL term = 0.44091424560546877\n",
      "Epoch 11200:         train accuracy = 2.6823 | logprob = -1.5791 | KL term = 0.4415977783203125\n",
      "Epoch 11220:         train accuracy = 2.6823 | logprob = -1.5770 | KL term = 0.44228082275390623\n",
      "Epoch 11240:         train accuracy = 2.6823 | logprob = -1.5750 | KL term = 0.44296337890625\n",
      "Epoch 11260:         train accuracy = 2.6822 | logprob = -1.5730 | KL term = 0.44364471435546876\n",
      "Epoch 11280:         train accuracy = 2.6821 | logprob = -1.5710 | KL term = 0.44432550048828123\n",
      "Epoch 11300:         train accuracy = 2.6820 | logprob = -1.5690 | KL term = 0.445005859375\n",
      "Epoch 11320:         train accuracy = 2.6819 | logprob = -1.5670 | KL term = 0.44568585205078126\n",
      "Epoch 11340:         train accuracy = 2.6817 | logprob = -1.5651 | KL term = 0.44636581420898436\n",
      "Epoch 11360:         train accuracy = 2.6815 | logprob = -1.5631 | KL term = 0.4470462646484375\n",
      "Epoch 11380:         train accuracy = 2.6814 | logprob = -1.5612 | KL term = 0.44772833251953126\n",
      "Epoch 11400:         train accuracy = 2.6812 | logprob = -1.5593 | KL term = 0.44841250610351563\n",
      "Epoch 11420:         train accuracy = 2.6811 | logprob = -1.5575 | KL term = 0.449098876953125\n",
      "Epoch 11440:         train accuracy = 2.6809 | logprob = -1.5556 | KL term = 0.44978750610351564\n",
      "Epoch 11460:         train accuracy = 2.6808 | logprob = -1.5538 | KL term = 0.4504788818359375\n",
      "Epoch 11480:         train accuracy = 2.6807 | logprob = -1.5520 | KL term = 0.4511734924316406\n",
      "Epoch 11500:         train accuracy = 2.6806 | logprob = -1.5502 | KL term = 0.45187197875976565\n",
      "Epoch 11520:         train accuracy = 2.6805 | logprob = -1.5484 | KL term = 0.4525750122070312\n",
      "Epoch 11540:         train accuracy = 2.6804 | logprob = -1.5466 | KL term = 0.45328311157226564\n",
      "Epoch 11560:         train accuracy = 2.6804 | logprob = -1.5449 | KL term = 0.4539969177246094\n",
      "Epoch 11580:         train accuracy = 2.6803 | logprob = -1.5431 | KL term = 0.45471701049804686\n",
      "Epoch 11600:         train accuracy = 2.6803 | logprob = -1.5414 | KL term = 0.45544387817382814\n",
      "Epoch 11620:         train accuracy = 2.6803 | logprob = -1.5397 | KL term = 0.4561778564453125\n",
      "Epoch 11640:         train accuracy = 2.6804 | logprob = -1.5381 | KL term = 0.4569187927246094\n",
      "Epoch 11660:         train accuracy = 2.6805 | logprob = -1.5364 | KL term = 0.4576662292480469\n",
      "Epoch 11680:         train accuracy = 2.6807 | logprob = -1.5348 | KL term = 0.4584188537597656\n",
      "Epoch 11700:         train accuracy = 2.6809 | logprob = -1.5332 | KL term = 0.4591753845214844\n",
      "Epoch 11720:         train accuracy = 2.6813 | logprob = -1.5316 | KL term = 0.4599343872070312\n",
      "Epoch 11740:         train accuracy = 2.6817 | logprob = -1.5300 | KL term = 0.46069467163085936\n",
      "Epoch 11760:         train accuracy = 2.6821 | logprob = -1.5285 | KL term = 0.4614549560546875\n",
      "Epoch 11780:         train accuracy = 2.6827 | logprob = -1.5270 | KL term = 0.46221414184570314\n",
      "Epoch 11800:         train accuracy = 2.6832 | logprob = -1.5255 | KL term = 0.4629716491699219\n",
      "Epoch 11820:         train accuracy = 2.6838 | logprob = -1.5240 | KL term = 0.4637269287109375\n",
      "Epoch 11840:         train accuracy = 2.6845 | logprob = -1.5226 | KL term = 0.464479248046875\n",
      "Epoch 11860:         train accuracy = 2.6851 | logprob = -1.5212 | KL term = 0.46522821044921875\n",
      "Epoch 11880:         train accuracy = 2.6858 | logprob = -1.5198 | KL term = 0.4659732666015625\n",
      "Epoch 11900:         train accuracy = 2.6865 | logprob = -1.5185 | KL term = 0.46671380615234376\n",
      "Epoch 11920:         train accuracy = 2.6872 | logprob = -1.5172 | KL term = 0.4674496154785156\n",
      "Epoch 11940:         train accuracy = 2.6880 | logprob = -1.5159 | KL term = 0.46818048095703124\n",
      "Epoch 11960:         train accuracy = 2.6887 | logprob = -1.5146 | KL term = 0.468906005859375\n",
      "Epoch 11980:         train accuracy = 2.6894 | logprob = -1.5134 | KL term = 0.4696260986328125\n",
      "Epoch 12000:         train accuracy = 2.6901 | logprob = -1.5122 | KL term = 0.4703408813476562\n",
      "Epoch 12020:         train accuracy = 2.6908 | logprob = -1.5110 | KL term = 0.4710504455566406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12040:         train accuracy = 2.6915 | logprob = -1.5098 | KL term = 0.4717548828125\n",
      "Epoch 12060:         train accuracy = 2.6922 | logprob = -1.5087 | KL term = 0.47245431518554687\n",
      "Epoch 12080:         train accuracy = 2.6929 | logprob = -1.5075 | KL term = 0.47314886474609374\n",
      "Epoch 12100:         train accuracy = 2.6936 | logprob = -1.5064 | KL term = 0.4738386840820312\n",
      "Epoch 12120:         train accuracy = 2.6943 | logprob = -1.5053 | KL term = 0.47452392578125\n",
      "Epoch 12140:         train accuracy = 2.6950 | logprob = -1.5043 | KL term = 0.47520468139648436\n",
      "Epoch 12160:         train accuracy = 2.6957 | logprob = -1.5032 | KL term = 0.4758811645507813\n",
      "Epoch 12180:         train accuracy = 2.6965 | logprob = -1.5022 | KL term = 0.4765535583496094\n",
      "Epoch 12200:         train accuracy = 2.6972 | logprob = -1.5012 | KL term = 0.4772218933105469\n",
      "Epoch 12220:         train accuracy = 2.6979 | logprob = -1.5002 | KL term = 0.47788592529296875\n",
      "Epoch 12240:         train accuracy = 2.6985 | logprob = -1.4993 | KL term = 0.47854568481445314\n",
      "Epoch 12260:         train accuracy = 2.6992 | logprob = -1.4983 | KL term = 0.47920135498046873\n",
      "Epoch 12280:         train accuracy = 2.6999 | logprob = -1.4974 | KL term = 0.4798530883789062\n",
      "Epoch 12300:         train accuracy = 2.7006 | logprob = -1.4965 | KL term = 0.4805011901855469\n",
      "Epoch 12320:         train accuracy = 2.7013 | logprob = -1.4956 | KL term = 0.48114584350585937\n",
      "Epoch 12340:         train accuracy = 2.7020 | logprob = -1.4947 | KL term = 0.4817873229980469\n",
      "Epoch 12360:         train accuracy = 2.7027 | logprob = -1.4939 | KL term = 0.48242581176757815\n",
      "Epoch 12380:         train accuracy = 2.7034 | logprob = -1.4930 | KL term = 0.48306158447265624\n",
      "Epoch 12400:         train accuracy = 2.7041 | logprob = -1.4922 | KL term = 0.4836949462890625\n",
      "Epoch 12420:         train accuracy = 2.7049 | logprob = -1.4914 | KL term = 0.4843260498046875\n",
      "Epoch 12440:         train accuracy = 2.7056 | logprob = -1.4906 | KL term = 0.48495523071289065\n",
      "Epoch 12460:         train accuracy = 2.7064 | logprob = -1.4898 | KL term = 0.48558270263671877\n",
      "Epoch 12480:         train accuracy = 2.7072 | logprob = -1.4890 | KL term = 0.4862087707519531\n",
      "Epoch 12500:         train accuracy = 2.7081 | logprob = -1.4882 | KL term = 0.4868336181640625\n",
      "Epoch 12520:         train accuracy = 2.7090 | logprob = -1.4875 | KL term = 0.4874577026367187\n",
      "Epoch 12540:         train accuracy = 2.7099 | logprob = -1.4867 | KL term = 0.48808099365234375\n",
      "Epoch 12560:         train accuracy = 2.7108 | logprob = -1.4860 | KL term = 0.4887032470703125\n",
      "Epoch 12580:         train accuracy = 2.7117 | logprob = -1.4853 | KL term = 0.4893244323730469\n",
      "Epoch 12600:         train accuracy = 2.7126 | logprob = -1.4845 | KL term = 0.489944580078125\n",
      "Epoch 12620:         train accuracy = 2.7135 | logprob = -1.4838 | KL term = 0.4905638427734375\n",
      "Epoch 12640:         train accuracy = 2.7145 | logprob = -1.4831 | KL term = 0.49118246459960935\n",
      "Epoch 12660:         train accuracy = 2.7156 | logprob = -1.4824 | KL term = 0.4918017272949219\n",
      "Epoch 12680:         train accuracy = 2.7170 | logprob = -1.4816 | KL term = 0.4924244079589844\n",
      "Epoch 12700:         train accuracy = 2.7184 | logprob = -1.4808 | KL term = 0.49305389404296873\n",
      "Epoch 12720:         train accuracy = 2.7197 | logprob = -1.4800 | KL term = 0.49369189453125\n",
      "Epoch 12740:         train accuracy = 2.7209 | logprob = -1.4792 | KL term = 0.49433758544921874\n",
      "Epoch 12760:         train accuracy = 2.7219 | logprob = -1.4784 | KL term = 0.494988525390625\n",
      "Epoch 12780:         train accuracy = 2.7228 | logprob = -1.4777 | KL term = 0.49564178466796877\n",
      "Epoch 12800:         train accuracy = 2.7236 | logprob = -1.4769 | KL term = 0.4962947998046875\n",
      "Epoch 12820:         train accuracy = 2.7243 | logprob = -1.4762 | KL term = 0.49694601440429687\n",
      "Epoch 12840:         train accuracy = 2.7250 | logprob = -1.4754 | KL term = 0.49759439086914065\n",
      "Epoch 12860:         train accuracy = 2.7257 | logprob = -1.4747 | KL term = 0.49823944091796873\n",
      "Epoch 12880:         train accuracy = 2.7263 | logprob = -1.4741 | KL term = 0.4988810424804688\n",
      "Epoch 12900:         train accuracy = 2.7270 | logprob = -1.4734 | KL term = 0.4995192260742187\n",
      "Epoch 12920:         train accuracy = 2.7276 | logprob = -1.4727 | KL term = 0.5001538391113282\n",
      "Epoch 12940:         train accuracy = 2.7282 | logprob = -1.4721 | KL term = 0.5007850952148437\n",
      "Epoch 12960:         train accuracy = 2.7288 | logprob = -1.4714 | KL term = 0.5014130554199219\n",
      "Epoch 12980:         train accuracy = 2.7294 | logprob = -1.4708 | KL term = 0.502037841796875\n",
      "Epoch 13000:         train accuracy = 2.7300 | logprob = -1.4702 | KL term = 0.502659423828125\n",
      "Epoch 13020:         train accuracy = 2.7306 | logprob = -1.4696 | KL term = 0.5032779541015625\n",
      "Epoch 13040:         train accuracy = 2.7311 | logprob = -1.4690 | KL term = 0.5038935241699218\n",
      "Epoch 13060:         train accuracy = 2.7317 | logprob = -1.4684 | KL term = 0.5045062255859375\n",
      "Epoch 13080:         train accuracy = 2.7322 | logprob = -1.4678 | KL term = 0.5051159973144531\n",
      "Epoch 13100:         train accuracy = 2.7327 | logprob = -1.4673 | KL term = 0.5057229309082031\n",
      "Epoch 13120:         train accuracy = 2.7332 | logprob = -1.4667 | KL term = 0.5063270263671875\n",
      "Epoch 13140:         train accuracy = 2.7337 | logprob = -1.4662 | KL term = 0.50692822265625\n",
      "Epoch 13160:         train accuracy = 2.7342 | logprob = -1.4656 | KL term = 0.5075264282226563\n",
      "Epoch 13180:         train accuracy = 2.7347 | logprob = -1.4651 | KL term = 0.5081217041015625\n",
      "Epoch 13200:         train accuracy = 2.7352 | logprob = -1.4646 | KL term = 0.5087139282226563\n",
      "Epoch 13220:         train accuracy = 2.7356 | logprob = -1.4641 | KL term = 0.5093030395507813\n",
      "Epoch 13240:         train accuracy = 2.7361 | logprob = -1.4636 | KL term = 0.5098889770507813\n",
      "Epoch 13260:         train accuracy = 2.7365 | logprob = -1.4632 | KL term = 0.5104715576171875\n",
      "Epoch 13280:         train accuracy = 2.7369 | logprob = -1.4627 | KL term = 0.5110509033203126\n",
      "Epoch 13300:         train accuracy = 2.7373 | logprob = -1.4622 | KL term = 0.5116268615722657\n",
      "Epoch 13320:         train accuracy = 2.7377 | logprob = -1.4618 | KL term = 0.512199462890625\n",
      "Epoch 13340:         train accuracy = 2.7380 | logprob = -1.4614 | KL term = 0.5127686767578125\n",
      "Epoch 13360:         train accuracy = 2.7384 | logprob = -1.4610 | KL term = 0.51333447265625\n",
      "Epoch 13380:         train accuracy = 2.7387 | logprob = -1.4605 | KL term = 0.513897216796875\n",
      "Epoch 13400:         train accuracy = 2.7391 | logprob = -1.4601 | KL term = 0.5144569091796874\n",
      "Epoch 13420:         train accuracy = 2.7394 | logprob = -1.4597 | KL term = 0.5150136108398438\n",
      "Epoch 13440:         train accuracy = 2.7398 | logprob = -1.4594 | KL term = 0.5155670776367187\n",
      "Epoch 13460:         train accuracy = 2.7401 | logprob = -1.4590 | KL term = 0.5161173706054687\n",
      "Epoch 13480:         train accuracy = 2.7404 | logprob = -1.4586 | KL term = 0.516664306640625\n",
      "Epoch 13500:         train accuracy = 2.7407 | logprob = -1.4583 | KL term = 0.5172080078125\n",
      "Epoch 13520:         train accuracy = 2.7410 | logprob = -1.4579 | KL term = 0.517748291015625\n",
      "Epoch 13540:         train accuracy = 2.7413 | logprob = -1.4576 | KL term = 0.518285400390625\n",
      "Epoch 13560:         train accuracy = 2.7416 | logprob = -1.4572 | KL term = 0.5188192138671875\n",
      "Epoch 13580:         train accuracy = 2.7418 | logprob = -1.4569 | KL term = 0.519349853515625\n",
      "Epoch 13600:         train accuracy = 2.7421 | logprob = -1.4566 | KL term = 0.5198773193359375\n",
      "Epoch 13620:         train accuracy = 2.7424 | logprob = -1.4563 | KL term = 0.5204017944335938\n",
      "Epoch 13640:         train accuracy = 2.7426 | logprob = -1.4560 | KL term = 0.5209237060546875\n",
      "Epoch 13660:         train accuracy = 2.7429 | logprob = -1.4557 | KL term = 0.521443115234375\n",
      "Epoch 13680:         train accuracy = 2.7431 | logprob = -1.4554 | KL term = 0.5219600830078125\n",
      "Epoch 13700:         train accuracy = 2.7433 | logprob = -1.4551 | KL term = 0.5224747314453125\n",
      "Epoch 13720:         train accuracy = 2.7436 | logprob = -1.4548 | KL term = 0.522987060546875\n",
      "Epoch 13740:         train accuracy = 2.7438 | logprob = -1.4546 | KL term = 0.5234969482421875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13760:         train accuracy = 2.7440 | logprob = -1.4543 | KL term = 0.5240044555664063\n",
      "Epoch 13780:         train accuracy = 2.7443 | logprob = -1.4540 | KL term = 0.524509521484375\n",
      "Epoch 13800:         train accuracy = 2.7445 | logprob = -1.4538 | KL term = 0.5250120849609375\n",
      "Epoch 13820:         train accuracy = 2.7447 | logprob = -1.4535 | KL term = 0.5255123291015625\n",
      "Epoch 13840:         train accuracy = 2.7449 | logprob = -1.4533 | KL term = 0.52601025390625\n",
      "Epoch 13860:         train accuracy = 2.7451 | logprob = -1.4530 | KL term = 0.526505859375\n",
      "Epoch 13880:         train accuracy = 2.7453 | logprob = -1.4528 | KL term = 0.5269989013671875\n",
      "Epoch 13900:         train accuracy = 2.7455 | logprob = -1.4526 | KL term = 0.5274896240234375\n",
      "Epoch 13920:         train accuracy = 2.7457 | logprob = -1.4523 | KL term = 0.52797802734375\n",
      "Epoch 13940:         train accuracy = 2.7458 | logprob = -1.4521 | KL term = 0.528464111328125\n",
      "Epoch 13960:         train accuracy = 2.7460 | logprob = -1.4519 | KL term = 0.5289481201171875\n",
      "Epoch 13980:         train accuracy = 2.7462 | logprob = -1.4517 | KL term = 0.529429931640625\n",
      "Epoch 14000:         train accuracy = 2.7464 | logprob = -1.4515 | KL term = 0.529909423828125\n",
      "Epoch 14020:         train accuracy = 2.7465 | logprob = -1.4513 | KL term = 0.53020166015625\n",
      "Epoch 14040:         train accuracy = 2.7467 | logprob = -1.4511 | KL term = 0.5298052978515625\n",
      "Epoch 14060:         train accuracy = 2.7468 | logprob = -1.4509 | KL term = 0.52859619140625\n",
      "Epoch 14080:         train accuracy = 2.7470 | logprob = -1.4508 | KL term = 0.5265784912109375\n",
      "Epoch 14100:         train accuracy = 2.7471 | logprob = -1.4506 | KL term = 0.52380224609375\n",
      "Epoch 14120:         train accuracy = 2.7472 | logprob = -1.4505 | KL term = 0.5203712768554688\n",
      "Epoch 14140:         train accuracy = 2.7473 | logprob = -1.4504 | KL term = 0.5164502563476563\n",
      "Epoch 14160:         train accuracy = 2.7474 | logprob = -1.4503 | KL term = 0.51219775390625\n",
      "Epoch 14180:         train accuracy = 2.7475 | logprob = -1.4503 | KL term = 0.5077187805175781\n",
      "Epoch 14200:         train accuracy = 2.7476 | logprob = -1.4502 | KL term = 0.5030868225097657\n",
      "Epoch 14220:         train accuracy = 2.7477 | logprob = -1.4502 | KL term = 0.4983392333984375\n",
      "Epoch 14240:         train accuracy = 2.7477 | logprob = -1.4502 | KL term = 0.4935020751953125\n",
      "Epoch 14260:         train accuracy = 2.7478 | logprob = -1.4502 | KL term = 0.48862066650390623\n",
      "Epoch 14280:         train accuracy = 2.7479 | logprob = -1.4502 | KL term = 0.48375274658203127\n",
      "Epoch 14300:         train accuracy = 2.7479 | logprob = -1.4503 | KL term = 0.4789491271972656\n",
      "Epoch 14320:         train accuracy = 2.7479 | logprob = -1.4503 | KL term = 0.47424609375\n",
      "Epoch 14340:         train accuracy = 2.7480 | logprob = -1.4504 | KL term = 0.46966665649414063\n",
      "Epoch 14360:         train accuracy = 2.7480 | logprob = -1.4505 | KL term = 0.4652178649902344\n",
      "Epoch 14380:         train accuracy = 2.7480 | logprob = -1.4506 | KL term = 0.4608951416015625\n",
      "Epoch 14400:         train accuracy = 2.7481 | logprob = -1.4507 | KL term = 0.4566959838867187\n",
      "Epoch 14420:         train accuracy = 2.7481 | logprob = -1.4508 | KL term = 0.452625244140625\n",
      "Epoch 14440:         train accuracy = 2.7481 | logprob = -1.4510 | KL term = 0.4486982421875\n",
      "Epoch 14460:         train accuracy = 2.7481 | logprob = -1.4512 | KL term = 0.44493939208984373\n",
      "Epoch 14480:         train accuracy = 2.7481 | logprob = -1.4514 | KL term = 0.4413455810546875\n",
      "Epoch 14500:         train accuracy = 2.7481 | logprob = -1.4516 | KL term = 0.43787789916992187\n",
      "Epoch 14520:         train accuracy = 2.7480 | logprob = -1.4518 | KL term = 0.4345177917480469\n",
      "Epoch 14540:         train accuracy = 2.7480 | logprob = -1.4521 | KL term = 0.4312664794921875\n",
      "Epoch 14560:         train accuracy = 2.7480 | logprob = -1.4523 | KL term = 0.4281226806640625\n",
      "Epoch 14580:         train accuracy = 2.7480 | logprob = -1.4526 | KL term = 0.4250810546875\n",
      "Epoch 14600:         train accuracy = 2.7479 | logprob = -1.4529 | KL term = 0.4221358642578125\n",
      "Epoch 14620:         train accuracy = 2.7479 | logprob = -1.4533 | KL term = 0.41928173828125\n",
      "Epoch 14640:         train accuracy = 2.7478 | logprob = -1.4536 | KL term = 0.4165137939453125\n",
      "Epoch 14660:         train accuracy = 2.7477 | logprob = -1.4540 | KL term = 0.41382781982421873\n",
      "Epoch 14680:         train accuracy = 2.7477 | logprob = -1.4545 | KL term = 0.4112200927734375\n",
      "Epoch 14700:         train accuracy = 2.7476 | logprob = -1.4549 | KL term = 0.408687255859375\n",
      "Epoch 14720:         train accuracy = 2.7475 | logprob = -1.4554 | KL term = 0.40622625732421874\n",
      "Epoch 14740:         train accuracy = 2.7474 | logprob = -1.4559 | KL term = 0.4038340454101563\n",
      "Epoch 14760:         train accuracy = 2.7473 | logprob = -1.4564 | KL term = 0.4015078125\n",
      "Epoch 14780:         train accuracy = 2.7472 | logprob = -1.4569 | KL term = 0.3992451171875\n",
      "Epoch 14800:         train accuracy = 2.7471 | logprob = -1.4575 | KL term = 0.39704367065429685\n",
      "Epoch 14820:         train accuracy = 2.7469 | logprob = -1.4581 | KL term = 0.3949015197753906\n",
      "Epoch 14840:         train accuracy = 2.7467 | logprob = -1.4587 | KL term = 0.39281689453125\n",
      "Epoch 14860:         train accuracy = 2.7466 | logprob = -1.4594 | KL term = 0.39078823852539063\n",
      "Epoch 14880:         train accuracy = 2.7464 | logprob = -1.4600 | KL term = 0.38881396484375\n",
      "Epoch 14900:         train accuracy = 2.7461 | logprob = -1.4607 | KL term = 0.3868927001953125\n",
      "Epoch 14920:         train accuracy = 2.7459 | logprob = -1.4615 | KL term = 0.3850230712890625\n",
      "Epoch 14940:         train accuracy = 2.7457 | logprob = -1.4622 | KL term = 0.38320379638671875\n",
      "Epoch 14960:         train accuracy = 2.7454 | logprob = -1.4630 | KL term = 0.38143359375\n",
      "Epoch 14980:         train accuracy = 2.7451 | logprob = -1.4638 | KL term = 0.37971124267578127\n",
      "Epoch 15000:         train accuracy = 2.7448 | logprob = -1.4646 | KL term = 0.37803546142578126\n",
      "Epoch 15020:         train accuracy = 2.7446 | logprob = -1.4653 | KL term = 0.37645645141601564\n",
      "Epoch 15040:         train accuracy = 2.7443 | logprob = -1.4661 | KL term = 0.3749941711425781\n",
      "Epoch 15060:         train accuracy = 2.7439 | logprob = -1.4668 | KL term = 0.3736390075683594\n",
      "Epoch 15080:         train accuracy = 2.7436 | logprob = -1.4675 | KL term = 0.3723843994140625\n",
      "Epoch 15100:         train accuracy = 2.7433 | logprob = -1.4681 | KL term = 0.3712227478027344\n",
      "Epoch 15120:         train accuracy = 2.7430 | logprob = -1.4687 | KL term = 0.37014691162109375\n",
      "Epoch 15140:         train accuracy = 2.7426 | logprob = -1.4693 | KL term = 0.36915032958984373\n",
      "Epoch 15160:         train accuracy = 2.7423 | logprob = -1.4698 | KL term = 0.368227294921875\n",
      "Epoch 15180:         train accuracy = 2.7419 | logprob = -1.4703 | KL term = 0.36737213134765623\n",
      "Epoch 15200:         train accuracy = 2.7416 | logprob = -1.4708 | KL term = 0.3665797119140625\n",
      "Epoch 15220:         train accuracy = 2.7412 | logprob = -1.4712 | KL term = 0.3658448486328125\n",
      "Epoch 15240:         train accuracy = 2.7409 | logprob = -1.4716 | KL term = 0.3651627197265625\n",
      "Epoch 15260:         train accuracy = 2.7405 | logprob = -1.4720 | KL term = 0.36452838134765625\n",
      "Epoch 15280:         train accuracy = 2.7402 | logprob = -1.4723 | KL term = 0.36393707275390624\n",
      "Epoch 15300:         train accuracy = 2.7399 | logprob = -1.4727 | KL term = 0.3633841552734375\n",
      "Epoch 15320:         train accuracy = 2.7396 | logprob = -1.4730 | KL term = 0.3628653564453125\n",
      "Epoch 15340:         train accuracy = 2.7392 | logprob = -1.4733 | KL term = 0.36237652587890623\n",
      "Epoch 15360:         train accuracy = 2.7389 | logprob = -1.4735 | KL term = 0.3619140625\n",
      "Epoch 15380:         train accuracy = 2.7386 | logprob = -1.4738 | KL term = 0.36147476196289063\n",
      "Epoch 15400:         train accuracy = 2.7383 | logprob = -1.4741 | KL term = 0.36105569458007813\n",
      "Epoch 15420:         train accuracy = 2.7381 | logprob = -1.4743 | KL term = 0.360654296875\n",
      "Epoch 15440:         train accuracy = 2.7378 | logprob = -1.4745 | KL term = 0.36026837158203123\n",
      "Epoch 15460:         train accuracy = 2.7375 | logprob = -1.4748 | KL term = 0.359895751953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15480:         train accuracy = 2.7373 | logprob = -1.4750 | KL term = 0.35953436279296874\n",
      "Epoch 15500:         train accuracy = 2.7370 | logprob = -1.4752 | KL term = 0.35918218994140627\n",
      "Epoch 15520:         train accuracy = 2.7367 | logprob = -1.4754 | KL term = 0.3588370361328125\n",
      "Epoch 15540:         train accuracy = 2.7365 | logprob = -1.4755 | KL term = 0.35849847412109376\n",
      "Epoch 15560:         train accuracy = 2.7367 | logprob = -1.4755 | KL term = 0.3581895446777344\n",
      "Epoch 15580:         train accuracy = 2.7360 | logprob = -1.4757 | KL term = 0.35780441284179687\n",
      "Epoch 15600:         train accuracy = 2.7358 | logprob = -1.4758 | KL term = 0.35748245239257814\n",
      "Epoch 15620:         train accuracy = 2.7355 | logprob = -1.4760 | KL term = 0.35715594482421875\n",
      "Epoch 15640:         train accuracy = 2.7352 | logprob = -1.4762 | KL term = 0.35684707641601565\n",
      "Epoch 15660:         train accuracy = 2.7349 | logprob = -1.4764 | KL term = 0.3565502624511719\n",
      "Epoch 15680:         train accuracy = 2.7346 | logprob = -1.4765 | KL term = 0.3562631530761719\n",
      "Epoch 15700:         train accuracy = 2.7343 | logprob = -1.4767 | KL term = 0.35598480224609375\n",
      "Epoch 15720:         train accuracy = 2.7340 | logprob = -1.4768 | KL term = 0.3557144775390625\n",
      "Epoch 15740:         train accuracy = 2.7338 | logprob = -1.4770 | KL term = 0.3554512939453125\n",
      "Epoch 15760:         train accuracy = 2.7335 | logprob = -1.4771 | KL term = 0.35519454956054686\n",
      "Epoch 15780:         train accuracy = 2.7333 | logprob = -1.4773 | KL term = 0.354943603515625\n",
      "Epoch 15800:         train accuracy = 2.7330 | logprob = -1.4774 | KL term = 0.3546978759765625\n",
      "Epoch 15820:         train accuracy = 2.7328 | logprob = -1.4776 | KL term = 0.3544566650390625\n",
      "Epoch 15840:         train accuracy = 2.7326 | logprob = -1.4777 | KL term = 0.3542194519042969\n",
      "Epoch 15860:         train accuracy = 2.7324 | logprob = -1.4778 | KL term = 0.3539856872558594\n",
      "Epoch 15880:         train accuracy = 2.7323 | logprob = -1.4779 | KL term = 0.353754638671875\n",
      "Epoch 15900:         train accuracy = 2.7321 | logprob = -1.4781 | KL term = 0.3535258178710938\n",
      "Epoch 15920:         train accuracy = 2.7320 | logprob = -1.4782 | KL term = 0.35329833984375\n",
      "Epoch 15940:         train accuracy = 2.7319 | logprob = -1.4783 | KL term = 0.35307177734375\n",
      "Epoch 15960:         train accuracy = 2.7319 | logprob = -1.4784 | KL term = 0.3528453369140625\n",
      "Epoch 15980:         train accuracy = 2.7318 | logprob = -1.4785 | KL term = 0.35261843872070314\n",
      "Epoch 16000:         train accuracy = 2.7318 | logprob = -1.4786 | KL term = 0.35239047241210936\n",
      "Epoch 16020:         train accuracy = 2.7318 | logprob = -1.4788 | KL term = 0.352160888671875\n",
      "Epoch 16040:         train accuracy = 2.7318 | logprob = -1.4789 | KL term = 0.35192926025390625\n",
      "Epoch 16060:         train accuracy = 2.7319 | logprob = -1.4790 | KL term = 0.3516942138671875\n",
      "Epoch 16080:         train accuracy = 2.7320 | logprob = -1.4791 | KL term = 0.35145013427734373\n",
      "Epoch 16100:         train accuracy = 2.7326 | logprob = -1.4791 | KL term = 0.3511719970703125\n",
      "Epoch 16120:         train accuracy = 2.7334 | logprob = -1.4790 | KL term = 0.3507613525390625\n",
      "Epoch 16140:         train accuracy = 2.7334 | logprob = -1.4787 | KL term = 0.35028326416015626\n",
      "Epoch 16160:         train accuracy = 2.7331 | logprob = -1.4787 | KL term = 0.3498695068359375\n",
      "Epoch 16180:         train accuracy = 2.7329 | logprob = -1.4786 | KL term = 0.3495068664550781\n",
      "Epoch 16200:         train accuracy = 2.7327 | logprob = -1.4787 | KL term = 0.34917315673828125\n",
      "Epoch 16220:         train accuracy = 2.7325 | logprob = -1.4787 | KL term = 0.34886019897460935\n",
      "Epoch 16240:         train accuracy = 2.7324 | logprob = -1.4787 | KL term = 0.34856170654296875\n",
      "Epoch 16260:         train accuracy = 2.7323 | logprob = -1.4788 | KL term = 0.34827593994140627\n",
      "Epoch 16280:         train accuracy = 2.7323 | logprob = -1.4788 | KL term = 0.34800302124023436\n",
      "Epoch 16300:         train accuracy = 2.7322 | logprob = -1.4789 | KL term = 0.34774462890625\n",
      "Epoch 16320:         train accuracy = 2.7321 | logprob = -1.4789 | KL term = 0.347502197265625\n",
      "Epoch 16340:         train accuracy = 2.7321 | logprob = -1.4789 | KL term = 0.347275146484375\n",
      "Epoch 16360:         train accuracy = 2.7320 | logprob = -1.4790 | KL term = 0.3470608825683594\n",
      "Epoch 16380:         train accuracy = 2.7320 | logprob = -1.4790 | KL term = 0.346856689453125\n",
      "Epoch 16400:         train accuracy = 2.7320 | logprob = -1.4790 | KL term = 0.34666064453125\n",
      "Epoch 16420:         train accuracy = 2.7320 | logprob = -1.4791 | KL term = 0.3464718017578125\n",
      "Epoch 16440:         train accuracy = 2.7319 | logprob = -1.4791 | KL term = 0.34628958129882814\n",
      "Epoch 16460:         train accuracy = 2.7319 | logprob = -1.4791 | KL term = 0.3461134033203125\n",
      "Epoch 16480:         train accuracy = 2.7319 | logprob = -1.4792 | KL term = 0.3459427795410156\n",
      "Epoch 16500:         train accuracy = 2.7319 | logprob = -1.4792 | KL term = 0.34577728271484376\n",
      "Epoch 16520:         train accuracy = 2.7319 | logprob = -1.4792 | KL term = 0.34561666870117186\n",
      "Epoch 16540:         train accuracy = 2.7319 | logprob = -1.4793 | KL term = 0.34546054077148436\n",
      "Epoch 16560:         train accuracy = 2.7318 | logprob = -1.4793 | KL term = 0.34530859375\n",
      "Epoch 16580:         train accuracy = 2.7318 | logprob = -1.4793 | KL term = 0.34516064453125\n",
      "Epoch 16600:         train accuracy = 2.7318 | logprob = -1.4793 | KL term = 0.3450164794921875\n",
      "Epoch 16620:         train accuracy = 2.7318 | logprob = -1.4794 | KL term = 0.3448758544921875\n",
      "Epoch 16640:         train accuracy = 2.7318 | logprob = -1.4794 | KL term = 0.3447387084960937\n",
      "Epoch 16660:         train accuracy = 2.7318 | logprob = -1.4794 | KL term = 0.34460479736328126\n",
      "Epoch 16680:         train accuracy = 2.7318 | logprob = -1.4794 | KL term = 0.3444739685058594\n",
      "Epoch 16700:         train accuracy = 2.7318 | logprob = -1.4795 | KL term = 0.34434613037109374\n",
      "Epoch 16720:         train accuracy = 2.7318 | logprob = -1.4795 | KL term = 0.3442210998535156\n",
      "Epoch 16740:         train accuracy = 2.7318 | logprob = -1.4795 | KL term = 0.344098876953125\n",
      "Epoch 16760:         train accuracy = 2.7317 | logprob = -1.4796 | KL term = 0.34397933959960936\n",
      "Epoch 16780:         train accuracy = 2.7317 | logprob = -1.4796 | KL term = 0.3438624267578125\n",
      "Epoch 16800:         train accuracy = 2.7317 | logprob = -1.4796 | KL term = 0.343748046875\n",
      "Epoch 16820:         train accuracy = 2.7317 | logprob = -1.4796 | KL term = 0.3436361083984375\n",
      "Epoch 16840:         train accuracy = 2.7317 | logprob = -1.4797 | KL term = 0.3435265808105469\n",
      "Epoch 16860:         train accuracy = 2.7317 | logprob = -1.4797 | KL term = 0.34341940307617186\n",
      "Epoch 16880:         train accuracy = 2.7317 | logprob = -1.4797 | KL term = 0.34331451416015624\n",
      "Epoch 16900:         train accuracy = 2.7317 | logprob = -1.4797 | KL term = 0.3432118225097656\n",
      "Epoch 16920:         train accuracy = 2.7317 | logprob = -1.4798 | KL term = 0.343111328125\n",
      "Epoch 16940:         train accuracy = 2.7317 | logprob = -1.4798 | KL term = 0.34301296997070313\n",
      "Epoch 16960:         train accuracy = 2.7317 | logprob = -1.4798 | KL term = 0.34291668701171873\n",
      "Epoch 16980:         train accuracy = 2.7317 | logprob = -1.4798 | KL term = 0.3428223876953125\n",
      "Epoch 17000:         train accuracy = 2.7317 | logprob = -1.4799 | KL term = 0.34273016357421876\n",
      "Epoch 17020:         train accuracy = 2.7317 | logprob = -1.4799 | KL term = 0.342639892578125\n",
      "Epoch 17040:         train accuracy = 2.7317 | logprob = -1.4799 | KL term = 0.3425514831542969\n",
      "Epoch 17060:         train accuracy = 2.7317 | logprob = -1.4799 | KL term = 0.3424649658203125\n",
      "Epoch 17080:         train accuracy = 2.7317 | logprob = -1.4800 | KL term = 0.34238021850585937\n",
      "Epoch 17100:         train accuracy = 2.7316 | logprob = -1.4800 | KL term = 0.34229727172851565\n",
      "Epoch 17120:         train accuracy = 2.7316 | logprob = -1.4800 | KL term = 0.34221612548828123\n",
      "Epoch 17140:         train accuracy = 2.7316 | logprob = -1.4800 | KL term = 0.3421365966796875\n",
      "Epoch 17160:         train accuracy = 2.7316 | logprob = -1.4801 | KL term = 0.34205874633789063\n",
      "Epoch 17180:         train accuracy = 2.7316 | logprob = -1.4801 | KL term = 0.3419825439453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17200:         train accuracy = 2.7316 | logprob = -1.4801 | KL term = 0.34190786743164064\n",
      "Epoch 17220:         train accuracy = 2.7316 | logprob = -1.4802 | KL term = 0.34183477783203126\n",
      "Epoch 17240:         train accuracy = 2.7316 | logprob = -1.4802 | KL term = 0.34176318359375\n",
      "Epoch 17260:         train accuracy = 2.7316 | logprob = -1.4802 | KL term = 0.3416929931640625\n",
      "Epoch 17280:         train accuracy = 2.7316 | logprob = -1.4802 | KL term = 0.34162417602539064\n",
      "Epoch 17300:         train accuracy = 2.7316 | logprob = -1.4803 | KL term = 0.3415567016601562\n",
      "Epoch 17320:         train accuracy = 2.7316 | logprob = -1.4803 | KL term = 0.3414905090332031\n",
      "Epoch 17340:         train accuracy = 2.7316 | logprob = -1.4803 | KL term = 0.341425537109375\n",
      "Epoch 17360:         train accuracy = 2.7316 | logprob = -1.4803 | KL term = 0.34136175537109376\n",
      "Epoch 17380:         train accuracy = 2.7316 | logprob = -1.4804 | KL term = 0.34129913330078127\n",
      "Epoch 17400:         train accuracy = 2.7316 | logprob = -1.4804 | KL term = 0.3412376098632813\n",
      "Epoch 17420:         train accuracy = 2.7316 | logprob = -1.4804 | KL term = 0.34117706298828127\n",
      "Epoch 17440:         train accuracy = 2.7316 | logprob = -1.4805 | KL term = 0.34111749267578123\n",
      "Epoch 17460:         train accuracy = 2.7316 | logprob = -1.4805 | KL term = 0.3410588684082031\n",
      "Epoch 17480:         train accuracy = 2.7316 | logprob = -1.4805 | KL term = 0.34100115966796873\n",
      "Epoch 17500:         train accuracy = 2.7316 | logprob = -1.4805 | KL term = 0.3409442443847656\n",
      "Epoch 17520:         train accuracy = 2.7316 | logprob = -1.4806 | KL term = 0.34088812255859374\n",
      "Epoch 17540:         train accuracy = 2.7316 | logprob = -1.4806 | KL term = 0.3408326416015625\n",
      "Epoch 17560:         train accuracy = 2.7316 | logprob = -1.4806 | KL term = 0.3407777404785156\n",
      "Epoch 17580:         train accuracy = 2.7316 | logprob = -1.4807 | KL term = 0.34072341918945315\n",
      "Epoch 17600:         train accuracy = 2.7315 | logprob = -1.4807 | KL term = 0.34066961669921875\n",
      "Epoch 17620:         train accuracy = 2.7315 | logprob = -1.4807 | KL term = 0.34061624145507813\n",
      "Epoch 17640:         train accuracy = 2.7315 | logprob = -1.4808 | KL term = 0.340563232421875\n",
      "Epoch 17660:         train accuracy = 2.7315 | logprob = -1.4808 | KL term = 0.34051046752929687\n",
      "Epoch 17680:         train accuracy = 2.7315 | logprob = -1.4808 | KL term = 0.34045794677734376\n",
      "Epoch 17700:         train accuracy = 2.7315 | logprob = -1.4809 | KL term = 0.34040557861328125\n",
      "Epoch 17720:         train accuracy = 2.7315 | logprob = -1.4809 | KL term = 0.34035324096679687\n",
      "Epoch 17740:         train accuracy = 2.7315 | logprob = -1.4809 | KL term = 0.3403009033203125\n",
      "Epoch 17760:         train accuracy = 2.7315 | logprob = -1.4810 | KL term = 0.34024847412109377\n",
      "Epoch 17780:         train accuracy = 2.7315 | logprob = -1.4810 | KL term = 0.3401958923339844\n",
      "Epoch 17800:         train accuracy = 2.7315 | logprob = -1.4810 | KL term = 0.3401430969238281\n",
      "Epoch 17820:         train accuracy = 2.7315 | logprob = -1.4811 | KL term = 0.3400899658203125\n",
      "Epoch 17840:         train accuracy = 2.7315 | logprob = -1.4811 | KL term = 0.34003634643554687\n",
      "Epoch 17860:         train accuracy = 2.7315 | logprob = -1.4811 | KL term = 0.339982177734375\n",
      "Epoch 17880:         train accuracy = 2.7315 | logprob = -1.4812 | KL term = 0.33992742919921876\n",
      "Epoch 17900:         train accuracy = 2.7315 | logprob = -1.4812 | KL term = 0.33987188720703126\n",
      "Epoch 17920:         train accuracy = 2.7315 | logprob = -1.4813 | KL term = 0.3398155517578125\n",
      "Epoch 17940:         train accuracy = 2.7315 | logprob = -1.4813 | KL term = 0.33975820922851563\n",
      "Epoch 17960:         train accuracy = 2.7315 | logprob = -1.4813 | KL term = 0.33969970703125\n",
      "Epoch 17980:         train accuracy = 2.7314 | logprob = -1.4814 | KL term = 0.33963983154296873\n",
      "Epoch 18000:         train accuracy = 2.7314 | logprob = -1.4814 | KL term = 0.33957839965820313\n",
      "Epoch 18020:         train accuracy = 2.7314 | logprob = -1.4815 | KL term = 0.33951516723632813\n",
      "Epoch 18040:         train accuracy = 2.7314 | logprob = -1.4815 | KL term = 0.339449951171875\n",
      "Epoch 18060:         train accuracy = 2.7314 | logprob = -1.4816 | KL term = 0.339382568359375\n",
      "Epoch 18080:         train accuracy = 2.7314 | logprob = -1.4816 | KL term = 0.3393125610351562\n",
      "Epoch 18100:         train accuracy = 2.7314 | logprob = -1.4817 | KL term = 0.339239501953125\n",
      "Epoch 18120:         train accuracy = 2.7314 | logprob = -1.4818 | KL term = 0.3391630859375\n",
      "Epoch 18140:         train accuracy = 2.7314 | logprob = -1.4818 | KL term = 0.33908270263671875\n",
      "Epoch 18160:         train accuracy = 2.7313 | logprob = -1.4819 | KL term = 0.3389977722167969\n",
      "Epoch 18180:         train accuracy = 2.7313 | logprob = -1.4820 | KL term = 0.338907470703125\n",
      "Epoch 18200:         train accuracy = 2.7313 | logprob = -1.4820 | KL term = 0.338810791015625\n",
      "Epoch 18220:         train accuracy = 2.7313 | logprob = -1.4821 | KL term = 0.33870654296875\n",
      "Epoch 18240:         train accuracy = 2.7313 | logprob = -1.4822 | KL term = 0.3385931396484375\n",
      "Epoch 18260:         train accuracy = 2.7312 | logprob = -1.4823 | KL term = 0.33846844482421873\n",
      "Epoch 18280:         train accuracy = 2.7312 | logprob = -1.4824 | KL term = 0.3383296813964844\n",
      "Epoch 18300:         train accuracy = 2.7312 | logprob = -1.4826 | KL term = 0.3381729736328125\n",
      "Epoch 18320:         train accuracy = 2.7311 | logprob = -1.4827 | KL term = 0.33799273681640624\n",
      "Epoch 18340:         train accuracy = 2.7311 | logprob = -1.4829 | KL term = 0.3377811279296875\n",
      "Epoch 18360:         train accuracy = 2.7310 | logprob = -1.4831 | KL term = 0.33752667236328127\n",
      "Epoch 18380:         train accuracy = 2.7309 | logprob = -1.4833 | KL term = 0.33721368408203123\n",
      "Epoch 18400:         train accuracy = 2.7308 | logprob = -1.4835 | KL term = 0.33682501220703126\n",
      "Epoch 18420:         train accuracy = 2.7307 | logprob = -1.4837 | KL term = 0.3363563232421875\n",
      "Epoch 18440:         train accuracy = 2.7306 | logprob = -1.4839 | KL term = 0.3358389892578125\n",
      "Epoch 18460:         train accuracy = 2.7306 | logprob = -1.4840 | KL term = 0.3353312683105469\n",
      "Epoch 18480:         train accuracy = 2.7307 | logprob = -1.4841 | KL term = 0.3348752746582031\n",
      "Epoch 18500:         train accuracy = 2.7308 | logprob = -1.4841 | KL term = 0.334482666015625\n",
      "Epoch 18520:         train accuracy = 2.7309 | logprob = -1.4840 | KL term = 0.3341474609375\n",
      "Epoch 18540:         train accuracy = 2.7311 | logprob = -1.4840 | KL term = 0.3338590393066406\n",
      "Epoch 18560:         train accuracy = 2.7312 | logprob = -1.4840 | KL term = 0.333607421875\n",
      "Epoch 18580:         train accuracy = 2.7312 | logprob = -1.4840 | KL term = 0.3333851318359375\n",
      "Epoch 18600:         train accuracy = 2.7313 | logprob = -1.4840 | KL term = 0.33318658447265626\n",
      "Epoch 18620:         train accuracy = 2.7314 | logprob = -1.4840 | KL term = 0.33300811767578126\n",
      "Epoch 18640:         train accuracy = 2.7314 | logprob = -1.4840 | KL term = 0.33284674072265624\n",
      "Epoch 18660:         train accuracy = 2.7315 | logprob = -1.4840 | KL term = 0.3327000732421875\n",
      "Epoch 18680:         train accuracy = 2.7315 | logprob = -1.4840 | KL term = 0.3325663146972656\n",
      "Epoch 18700:         train accuracy = 2.7315 | logprob = -1.4840 | KL term = 0.33244403076171875\n",
      "Epoch 18720:         train accuracy = 2.7316 | logprob = -1.4840 | KL term = 0.33233251953125\n",
      "Epoch 18740:         train accuracy = 2.7316 | logprob = -1.4839 | KL term = 0.33223193359375\n",
      "Epoch 18760:         train accuracy = 2.7316 | logprob = -1.4839 | KL term = 0.33214324951171875\n",
      "Epoch 18780:         train accuracy = 2.7316 | logprob = -1.4839 | KL term = 0.33206787109375\n",
      "Epoch 18800:         train accuracy = 2.7317 | logprob = -1.4839 | KL term = 0.3320062255859375\n",
      "Epoch 18820:         train accuracy = 2.7317 | logprob = -1.4839 | KL term = 0.33195700073242185\n",
      "Epoch 18840:         train accuracy = 2.7317 | logprob = -1.4839 | KL term = 0.3319170227050781\n",
      "Epoch 18860:         train accuracy = 2.7317 | logprob = -1.4839 | KL term = 0.33188323974609374\n",
      "Epoch 18880:         train accuracy = 2.7317 | logprob = -1.4839 | KL term = 0.33185385131835937\n",
      "Epoch 18900:         train accuracy = 2.7318 | logprob = -1.4839 | KL term = 0.3318278198242188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18920:         train accuracy = 2.7318 | logprob = -1.4839 | KL term = 0.3318045654296875\n",
      "Epoch 18940:         train accuracy = 2.7318 | logprob = -1.4838 | KL term = 0.33178359985351563\n",
      "Epoch 18960:         train accuracy = 2.7318 | logprob = -1.4838 | KL term = 0.33176470947265624\n",
      "Epoch 18980:         train accuracy = 2.7318 | logprob = -1.4838 | KL term = 0.3317474670410156\n",
      "Epoch 19000:         train accuracy = 2.7318 | logprob = -1.4838 | KL term = 0.3317317199707031\n",
      "Epoch 19020:         train accuracy = 2.7318 | logprob = -1.4838 | KL term = 0.33171728515625\n",
      "Epoch 19040:         train accuracy = 2.7319 | logprob = -1.4838 | KL term = 0.3317039794921875\n",
      "Epoch 19060:         train accuracy = 2.7319 | logprob = -1.4838 | KL term = 0.33169171142578124\n",
      "Epoch 19080:         train accuracy = 2.7319 | logprob = -1.4838 | KL term = 0.33168026733398437\n",
      "Epoch 19100:         train accuracy = 2.7319 | logprob = -1.4838 | KL term = 0.33166961669921874\n",
      "Epoch 19120:         train accuracy = 2.7319 | logprob = -1.4838 | KL term = 0.33165966796875\n",
      "Epoch 19140:         train accuracy = 2.7319 | logprob = -1.4838 | KL term = 0.331650390625\n",
      "Epoch 19160:         train accuracy = 2.7319 | logprob = -1.4838 | KL term = 0.3316417236328125\n",
      "Epoch 19180:         train accuracy = 2.7319 | logprob = -1.4838 | KL term = 0.331633544921875\n",
      "Epoch 19200:         train accuracy = 2.7319 | logprob = -1.4838 | KL term = 0.33162579345703125\n",
      "Epoch 19220:         train accuracy = 2.7319 | logprob = -1.4838 | KL term = 0.3316184997558594\n",
      "Epoch 19240:         train accuracy = 2.7320 | logprob = -1.4838 | KL term = 0.331611572265625\n",
      "Epoch 19260:         train accuracy = 2.7320 | logprob = -1.4838 | KL term = 0.3316051025390625\n",
      "Epoch 19280:         train accuracy = 2.7320 | logprob = -1.4838 | KL term = 0.331598876953125\n",
      "Epoch 19300:         train accuracy = 2.7320 | logprob = -1.4838 | KL term = 0.331593017578125\n",
      "Epoch 19320:         train accuracy = 2.7320 | logprob = -1.4838 | KL term = 0.33158740234375\n",
      "Epoch 19340:         train accuracy = 2.7320 | logprob = -1.4837 | KL term = 0.33158212280273436\n",
      "Epoch 19360:         train accuracy = 2.7320 | logprob = -1.4837 | KL term = 0.33157705688476563\n",
      "Epoch 19380:         train accuracy = 2.7320 | logprob = -1.4837 | KL term = 0.331572265625\n",
      "Epoch 19400:         train accuracy = 2.7320 | logprob = -1.4837 | KL term = 0.3315676574707031\n",
      "Epoch 19420:         train accuracy = 2.7320 | logprob = -1.4837 | KL term = 0.3315632934570312\n",
      "Epoch 19440:         train accuracy = 2.7320 | logprob = -1.4837 | KL term = 0.33155911254882814\n",
      "Epoch 19460:         train accuracy = 2.7320 | logprob = -1.4837 | KL term = 0.3315551147460937\n",
      "Epoch 19480:         train accuracy = 2.7320 | logprob = -1.4837 | KL term = 0.3315513000488281\n",
      "Epoch 19500:         train accuracy = 2.7320 | logprob = -1.4837 | KL term = 0.33154763793945313\n",
      "Epoch 19520:         train accuracy = 2.7320 | logprob = -1.4837 | KL term = 0.331544189453125\n",
      "Epoch 19540:         train accuracy = 2.7320 | logprob = -1.4837 | KL term = 0.3315408935546875\n",
      "Epoch 19560:         train accuracy = 2.7320 | logprob = -1.4837 | KL term = 0.33153768920898435\n",
      "Epoch 19580:         train accuracy = 2.7320 | logprob = -1.4837 | KL term = 0.33153466796875\n",
      "Epoch 19600:         train accuracy = 2.7320 | logprob = -1.4837 | KL term = 0.33153179931640625\n",
      "Epoch 19620:         train accuracy = 2.7320 | logprob = -1.4837 | KL term = 0.331529052734375\n",
      "Epoch 19640:         train accuracy = 2.7320 | logprob = -1.4837 | KL term = 0.3315263671875\n",
      "Epoch 19660:         train accuracy = 2.7320 | logprob = -1.4837 | KL term = 0.33152392578125\n",
      "Epoch 19680:         train accuracy = 2.7321 | logprob = -1.4837 | KL term = 0.33152154541015627\n",
      "Epoch 19700:         train accuracy = 2.7321 | logprob = -1.4837 | KL term = 0.331519287109375\n",
      "Epoch 19720:         train accuracy = 2.7321 | logprob = -1.4837 | KL term = 0.33151708984375\n",
      "Epoch 19740:         train accuracy = 2.7321 | logprob = -1.4837 | KL term = 0.3315150146484375\n",
      "Epoch 19760:         train accuracy = 2.7321 | logprob = -1.4837 | KL term = 0.3315130615234375\n",
      "Epoch 19780:         train accuracy = 2.7321 | logprob = -1.4837 | KL term = 0.3315112609863281\n",
      "Epoch 19800:         train accuracy = 2.7321 | logprob = -1.4837 | KL term = 0.33150946044921875\n",
      "Epoch 19820:         train accuracy = 2.7321 | logprob = -1.4837 | KL term = 0.33150775146484374\n",
      "Epoch 19840:         train accuracy = 2.7321 | logprob = -1.4837 | KL term = 0.3315061340332031\n",
      "Epoch 19860:         train accuracy = 2.7321 | logprob = -1.4837 | KL term = 0.331504638671875\n",
      "Epoch 19880:         train accuracy = 2.7321 | logprob = -1.4837 | KL term = 0.3315030822753906\n",
      "Epoch 19900:         train accuracy = 2.7321 | logprob = -1.4837 | KL term = 0.33150177001953124\n",
      "Epoch 19920:         train accuracy = 2.7321 | logprob = -1.4837 | KL term = 0.3315004577636719\n",
      "Epoch 19940:         train accuracy = 2.7321 | logprob = -1.4837 | KL term = 0.33149917602539064\n",
      "Epoch 19960:         train accuracy = 2.7321 | logprob = -1.4837 | KL term = 0.33149798583984375\n",
      "Epoch 19980:         train accuracy = 2.7321 | logprob = -1.4837 | KL term = 0.3314968566894531\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "run(toy_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于m的结果，DVI和MCVI的一致性变强了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
