{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在不同数据集上测试DVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "from matplotlib import rc\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "rc('text', usetex=True)\n",
    "rc('font', size=15)\n",
    "rc('xtick', labelsize=10)\n",
    "rc('ytick', labelsize=10)\n",
    "\n",
    "import gaussian_variables as gv\n",
    "import utils as u\n",
    "import plot_utils as pu\n",
    "import bayes_layers as bnn\n",
    "from bayes_models import MLP, PointMLP, AdaptedMLP\n",
    "from dataset.UCIdataset import UCIDataset\n",
    "from dataset.Facedataset import FaceDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(hypers):\n",
    "    if hypers['method'].lower().strip() == 'bayes':\n",
    "        MLP_factory = MLP\n",
    "\n",
    "        def prediction(y): return tf.reshape(y.mean[:, 0], [-1])\n",
    "        loss = bnn.regression_loss\n",
    "    else:\n",
    "        MLP_factory = PointMLP\n",
    "\n",
    "        def prediction(y): return tf.reshape(y.mean[:, 0], [-1])\n",
    "        loss = bnn.point_regression_loss\n",
    "\n",
    "    mlp = MLP_factory(hypers['x_dim'], hypers['y_dim'], hypers)\n",
    "    mlp = AdaptedMLP(mlp)\n",
    "    mlp.make_placeholders()\n",
    "    ipt = mlp.placeholders['ipt_mean']\n",
    "    y = mlp(ipt)\n",
    "\n",
    "    target = tf.placeholder(tf.float32, [None])\n",
    "    mlp.placeholders['target'] = target\n",
    "    global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "    loss, logprob, all_surprise = loss(y, target, mlp, hypers, global_step)\n",
    "\n",
    "    accuracy = tf.reduce_mean(tf.abs(target - prediction(y)))\n",
    "\n",
    "    return {\n",
    "        'model': mlp,\n",
    "        'metrics': {\n",
    "            'accuracy': accuracy, 'loss': loss,\n",
    "            'logprob': logprob, 'all_surprise': all_surprise\n",
    "        },\n",
    "        'global_step': global_step}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练和测试的函数。除了“prot”数据集因为数据量过大而使用1000大小的minibatch训练之外，其他都是用全部数据进行训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(\n",
    "        Xtrain,\n",
    "        Ytrain,\n",
    "        Xtest,\n",
    "        Ytest,\n",
    "        paras,\n",
    "        outpath):\n",
    "    train_no, x_dim = Xtrain.shape\n",
    "    try:\n",
    "        test_no, y_dim = Ytest.shape\n",
    "    except:\n",
    "        test_no = Ytest.shape\n",
    "        y_dim = 1\n",
    "\n",
    "    hypers = {\n",
    "        \"x_dim\": x_dim,\n",
    "        \"y_dim\": y_dim,\n",
    "        \"hidden_dims\": paras[\"hidden_dims\"],\n",
    "        \"nonlinearity\": \"relu\",\n",
    "        \"adapter\": {'in':paras['in'],'out':paras['out']},\n",
    "        \"method\": \"bayes\",\n",
    "        \"style\": \"heteroskedastic\",\n",
    "        \"homo_logvar_scale\": 2 * np.log(0.2),\n",
    "        \"prior_type\": [\n",
    "            \"empirical\",\n",
    "            \"wider_he\",\n",
    "            \"wider_he\"],\n",
    "        \"n_epochs\": paras['n_epochs'],\n",
    "#         \"batch_size\": 1000,\n",
    "        \"batch_size\": train_no,\n",
    "        \"learning_rate\": paras['learning_rate'],\n",
    "        \"lambda\": 1.0,\n",
    "        \"warmup_updates\": {\n",
    "            'lambda': 14000.0},\n",
    "        \"anneal_updates\": {\n",
    "            'lambda': 1000.0},\n",
    "        \"optimizer\": \"adam\",\n",
    "        \"gradient_clip\": 0.1,\n",
    "        \"data_fraction\": 1.0,\n",
    "        \"sections_to_run\": [\n",
    "            \"train\",\n",
    "            'test']}\n",
    "\n",
    "    data = [[Xtrain, Ytrain.reshape(-1)],\n",
    "            [Xtest, Ytest.reshape(-1)]]\n",
    "\n",
    "    restricted_training_set = u.restrict_dataset_size(\n",
    "        data[0], hypers['data_fraction'])\n",
    "    hypers['dataset_size'] = len(restricted_training_set[0])\n",
    "\n",
    "    device_id = 0\n",
    "    device_string = u.get_device_string(device_id)\n",
    "    print(hypers)\n",
    "    with tf.device(device_string):\n",
    "        if True:\n",
    "            model_and_metrics = make_model(hypers)\n",
    "\n",
    "            train_op = u.make_optimizer(model_and_metrics, hypers)\n",
    "            sess = u.get_session()\n",
    "            saver = tf.train.Saver()\n",
    "\n",
    "            all_summaries = []\n",
    "            best_valid_accuracy = np.inf\n",
    "\n",
    "        for epoch in range(1, hypers['n_epochs'] + 1):\n",
    "            verbose = (epoch % 20 == 0)\n",
    "            if verbose:\n",
    "                print(\"Epoch %i:        \" % epoch, end='')\n",
    "\n",
    "            epoch_summary, accuracies = u.train_valid_test(\n",
    "                {\n",
    "                    'train': restricted_training_set,\n",
    "                    'test': data[1]\n",
    "                },\n",
    "                sess, model_and_metrics, train_op, hypers, verbose)\n",
    "            # dump log file\n",
    "            all_summaries.append(epoch_summary)\n",
    "\n",
    "            if epoch % 5000 == 0:\n",
    "                saver.save(\n",
    "                    sess,\n",
    "                    os.path.join(\n",
    "                        outpath,\n",
    "                        'model.ckpt'),\n",
    "                    global_step=epoch)\n",
    "\n",
    "        with open(os.path.join(outpath, \"summaries.json\"), 'w') as f:\n",
    "            json.dump(all_summaries, f, indent=4, cls=u.NumpyEncoder)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每个数据集运行多次，取结果的平均。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_(dataset_name, dataset_path, times, paras):\n",
    "    np.random.seed(123)\n",
    "\n",
    "    for time in range(times):\n",
    "        outpath = os.path.join(dataset_path, str(time))\n",
    "        if not os.path.exists(outpath):\n",
    "            os.makedirs(outpath)\n",
    "\n",
    "        if dataset_name == 'face':\n",
    "            data = FaceDataset(\"./dataset\", 0.9)\n",
    "        else:\n",
    "            data = UCIDataset(dataset_name, 0.9)\n",
    "        print(\n",
    "            data.Xtrain.shape,\n",
    "            data.Ytrain.shape,\n",
    "            data.Xtest.shape,\n",
    "            data.Ytest.shape)\n",
    "\n",
    "        train_test(\n",
    "            data.Xtrain,\n",
    "            data.Ytrain,\n",
    "            data.Xtest,\n",
    "            data.Ytest,\n",
    "            paras,\n",
    "            outpath)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画出测试集的log-likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_(datasets, root_path, times, epoch_list, shape):\n",
    "    fig = plt.figure()\n",
    "    for i in range(len(datasets)):\n",
    "        dataset_name = datasets[i]\n",
    "        print (dataset_name)\n",
    "        data_path = os.path.join(root_path, dataset_name)\n",
    "        b_epoch, e_epoch = epoch_list[i]\n",
    "        ax = fig.add_subplot(2, 2, i + 1)\n",
    "        pu.UCI_result_plot(\n",
    "            dataset_name,\n",
    "            data_path,\n",
    "            times,\n",
    "            ax,\n",
    "            b_epoch=b_epoch,\n",
    "            e_epoch=e_epoch,\n",
    "            shape=shape)\n",
    "        if i+1 in [1, 3]:\n",
    "            ax.set_ylabel(shape)\n",
    "        if i+1 in [3, 4]:\n",
    "            ax.set_xlabel('Epoch')\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_face(root_path, times, b_epoch, e_epoch, shape):\n",
    "    fig = plt.figure()\n",
    "    data_path = os.path.join(root_path, dataset_name)\n",
    "    ax = fig.add_subplot(111)\n",
    "    test_mean, test_std = pu.UCI_result_plot(\n",
    "        dataset_name,\n",
    "        data_path,\n",
    "        times,\n",
    "        ax,\n",
    "        b_epoch=b_epoch,\n",
    "        e_epoch=e_epoch,\n",
    "        shape=shape)\n",
    "\n",
    "    ax.set_ylabel(shape)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "开始运行，这里以“conc”数据集为例，只运行一次，实际项目中是运行20次。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(927, 8) (927, 1) (103, 8) (103, 1)\n",
      "{'x_dim': 8, 'y_dim': 1, 'hidden_dims': [50], 'nonlinearity': 'relu', 'adapter': {'in': {'scale': [[1.0]], 'shift': [[0.0]]}, 'out': {'scale': [[1.0, 0.1]], 'shift': [[0.0, 1.9]]}}, 'method': 'bayes', 'style': 'heteroskedastic', 'homo_logvar_scale': -3.2188758248682006, 'prior_type': ['empirical', 'wider_he', 'wider_he'], 'n_epochs': 2000, 'batch_size': 927, 'learning_rate': 0.1, 'lambda': 1.0, 'warmup_updates': {'lambda': 14000.0}, 'anneal_updates': {'lambda': 1000.0}, 'optimizer': 'adam', 'gradient_clip': 0.1, 'data_fraction': 1.0, 'sections_to_run': ['train', 'test'], 'dataset_size': 927}\n",
      "WARNING:tensorflow:From /home/yunnd/.conda/envs/tf1.13.1/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/yunnd/project/code/MCS-project/gaussian_variables.py:77: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 20:         train accuracy = 33.7896 | logprob = -89.9332 | KL term = 1.4956175836030206 test accuracy = 34.9720 | logprob = -92.7892 | KL term = 1.5333909052218178\n",
      "Epoch 40:         train accuracy = 31.7942 | logprob = -67.4459 | KL term = 1.8455256160666127 test accuracy = 32.9720 | logprob = -69.6141 | KL term = 1.8510942345941208\n",
      "Epoch 60:         train accuracy = 29.8103 | logprob = -50.5886 | KL term = 1.8978658632938916 test accuracy = 30.9947 | logprob = -52.2214 | KL term = 1.8987003396372708\n",
      "Epoch 80:         train accuracy = 27.8549 | logprob = -38.0022 | KL term = 1.9057407811235842 test accuracy = 29.0385 | logprob = -39.2199 | KL term = 1.9058711474767396\n",
      "Epoch 100:         train accuracy = 25.9613 | logprob = -28.6462 | KL term = 1.9070668307965886 test accuracy = 27.1550 | logprob = -29.5436 | KL term = 1.9070946159486246\n",
      "Epoch 120:         train accuracy = 24.1620 | logprob = -21.7261 | KL term = 1.9074304080703883 test accuracy = 25.3277 | logprob = -22.3776 | KL term = 1.9074425229234089\n",
      "Epoch 140:         train accuracy = 22.4831 | logprob = -16.6364 | KL term = 1.9076318833434467 test accuracy = 23.5763 | logprob = -17.1004 | KL term = 1.9076404427504718\n",
      "Epoch 160:         train accuracy = 20.9535 | logprob = -12.9173 | KL term = 1.907789376432713 test accuracy = 21.8959 | logprob = -13.2393 | KL term = 1.9077966190078883\n",
      "Epoch 180:         train accuracy = 19.5549 | logprob = -10.2202 | KL term = 1.9079244833805287 test accuracy = 20.3103 | logprob = -10.4357 | KL term = 1.9079308041734089\n",
      "Epoch 200:         train accuracy = 18.2829 | logprob = -8.2821 | KL term = 1.9080441833956985 test accuracy = 18.8165 | logprob = -8.4183 | KL term = 1.9080498457726538\n",
      "Epoch 220:         train accuracy = 17.1122 | logprob = -6.9048 | KL term = 1.908151505191478 test accuracy = 17.4007 | logprob = -6.9830 | KL term = 1.9081566408356931\n",
      "Epoch 240:         train accuracy = 16.0564 | logprob = -5.9399 | KL term = 1.908248819065197 test accuracy = 16.3285 | logprob = -5.9762 | KL term = 1.908253427976672\n",
      "Epoch 260:         train accuracy = 15.2064 | logprob = -5.2764 | KL term = 1.9083379685814454 test accuracy = 15.4057 | logprob = -5.2832 | KL term = 1.9083421824433657\n",
      "Epoch 280:         train accuracy = 14.5350 | logprob = -4.8320 | KL term = 1.9084200072057038 test accuracy = 14.6505 | logprob = -4.8186 | KL term = 1.908423957701254\n",
      "Epoch 300:         train accuracy = 13.9995 | logprob = -4.5456 | KL term = 1.908496251769822 test accuracy = 14.0197 | logprob = -4.5189 | KL term = 1.9084999388990023\n",
      "Epoch 320:         train accuracy = 13.6286 | logprob = -4.3794 | KL term = 1.9085635418773597 test accuracy = 13.6278 | logprob = -4.3462 | KL term = 1.90856643890743\n",
      "Epoch 340:         train accuracy = 13.4691 | logprob = -4.3067 | KL term = 1.9086093676257416 test accuracy = 13.4175 | logprob = -4.2708 | KL term = 1.9086112111903317\n",
      "Epoch 360:         train accuracy = 13.4412 | logprob = -4.2751 | KL term = 1.9086388646591828 test accuracy = 13.3127 | logprob = -4.2377 | KL term = 1.908640049807848\n",
      "Epoch 380:         train accuracy = 13.4476 | logprob = -4.2597 | KL term = 1.9086590121864886 test accuracy = 13.2465 | logprob = -4.2214 | KL term = 1.9086599339687838\n",
      "Epoch 400:         train accuracy = 13.4605 | logprob = -4.2516 | KL term = 1.9086734973368393 test accuracy = 13.1980 | logprob = -4.2126 | KL term = 1.9086741557527642\n",
      "Epoch 420:         train accuracy = 13.4766 | logprob = -4.2471 | KL term = 1.9086844270411947 test accuracy = 13.1701 | logprob = -4.2076 | KL term = 1.9086848220907497\n",
      "Epoch 440:         train accuracy = 13.4917 | logprob = -4.2445 | KL term = 1.90869272308185 test accuracy = 13.1522 | logprob = -4.2046 | KL term = 1.908693118131405\n",
      "Epoch 460:         train accuracy = 13.5052 | logprob = -4.2429 | KL term = 1.9086991755579152 test accuracy = 13.1383 | logprob = -4.2029 | KL term = 1.9086994389242853\n",
      "Epoch 480:         train accuracy = 13.5165 | logprob = -4.2420 | KL term = 1.9087041795189454 test accuracy = 13.1275 | logprob = -4.2018 | KL term = 1.9087043112021305\n",
      "Epoch 500:         train accuracy = 13.5256 | logprob = -4.2415 | KL term = 1.9087079983313107 test accuracy = 13.1191 | logprob = -4.2011 | KL term = 1.9087082616976807\n",
      "Epoch 520:         train accuracy = 13.5328 | logprob = -4.2412 | KL term = 1.9087111587277508 test accuracy = 13.1155 | logprob = -4.2007 | KL term = 1.9087112904109358\n",
      "Epoch 540:         train accuracy = 13.5389 | logprob = -4.2410 | KL term = 1.908713529025081 test accuracy = 13.1133 | logprob = -4.2004 | KL term = 1.908713660708266\n",
      "Epoch 560:         train accuracy = 13.5440 | logprob = -4.2408 | KL term = 1.908715504272856 test accuracy = 13.1116 | logprob = -4.2003 | KL term = 1.908715635956041\n",
      "Epoch 580:         train accuracy = 13.5480 | logprob = -4.2408 | KL term = 1.908716952787891 test accuracy = 13.1102 | logprob = -4.2002 | KL term = 1.9087170844710761\n",
      "Epoch 600:         train accuracy = 13.5511 | logprob = -4.2407 | KL term = 1.9087182696197411 test accuracy = 13.1092 | logprob = -4.2001 | KL term = 1.9087182696197411\n",
      "Epoch 620:         train accuracy = 13.5536 | logprob = -4.2407 | KL term = 1.908719191402036 test accuracy = 13.1084 | logprob = -4.2001 | KL term = 1.908719191402036\n",
      "Epoch 640:         train accuracy = 13.5555 | logprob = -4.2407 | KL term = 1.9087199815011462 test accuracy = 13.1078 | logprob = -4.2000 | KL term = 1.9087199815011462\n",
      "Epoch 660:         train accuracy = 13.5570 | logprob = -4.2407 | KL term = 1.9087205082338863 test accuracy = 13.1074 | logprob = -4.2000 | KL term = 1.9087206399170713\n",
      "Epoch 680:         train accuracy = 13.5581 | logprob = -4.2407 | KL term = 1.9087210349666262 test accuracy = 13.1070 | logprob = -4.2000 | KL term = 1.9087210349666262\n",
      "Epoch 700:         train accuracy = 13.5589 | logprob = -4.2407 | KL term = 1.9087214300161812 test accuracy = 13.1068 | logprob = -4.2000 | KL term = 1.9087214300161812\n",
      "Epoch 720:         train accuracy = 13.5595 | logprob = -4.2407 | KL term = 1.9087218250657363 test accuracy = 13.1066 | logprob = -4.2000 | KL term = 1.9087218250657363\n",
      "Epoch 740:         train accuracy = 13.5600 | logprob = -4.2407 | KL term = 1.9087220884321063 test accuracy = 13.1065 | logprob = -4.2000 | KL term = 1.9087220884321063\n",
      "Epoch 760:         train accuracy = 13.5603 | logprob = -4.2407 | KL term = 1.9087223517984762 test accuracy = 13.1064 | logprob = -4.2000 | KL term = 1.9087223517984762\n",
      "Epoch 780:         train accuracy = 13.5605 | logprob = -4.2407 | KL term = 1.9087226151648462 test accuracy = 13.1063 | logprob = -4.2000 | KL term = 1.9087226151648462\n",
      "Epoch 800:         train accuracy = 13.5607 | logprob = -4.2407 | KL term = 1.9087227468480312 test accuracy = 13.1062 | logprob = -4.2000 | KL term = 1.9087227468480312\n",
      "Epoch 820:         train accuracy = 13.5608 | logprob = -4.2407 | KL term = 1.9087230102144013 test accuracy = 13.1062 | logprob = -4.2000 | KL term = 1.9087230102144013\n",
      "Epoch 840:         train accuracy = 13.5609 | logprob = -4.2407 | KL term = 1.9087231418975863 test accuracy = 13.1062 | logprob = -4.2000 | KL term = 1.9087231418975863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 860:         train accuracy = 13.5610 | logprob = -4.2407 | KL term = 1.9087234052639563 test accuracy = 13.1061 | logprob = -4.2000 | KL term = 1.9087234052639563\n",
      "Epoch 880:         train accuracy = 13.5610 | logprob = -4.2407 | KL term = 1.9087235369471414 test accuracy = 13.1061 | logprob = -4.2000 | KL term = 1.9087235369471414\n",
      "Epoch 900:         train accuracy = 13.5610 | logprob = -4.2407 | KL term = 1.9087238003135114 test accuracy = 13.1061 | logprob = -4.2000 | KL term = 1.9087238003135114\n",
      "Epoch 920:         train accuracy = 13.5611 | logprob = -4.2407 | KL term = 1.9087239319966964 test accuracy = 13.1061 | logprob = -4.2000 | KL term = 1.9087239319966964\n",
      "Epoch 940:         train accuracy = 13.5611 | logprob = -4.2407 | KL term = 1.9087240636798812 test accuracy = 13.1061 | logprob = -4.2000 | KL term = 1.9087240636798812\n",
      "Epoch 960:         train accuracy = 13.5611 | logprob = -4.2407 | KL term = 1.9087243270462513 test accuracy = 13.1061 | logprob = -4.2000 | KL term = 1.9087243270462513\n",
      "Epoch 980:         train accuracy = 13.5611 | logprob = -4.2407 | KL term = 1.9087244587294363 test accuracy = 13.1061 | logprob = -4.2000 | KL term = 1.9087244587294363\n",
      "Epoch 1000:         train accuracy = 13.5611 | logprob = -4.2407 | KL term = 1.9087247220958063 test accuracy = 13.1061 | logprob = -4.2000 | KL term = 1.9087247220958063\n",
      "Epoch 1020:         train accuracy = 13.5611 | logprob = -4.2407 | KL term = 1.9087248537789914 test accuracy = 13.1061 | logprob = -4.2000 | KL term = 1.9087248537789914\n",
      "Epoch 1040:         train accuracy = 13.5611 | logprob = -4.2407 | KL term = 1.9087251171453614 test accuracy = 13.1061 | logprob = -4.2000 | KL term = 1.9087251171453614\n",
      "Epoch 1060:         train accuracy = 13.5611 | logprob = -4.2407 | KL term = 1.9087252488285464 test accuracy = 13.1061 | logprob = -4.2000 | KL term = 1.9087252488285464\n",
      "Epoch 1080:         train accuracy = 13.5611 | logprob = -4.2407 | KL term = 1.9087255121949165 test accuracy = 13.1061 | logprob = -4.2000 | KL term = 1.9087255121949165\n",
      "Epoch 1100:         train accuracy = 13.5611 | logprob = -4.2407 | KL term = 1.9087256438781015 test accuracy = 13.1061 | logprob = -4.2000 | KL term = 1.9087256438781015\n",
      "Epoch 1120:         train accuracy = 13.5611 | logprob = -4.2407 | KL term = 1.9087259072444713 test accuracy = 13.1061 | logprob = -4.2000 | KL term = 1.9087259072444713\n",
      "Epoch 1140:         train accuracy = 13.5611 | logprob = -4.2407 | KL term = 1.9087261706108414 test accuracy = 13.1061 | logprob = -4.2000 | KL term = 1.9087261706108414\n",
      "Epoch 1160:         train accuracy = 13.5611 | logprob = -4.2407 | KL term = 1.9087263022940264 test accuracy = 13.1061 | logprob = -4.2000 | KL term = 1.9087263022940264\n",
      "Epoch 1180:         train accuracy = 13.5611 | logprob = -4.2407 | KL term = 1.9087265656603964 test accuracy = 13.1061 | logprob = -4.2000 | KL term = 1.9087265656603964\n",
      "Epoch 1200:         train accuracy = 13.5611 | logprob = -4.2407 | KL term = 1.9087266973435815 test accuracy = 13.1061 | logprob = -4.2000 | KL term = 1.9087266973435815\n",
      "Epoch 1220:         train accuracy = 13.5611 | logprob = -4.2407 | KL term = 1.9087269607099515 test accuracy = 13.1061 | logprob = -4.2000 | KL term = 1.9087269607099515\n",
      "Epoch 1240:         train accuracy = 13.5611 | logprob = -4.2407 | KL term = 1.9087272240763216 test accuracy = 13.1061 | logprob = -4.2000 | KL term = 1.9087272240763216\n",
      "Epoch 1260:         train accuracy = 13.5611 | logprob = -4.2407 | KL term = 1.9087274874426914 test accuracy = 13.1061 | logprob = -4.2000 | KL term = 1.9087274874426914\n",
      "Epoch 1280:         train accuracy = 13.5611 | logprob = -4.2407 | KL term = 1.9087276191258764 test accuracy = 13.1061 | logprob = -4.2000 | KL term = 1.9087276191258764\n",
      "Epoch 1300:         train accuracy = 13.5611 | logprob = -4.2407 | KL term = 1.9087278824922465 test accuracy = 13.1061 | logprob = -4.2000 | KL term = 1.9087278824922465\n",
      "Epoch 1320:         train accuracy = 13.5611 | logprob = -4.2407 | KL term = 1.9087281458586165 test accuracy = 13.1061 | logprob = -4.2000 | KL term = 1.9087281458586165\n",
      "Epoch 1340:         train accuracy = 13.5611 | logprob = -4.2407 | KL term = 1.9087284092249865 test accuracy = 13.1061 | logprob = -4.2000 | KL term = 1.9087284092249865\n",
      "Epoch 1360:         train accuracy = 13.5611 | logprob = -4.2407 | KL term = 1.9087286725913566 test accuracy = 13.1061 | logprob = -4.2000 | KL term = 1.9087286725913566\n",
      "Epoch 1380:         train accuracy = 13.5611 | logprob = -4.2407 | KL term = 1.9087288042745416 test accuracy = 13.1061 | logprob = -4.2000 | KL term = 1.9087289359577266\n",
      "Epoch 1400:         train accuracy = 13.5611 | logprob = -4.2407 | KL term = 1.9087290676409114 test accuracy = 13.1061 | logprob = -4.2000 | KL term = 1.9087290676409114\n",
      "Epoch 1420:         train accuracy = 13.5611 | logprob = -4.2407 | KL term = 1.9087293310072815 test accuracy = 13.1061 | logprob = -4.2000 | KL term = 1.9087293310072815\n",
      "Epoch 1440:         train accuracy = 13.5611 | logprob = -4.2407 | KL term = 1.9087295943736515 test accuracy = 13.1061 | logprob = -4.2000 | KL term = 1.9087295943736515\n",
      "Epoch 1460:         train accuracy = 13.5611 | logprob = -4.2407 | KL term = 1.9087298577400216 test accuracy = 13.1061 | logprob = -4.2000 | KL term = 1.9087298577400216\n",
      "Epoch 1480:         train accuracy = 13.5611 | logprob = -4.2407 | KL term = 1.9087301211063916 test accuracy = 13.1061 | logprob = -4.2000 | KL term = 1.9087301211063916\n",
      "Epoch 1500:         train accuracy = 13.5611 | logprob = -4.2407 | KL term = 1.9087303844727617 test accuracy = 13.1061 | logprob = -4.2000 | KL term = 1.9087303844727617\n",
      "Epoch 1520:         train accuracy = 13.5611 | logprob = -4.2407 | KL term = 1.9087306478391317 test accuracy = 13.1061 | logprob = -4.2000 | KL term = 1.9087306478391317\n",
      "Epoch 1540:         train accuracy = 13.5611 | logprob = -4.2407 | KL term = 1.9087309112055015 test accuracy = 13.1061 | logprob = -4.2000 | KL term = 1.9087310428886866\n",
      "Epoch 1560:         train accuracy = 13.5611 | logprob = -4.2407 | KL term = 1.9087313062550566 test accuracy = 13.1061 | logprob = -4.2000 | KL term = 1.9087313062550566\n",
      "Epoch 1580:         train accuracy = 13.5611 | logprob = -4.2407 | KL term = 1.9087315696214266 test accuracy = 13.1061 | logprob = -4.2000 | KL term = 1.9087315696214266\n",
      "Epoch 1600:         train accuracy = 13.5611 | logprob = -4.2407 | KL term = 1.9087318329877967 test accuracy = 13.1061 | logprob = -4.2000 | KL term = 1.9087318329877967\n",
      "Epoch 1620:         train accuracy = 13.5611 | logprob = -4.2407 | KL term = 1.9087320963541667 test accuracy = 13.1061 | logprob = -4.2000 | KL term = 1.9087320963541667\n",
      "Epoch 1640:         train accuracy = 13.5611 | logprob = -4.2407 | KL term = 1.9087323597205368 test accuracy = 13.1061 | logprob = -4.2000 | KL term = 1.9087324914037216\n",
      "Epoch 1660:         train accuracy = 13.5611 | logprob = -4.2407 | KL term = 1.9087327547700916 test accuracy = 13.1061 | logprob = -4.2000 | KL term = 1.9087327547700916\n",
      "Epoch 1680:         train accuracy = 13.5611 | logprob = -4.2407 | KL term = 1.9087330181364617 test accuracy = 13.1061 | logprob = -4.2000 | KL term = 1.9087330181364617\n",
      "Epoch 1700:         train accuracy = 13.5611 | logprob = -4.2407 | KL term = 1.9087332815028317 test accuracy = 13.1061 | logprob = -4.2000 | KL term = 1.9087332815028317\n",
      "Epoch 1720:         train accuracy = 13.5611 | logprob = -4.2407 | KL term = 1.9087335448692018 test accuracy = 13.1061 | logprob = -4.2000 | KL term = 1.9087336765523868\n",
      "Epoch 1740:         train accuracy = 13.5611 | logprob = -4.2407 | KL term = 1.9087339399187568 test accuracy = 13.1061 | logprob = -4.2000 | KL term = 1.9087339399187568\n",
      "Epoch 1760:         train accuracy = 13.5611 | logprob = -4.2407 | KL term = 1.9087342032851267 test accuracy = 13.1061 | logprob = -4.2000 | KL term = 1.9087342032851267\n",
      "Epoch 1780:         train accuracy = 13.5611 | logprob = -4.2407 | KL term = 1.9087345983346817 test accuracy = 13.1061 | logprob = -4.2000 | KL term = 1.9087345983346817\n",
      "Epoch 1800:         train accuracy = 13.5611 | logprob = -4.2407 | KL term = 1.9087348617010518 test accuracy = 13.1061 | logprob = -4.2000 | KL term = 1.9087348617010518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1820:         train accuracy = 13.5611 | logprob = -4.2407 | KL term = 1.9087351250674218 test accuracy = 13.1061 | logprob = -4.2000 | KL term = 1.9087352567506068\n",
      "Epoch 1840:         train accuracy = 13.5611 | logprob = -4.2407 | KL term = 1.908735520116977 test accuracy = 13.1061 | logprob = -4.2000 | KL term = 1.908735520116977\n",
      "Epoch 1860:         train accuracy = 13.5611 | logprob = -4.2407 | KL term = 1.9087359151665317 test accuracy = 13.1061 | logprob = -4.2000 | KL term = 1.9087359151665317\n",
      "Epoch 1880:         train accuracy = 13.5611 | logprob = -4.2407 | KL term = 1.9087361785329018 test accuracy = 13.1061 | logprob = -4.2000 | KL term = 1.9087361785329018\n",
      "Epoch 1900:         train accuracy = 13.5611 | logprob = -4.2407 | KL term = 1.9087365735824569 test accuracy = 13.1061 | logprob = -4.2000 | KL term = 1.9087365735824569\n",
      "Epoch 1920:         train accuracy = 13.5611 | logprob = -4.2407 | KL term = 1.908736836948827 test accuracy = 13.1061 | logprob = -4.2000 | KL term = 1.908736836948827\n",
      "Epoch 1940:         train accuracy = 13.5611 | logprob = -4.2407 | KL term = 1.908737231998382 test accuracy = 13.1061 | logprob = -4.2000 | KL term = 1.908737231998382\n",
      "Epoch 1960:         train accuracy = 13.5611 | logprob = -4.2407 | KL term = 1.9087376270479368 test accuracy = 13.1061 | logprob = -4.2000 | KL term = 1.9087376270479368\n",
      "Epoch 1980:         train accuracy = 13.5611 | logprob = -4.2407 | KL term = 1.9087378904143069 test accuracy = 13.1061 | logprob = -4.2000 | KL term = 1.9087378904143069\n",
      "Epoch 2000:         train accuracy = 13.5611 | logprob = -4.2407 | KL term = 1.908738285463862 test accuracy = 13.1061 | logprob = -4.2000 | KL term = 1.908738285463862\n"
     ]
    }
   ],
   "source": [
    "times = 1 #运行次数\n",
    "paras = {'conc':\n",
    "             {'in': {\"scale\": [[1.0]], \"shift\": [[0.0]]},\n",
    "              'out': {\"scale\": [[1.0, 0.1]], \"shift\": [[0.0, 1.9]]},\n",
    "              'hidden_dims': [50],\n",
    "              'learning_rate': 0.1,\n",
    "              'n_epochs': 2000,\n",
    "              'epochs': [300, 700]\n",
    "              },\n",
    "         'powe':\n",
    "             {'in': {\"scale\": [[1.0]], \"shift\": [[0.0]]},\n",
    "              'out': {\"scale\": [[1.0, 0.02]], \"shift\": [[0.0, -3.5]]},\n",
    "              'hidden_dims': [50],\n",
    "              'learning_rate': 0.6,\n",
    "              'n_epochs': 2000,\n",
    "              'epochs': [760, 900]\n",
    "              },\n",
    "         'yach':\n",
    "             {'in': {\"scale\": [[1.0]], \"shift\": [[0.0]]},\n",
    "              'out': {\"scale\": [[1.0, 0.85]], \"shift\": [[0.0, -1.7]]},\n",
    "              'hidden_dims': [50],\n",
    "              'learning_rate': 0.001,\n",
    "              'n_epochs': 10000,\n",
    "              'epochs': [8000, 10000]\n",
    "              },\n",
    "         'prot':\n",
    "             {'in': {\"scale\": [[1.0]], \"shift\": [[0.0]]},\n",
    "              'out': {\"scale\": [[1.0, 0.96]], \"shift\": [[0.0, -3.5]]},\n",
    "              'hidden_dims': [100],\n",
    "              'learning_rate': 0.1,\n",
    "              'n_epochs': 500,\n",
    "              'epochs': [5, 20]\n",
    "              },\n",
    "         'face':\n",
    "             {'in': {\"scale\": [[1.0]], \"shift\": [[0.0]]},\n",
    "              'out': {\"scale\": [[1.0, 0.1]], \"shift\": [[0.0, -1.0]]},\n",
    "              'hidden_dims': [50],\n",
    "              'learning_rate': 0.3,\n",
    "              'n_epochs': 800,\n",
    "              'epochs': [225, 400]\n",
    "              }  \n",
    "         }\n",
    "\n",
    "dataset_name = 'conc'  # 数据集名称\n",
    "root_path = '/home/yunnd/project/result/DVI_test'  # 存储结果的路径\n",
    "run_(dataset_name, os.path.join(root_path, dataset_name), times, paras[dataset_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画出结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conc\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# datasets = [key for key in paras.keys()]\n",
    "datasets=['conc']\n",
    "epoch_list = [paras[key]['epochs'] for key in paras.keys()]\n",
    "show_(datasets, root_path, times, epoch_list, 'logprob')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
